{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Optional, Dict, Set, Callable, Any\n",
    "from joblib import Memory, Parallel, delayed\n",
    "import tslearn\n",
    "import tslearn.metrics\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "\n",
    "from cross_validation import cv_tslearn, print_cv_results\n",
    "from eval_on_test import validate_tslearn, print_test_results\n",
    "from utils import load_from_pickle, save_to_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerate all tslearn datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _datasets = [\n",
    "#             'ArticularyWordRecognition', \n",
    "#             'BasicMotions', \n",
    "#             'Cricket',\n",
    "#             #'ERing',\n",
    "#             'Libras', \n",
    "#             'NATOPS', \n",
    "#             'RacketSports',     \n",
    "#             'FingerMovements',\n",
    "#             'Heartbeat',\n",
    "#             'SelfRegulationSCP1', \n",
    "#             'UWaveGestureLibrary'\n",
    "#             ]\n",
    "\n",
    "# import tslearn\n",
    "# UCR_UEA_datasets = tslearn.datasets.UCR_UEA_datasets()\n",
    "\n",
    "# for dataset_name in UCR_UEA_datasets.list_multivariate_datasets():\n",
    "# #for dataset_name in _datasets:\n",
    "#     print(\"Dataset:\", dataset_name)\n",
    "#     dataset = UCR_UEA_datasets.load_dataset(dataset_name)\n",
    "#     if dataset[0] is not None:\n",
    "#         X_train, y_train, X_test, y_test = dataset\n",
    "#         num_classes = len(np.unique(y_train))\n",
    "#         N_train, T, d = X_train.shape\n",
    "#         N_test, _, _  = X_test.shape\n",
    "        \n",
    "#         print(\"Number of Classes:\", num_classes)\n",
    "#         print(\"Dimension of path:\", d)\n",
    "#         print(\"Length:\", T)\n",
    "#         print(\"Train Size, Test Size\", N_train, N_test)\n",
    "#         print()\n",
    "#     else:\n",
    "#         print(\"No dataset found\")\n",
    "#         print()\n",
    "\n",
    "#yes\n",
    "# Dataset: ArticularyWordRecognition\n",
    "# Number of Classes: 25\n",
    "# Dimension of path: 9\n",
    "# Length: 144\n",
    "# Train Size, Test Size 275 300\n",
    "\n",
    "# Dataset: AtrialFibrillation\n",
    "# No dataset found\n",
    "\n",
    "#yes\n",
    "# Dataset: BasicMotions\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 6\n",
    "# Length: 100\n",
    "# Train Size, Test Size 40 40\n",
    "\n",
    "# Dataset: CharacterTrajectories\n",
    "# No dataset found\n",
    "\n",
    "#yes\n",
    "# Dataset: Cricket\n",
    "# Number of Classes: 12\n",
    "# Dimension of path: 6\n",
    "# Length: 1197\n",
    "# Train Size, Test Size 108 72\n",
    "\n",
    "# Dataset: DuckDuckGeese\n",
    "# No dataset found\n",
    "\n",
    "# Dataset: EigenWorms\n",
    "# Number of Classes: 5\n",
    "# Dimension of path: 6\n",
    "# Length: 17984\n",
    "# Train Size, Test Size 128 131\n",
    "\n",
    "#why not\n",
    "# Dataset: Epilepsy\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 3\n",
    "# Length: 206\n",
    "# Train Size, Test Size 137 138\n",
    "\n",
    "#longLength\n",
    "# Dataset: EthanolConcentration\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 3\n",
    "# Length: 1751\n",
    "# Train Size, Test Size 261 263\n",
    "\n",
    "# Dataset: ERing\n",
    "# No dataset found\n",
    "\n",
    "#big\n",
    "# Dataset: FaceDetection\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 144\n",
    "# Length: 62\n",
    "# Train Size, Test Size 5890 3524\n",
    "\n",
    "#yes\n",
    "# Dataset: FingerMovements\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 28\n",
    "# Length: 50\n",
    "# Train Size, Test Size 316 100\n",
    "\n",
    "#why not, maybe big length\n",
    "# Dataset: HandMovementDirection\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 10\n",
    "# Length: 400\n",
    "# Train Size, Test Size 160 74\n",
    "\n",
    "#smallTrain\n",
    "# Dataset: Handwriting\n",
    "# Number of Classes: 26\n",
    "# Dimension of path: 3\n",
    "# Length: 152\n",
    "# Train Size, Test Size 150 850\n",
    "\n",
    "#yes\n",
    "# Dataset: Heartbeat\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 61\n",
    "# Length: 405\n",
    "# Train Size, Test Size 204 205\n",
    "\n",
    "#big\n",
    "# Dataset: InsectWingbeat\n",
    "# Number of Classes: 10\n",
    "# Dimension of path: 200\n",
    "# Length: 22\n",
    "# Train Size, Test Size 25000 25000\n",
    "\n",
    "# Dataset: JapaneseVowels\n",
    "# No dataset found\n",
    "\n",
    "#yes\n",
    "# Dataset: Libras\n",
    "# Number of Classes: 15\n",
    "# Dimension of path: 2\n",
    "# Length: 45\n",
    "# Train Size, Test Size 180 180\n",
    "\n",
    "#TODO I SHOULD INCLUDE\n",
    "# Dataset: LSST\n",
    "# Number of Classes: 14\n",
    "# Dimension of path: 6\n",
    "# Length: 36\n",
    "# Train Size, Test Size 2459 2466\n",
    "\n",
    "#length\n",
    "# Dataset: MotorImagery\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 64\n",
    "# Length: 3000\n",
    "# Train Size, Test Size 278 100\n",
    "\n",
    "#yes\n",
    "# Dataset: NATOPS\n",
    "# Number of Classes: 6\n",
    "# Dimension of path: 24\n",
    "# Length: 51\n",
    "# Train Size, Test Size 180 180\n",
    "\n",
    "#yes\n",
    "# Dataset: PenDigits\n",
    "# Number of Classes: 10\n",
    "# Dimension of path: 2\n",
    "# Length: 8\n",
    "# Train Size, Test Size 7494 3498\n",
    "\n",
    "#TODO SHOULD INCLUDE highDim\n",
    "# Dataset: PEMS-SF\n",
    "# Number of Classes: 7\n",
    "# Dimension of path: 963\n",
    "# Length: 144\n",
    "# Train Size, Test Size 267 173\n",
    "\n",
    "#NO, dim=1, big length, large num classes\n",
    "# Dataset: Phoneme\n",
    "# Number of Classes: 39\n",
    "# Dimension of path: 1\n",
    "# Length: 1024\n",
    "# Train Size, Test Size 214 1896\n",
    "\n",
    "#yes\n",
    "# Dataset: RacketSports\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 6\n",
    "# Length: 30\n",
    "# Train Size, Test Size 151 152\n",
    "\n",
    "#yes\n",
    "# Dataset: SelfRegulationSCP1\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 6\n",
    "# Length: 896\n",
    "# Train Size, Test Size 268 293\n",
    "\n",
    "# Dataset: SelfRegulationSCP2\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 7\n",
    "# Length: 1152\n",
    "# Train Size, Test Size 200 180\n",
    "\n",
    "# Dataset: SpokenArabicDigits\n",
    "# No dataset found\n",
    "\n",
    "#NO, long, also very small set\n",
    "# Dataset: StandWalkJump\n",
    "# Number of Classes: 3\n",
    "# Dimension of path: 4\n",
    "# Length: 2500\n",
    "# Train Size, Test Size 12 15\n",
    "\n",
    "#yes\n",
    "# Dataset: UWaveGestureLibrary\n",
    "# Number of Classes: 8\n",
    "# Dimension of path: 3\n",
    "# Length: 315\n",
    "# Train Size, Test Size 120 320\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: PenDigits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes: 10\n",
      "Dimension of path: 2\n",
      "Length: 8\n",
      "Train: 7494\n",
      "Test: N/A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Label for rbf:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cv_best_models = cv_tslearn(\n",
    "    dataset_names = [\n",
    "        #'ArticularyWordRecognition', \n",
    "        #'BasicMotions', \n",
    "        #'Cricket',\n",
    "             #########'ERing', #cant find dataset\n",
    "        #'Libras', \n",
    "        #'NATOPS', \n",
    "        #'RacketSports',     \n",
    "        #'FingerMovements',\n",
    "        #'Heartbeat',\n",
    "        #'SelfRegulationSCP1', \n",
    "        #'UWaveGestureLibrary',\n",
    "        'PenDigits',\n",
    "        #'LSST',\n",
    "        #'EthanolConcentration',\n",
    "        ],\n",
    "    kernel_names = [\n",
    "        #\"linear\",\n",
    "        \"rbf\",\n",
    "        #\"poly\",\n",
    "        #\"gak\",\n",
    "        #\"truncated sig\",\n",
    "        #\"truncated sig rbf\",\n",
    "        #\"signature pde rbf\",\n",
    "        #\"integral linear\",\n",
    "        #\"integral rbf\",\n",
    "        #\"integral poly\",\n",
    "        ],\n",
    "        k=5,\n",
    "        n_repeats=1,\n",
    "        n_jobs_repeats=1,\n",
    "        n_jobs_gram=1,\n",
    "        verbose=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print CV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_results(cv_best_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = validate_tslearn(cv_best_models, n_jobs=1, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_results(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CV data from file and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dicts_from_pickle(paths:List[str]) -> Dict:\n",
    "    dicts = [load_from_pickle(path)\n",
    "             for path in paths]\n",
    "    joined_dicts = {}\n",
    "    for d in dicts:\n",
    "        joined_dicts.update(d)\n",
    "    return joined_dicts\n",
    "\n",
    "# Load the cross validation results\n",
    "cv_results = read_dicts_from_pickle(\n",
    "    [\n",
    "    \"../Data/cv_results_Heart.pkl\", \n",
    "    \"../Data/cv_results_UWave_BM.pkl\",\n",
    "    ])\n",
    "print_cv_results(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = read_dicts_from_pickle([]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
