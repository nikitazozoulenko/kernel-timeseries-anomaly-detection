{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import sklearn.utils\n",
    "import sklearn.metrics\n",
    "import iisignature\n",
    "import torch\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import List, Optional, Dict, Set, Callable, Any\n",
    "from joblib import Memory, Parallel, delayed\n",
    "import tslearn\n",
    "import tslearn.metrics\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "import sigkernel\n",
    "import scipy\n",
    "from scipy.interpolate import interp1d\n",
    "from numba import njit\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from models.signature import streams_to_sigs, transform_stream\n",
    "from models.conformance import BaseclassConformanceScore, stream_to_torch\n",
    "from models.kernels import linear_kernel_gram, rbf_kernel_gram, poly_kernel_gram\n",
    "from models.kernels import pairwise_kernel_gram, integral_kernel_gram, sig_kernel_gram\n",
    "from experiment_code import print_dataset_stats\n",
    "\n",
    "from models.signature import transform_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PenDigits dataset (Variable Length) \n",
    "\n",
    "* Can't use ts-learn since it interpolated and homogenized the length of all time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################## |\n",
    "################################### PenDigits experiments #################################### |\n",
    "############################################################################################## \\/\n",
    "\n",
    "def run_pendigits_experiments(df:pd.DataFrame, \n",
    "                              kernel_names:List[str],\n",
    "                              stream_transforms = [\"time_enhance\", \"min_max_normalize\"],):\n",
    "    \"\"\"Calculates AUCs for each kernel on the PenDigits dataset.\n",
    "    df has columns [\"data\", \"label\", \"subset\"]. Each data point \n",
    "    is a timeseries of shape (T_i, d) of variable length.\"\"\"\n",
    "    #transform streams\n",
    "    df[\"data\"] = df[\"data\"].apply(lambda x : transform_stream(x, stream_transforms))\n",
    "\n",
    "    #Gather dataset info\n",
    "    X_train = df[df[\"subset\"]==\"train\"][\"data\"].values\n",
    "    y_train = np.array(df[df[\"subset\"]==\"train\"][\"label\"].values)\n",
    "    X_test = df[df[\"subset\"]==\"test\"][\"data\"].values\n",
    "    y_test = np.array(df[df[\"subset\"]==\"test\"][\"label\"].values)\n",
    "    labels = sorted(df[\"label\"].unique())\n",
    "    num_classes = len(labels)\n",
    "    d = X_train[0].shape[1]\n",
    "    T = \"variable length\"\n",
    "    N_train = len(X_train)\n",
    "    N_test = len(X_test)\n",
    "    print_dataset_stats(num_classes, d, T, N_train, N_test)\n",
    "\n",
    "    # Run each kernel\n",
    "    kernel_results = {}\n",
    "    for kernel_name in kernel_names:\n",
    "        print(kernel_name)\n",
    "        scores = run_single_kernel(X_train, y_train, X_test, y_test, labels, \n",
    "                        kernel_name, variable_length=True, normalize=False,\n",
    "                        trunc_sig_dim_bound=200, SVD_max_rank=None)\n",
    "        kernel_results[kernel_name] = scores\n",
    "\n",
    "    #log results\n",
    "    pendigits_results = {\"results\": kernel_results, \n",
    "                         \"num_classes\": num_classes,\n",
    "                         \"dim\": d,\n",
    "                         \"ts_length\":T, \n",
    "                         \"N_train\":N_train, \n",
    "                         \"N_test\":N_test}\n",
    "    return pendigits_results\n",
    "\n",
    "# pendigits_results = run_pendigits_experiments(\n",
    "#     df_pendigits_raw, \n",
    "#     kernel_names=[\n",
    "#         #\"gak\",\n",
    "#         \"truncated signature\", \n",
    "#         #\"signature pde\", \n",
    "#         #\"signature pde RBF\"\n",
    "#         ],\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_experiment_results({\"PenDigits\": pendigits_results})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
