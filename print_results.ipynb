{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Optional, Dict, Set, Callable, Any, Literal\n",
    "from joblib import Memory, Parallel, delayed\n",
    "import tslearn\n",
    "import tslearn.metrics\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "\n",
    "from experiments.cross_validation import cv_tslearn, print_cv_results\n",
    "from experiments.eval_on_test import validate_tslearn, print_test_results\n",
    "from experiments.utils import join_dicts_from_pickle_paths, save_to_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: NATOPS\n",
      "Number of Classes: 6\n",
      "Dimension of path: 24\n",
      "Length: 51\n",
      "Train: 180\n",
      "Test: N/A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Label for signature pde rbf: 100%|██████████| 6/6 [02:16<00:00, 22.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for kernel signature pde rbf: 136.38422012329102 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Label for gak: 100%|██████████| 6/6 [00:15<00:00,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for kernel gak: 15.546572208404541 seconds\n",
      "Time taken for dataset NATOPS: 151.94349932670593 seconds\n",
      "\n",
      "\n",
      "\n",
      "Cross Validation Results\n",
      "Number of Classes: 6\n",
      "Dimension of path: 24\n",
      "Length: 51\n",
      "Train: 180\n",
      "Test: N/A\n",
      "\n",
      "conf_results\n",
      "\n",
      "signature pde rbf\n",
      "final_score_avgs 1.1739908768807794\n",
      "params_score_avgs [0.703 0.893 1.051 0.99  1.09 ]\n",
      "thresh_score_avgs [0.963 0.889 0.909 0.97  0.925 0.906 0.927 0.933 0.926 0.913 0.887 0.887\n",
      " 0.913 0.897 0.92  0.9   0.93  0.967 0.983 0.974 0.988 1.019 1.086 0.736]\n",
      "1.0\n",
      "{'sigma': 10.0, 'dyadic_order': 2.0, 'threshold': 20}\n",
      "2.0\n",
      "{'sigma': 10.0, 'dyadic_order': 2.0, 'threshold': 23}\n",
      "3.0\n",
      "{'sigma': 0.1, 'dyadic_order': 2.0, 'threshold': 18}\n",
      "4.0\n",
      "{'sigma': 10.0, 'dyadic_order': 2.0, 'threshold': 23}\n",
      "5.0\n",
      "{'sigma': 1.0, 'dyadic_order': 2.0, 'threshold': 1}\n",
      "6.0\n",
      "{'sigma': 0.1, 'dyadic_order': 2.0, 'threshold': 7}\n",
      "\n",
      "gak\n",
      "final_score_avgs 1.6473840215379374\n",
      "params_score_avgs [1.486 1.59  1.629]\n",
      "thresh_score_avgs [1.265 1.295 1.41  1.385 1.46  1.5   1.514 1.51  1.481 1.461 1.435 1.411\n",
      " 1.419 1.411 1.419 1.423 1.448 1.502 1.516 1.546 1.544 1.557 1.63  0.   ]\n",
      "1.0\n",
      "{'gak_factor': 3.0, 'threshold': 22}\n",
      "2.0\n",
      "{'gak_factor': 3.0, 'threshold': 20}\n",
      "3.0\n",
      "{'gak_factor': 3.0, 'threshold': 21}\n",
      "4.0\n",
      "{'gak_factor': 1.0, 'threshold': 3}\n",
      "5.0\n",
      "{'gak_factor': 0.333, 'threshold': 23}\n",
      "6.0\n",
      "{'gak_factor': 1.0, 'threshold': 23}\n",
      "\n",
      "mahal_results\n",
      "\n",
      "signature pde rbf\n",
      "final_score_avgs 1.2319295213503716\n",
      "params_score_avgs [0.686 0.874 0.97  1.124 0.95 ]\n",
      "thresh_score_avgs [0.779 0.825 0.851 0.856 0.872 0.83  0.861 0.849 0.87  0.928 0.913 0.969\n",
      " 1.008 0.973 1.023 1.038 1.035 1.022 1.041 1.035 1.094 1.086 1.171 0.813]\n",
      "1.0\n",
      "{'sigma': 10.0, 'dyadic_order': 2.0, 'threshold': 23}\n",
      "2.0\n",
      "{'sigma': 10.0, 'dyadic_order': 2.0, 'threshold': 23}\n",
      "3.0\n",
      "{'sigma': 10.0, 'dyadic_order': 2.0, 'threshold': 5}\n",
      "4.0\n",
      "{'sigma': 1.0, 'dyadic_order': 2.0, 'threshold': 22}\n",
      "5.0\n",
      "{'sigma': 1.0, 'dyadic_order': 2.0, 'threshold': 16}\n",
      "6.0\n",
      "{'sigma': 1.0, 'dyadic_order': 2.0, 'threshold': 23}\n",
      "\n",
      "gak\n",
      "final_score_avgs 1.5801600780683598\n",
      "params_score_avgs [0.536 0.713 1.58 ]\n",
      "thresh_score_avgs [0.732 0.634 0.696 0.809 0.904 0.948 0.99  1.069 1.116 1.176 1.212 1.255\n",
      " 1.274 1.283 1.299 1.347 1.384 1.44  1.467 1.483 1.507 1.547 1.575 0.   ]\n",
      "1.0\n",
      "{'gak_factor': 3.0, 'threshold': 23}\n",
      "2.0\n",
      "{'gak_factor': 3.0, 'threshold': 23}\n",
      "3.0\n",
      "{'gak_factor': 3.0, 'threshold': 21}\n",
      "4.0\n",
      "{'gak_factor': 3.0, 'threshold': 23}\n",
      "5.0\n",
      "{'gak_factor': 3.0, 'threshold': 23}\n",
      "6.0\n",
      "{'gak_factor': 3.0, 'threshold': 18}\n",
      "\n",
      "End dataset \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cv_results = cv_tslearn(\n",
    "    dataset_names = [\n",
    "        # 'Epilepsy',                    # N_corpus = 34\n",
    "        # 'EthanolConcentration',        # N_corpus = 65\n",
    "        # 'FingerMovements',             # N_corpus = 158\n",
    "        # 'HandMovementDirection',       # N_corpus = 40\n",
    "        # 'Heartbeat',                   # N_corpus = 102\n",
    "        # 'LSST',                        # N_corpus = 176\n",
    "        # 'MotorImagery',                # N_corpus = 139\n",
    "         'NATOPS',                      # N_corpus = 30\n",
    "        # 'PenDigits',                   # N_corpus = 749\n",
    "        # 'PEMS-SF',                     # N_corpus = 38\n",
    "        # 'PhonemeSpectra',              # N_corpus = 85\n",
    "        # 'RacketSports',                # N_corpus = 38\n",
    "        # 'SelfRegulationSCP1',          # N_corpus = 134\n",
    "        ],\n",
    "    kernel_names = [\n",
    "        # \"linear\",\n",
    "        # \"rbf\",\n",
    "        # \"poly\",\n",
    "        # \"integral rbf\",\n",
    "        # \"integral poly\",\n",
    "        # \"truncated sig\",\n",
    "        # \"truncated sig rbf\",\n",
    "        \"signature pde rbf\",\n",
    "        \"gak\",\n",
    "        ],\n",
    "        k=5,\n",
    "        n_repeats=1,\n",
    "        n_jobs_repeats=3,\n",
    "        n_jobs_gram=1,\n",
    "        verbose=False,\n",
    "        )\n",
    "print_cv_results(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = validate_tslearn(cv_results, n_jobs=4, verbose=False)\n",
    "print_test_results(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CV data from file and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cross validation results\n",
    "cv_results = join_dicts_from_pickle_paths(\n",
    "    [\n",
    "    \"Data/cv_Epilepsy.pkl\",\n",
    "    #\"Data/cv_EthanolConcentration.pkl\",\n",
    "    #\"Data/cv_FingerMovements.pkl\",\n",
    "    #\"Data/cv_HandMovementDirection.pkl\",\n",
    "    #\"Data/cv_Heartbeat.pkl\",\n",
    "    #\"Data/cv_LSST.pkl\",\n",
    "    #\"Data/cv_MotorImagery.pkl\",\n",
    "    #\"Data/cv_NATOPS.pkl\",\n",
    "    #\"Data/cv_PEMS-SF.pkl\",\n",
    "    #\"Data/cv_PenDigits.pkl\",\n",
    "    #\"Data/cv_PhonemeSpectra.pkl\",\n",
    "    #\"Data/cv_RacketSports.pkl\",\n",
    "    #\"Data/cv_SelfRegulationSCP1.pkl\",\n",
    "    ])\n",
    "print_cv_results(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.experiment_code import print_dataset_stats\n",
    "from experiments.utils import print_latex_results, join_dicts_from_pickle_paths\n",
    "\n",
    "test_results = join_dicts_from_pickle_paths([\n",
    "                                \"Data/results_shorts.pkl\",\n",
    "                                \"Data/results_longs.pkl\",\n",
    "                                             ])\n",
    "\n",
    "test_results = {d:k for d,k in test_results.items() \n",
    "                # if d in [\"EthanolConcentration\",  #datasets with corpus size > 50\n",
    "                #         \"FingerMovements\",\n",
    "                #         \"Heartbeat\",\n",
    "                #         \"LSST\",\n",
    "                #         \"MotorImagery\",\n",
    "                #         \"PenDigits\",\n",
    "                #         \"PhonemeSpectra\",\n",
    "                #         \"SelfRegulationSCP1\",]\n",
    "                }\n",
    "print_latex_results(test_results, round_digits=2)\n",
    "print_latex_results(test_results, round_digits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerate all UCR UEA datasets in 'tslearn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCR_UEA_datasets = UCR_UEA_datasets()\n",
    "\n",
    "for dataset_name in UCR_UEA_datasets.list_multivariate_datasets():\n",
    "#for dataset_name in _datasets:\n",
    "    print(\"Dataset:\", dataset_name)\n",
    "    dataset = UCR_UEA_datasets.load_dataset(dataset_name)\n",
    "    if dataset[0] is not None:\n",
    "        X_train, y_train, X_test, y_test = dataset\n",
    "        num_classes = len(np.unique(y_train))\n",
    "        N_train, T, d = X_train.shape\n",
    "        N_test, _, _  = X_test.shape\n",
    "        \n",
    "        print(\"Number of Classes:\", num_classes)\n",
    "        print(\"Dimension of path:\", d)\n",
    "        print(\"Length:\", T)\n",
    "        print(\"Train Size, Test Size\", N_train, N_test)\n",
    "        print()\n",
    "    else:\n",
    "        print(\"No dataset found\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
