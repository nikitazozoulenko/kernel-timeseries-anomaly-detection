{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional, Dict, Set, Callable, Any, Literal\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Memory, Parallel, delayed\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Optional, Dict, Set, Callable, Any, Literal\n",
    "from joblib import Memory, Parallel, delayed\n",
    "import tslearn\n",
    "import tslearn.metrics\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "\n",
    "from experiments.cross_validation import cv_tslearn, print_cv_results\n",
    "from experiments.eval_on_test import validate_tslearn, print_test_results\n",
    "from experiments.utils import join_dicts_from_pickle_paths, save_to_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerate all tslearn datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _datasets = [\n",
    "#             'ArticularyWordRecognition', \n",
    "#             'BasicMotions', \n",
    "#             'Cricket',\n",
    "#             #'ERing',\n",
    "#             'Libras', \n",
    "#             'NATOPS', \n",
    "#             'RacketSports',     \n",
    "#             'FingerMovements',\n",
    "#             'Heartbeat',\n",
    "#             'SelfRegulationSCP1', \n",
    "#             'UWaveGestureLibrary'\n",
    "#             ]\n",
    "\n",
    "# import tslearn\n",
    "# UCR_UEA_datasets = tslearn.datasets.UCR_UEA_datasets()\n",
    "\n",
    "# for dataset_name in UCR_UEA_datasets.list_multivariate_datasets():\n",
    "# #for dataset_name in _datasets:\n",
    "#     print(\"Dataset:\", dataset_name)\n",
    "#     dataset = UCR_UEA_datasets.load_dataset(dataset_name)\n",
    "#     if dataset[0] is not None:\n",
    "#         X_train, y_train, X_test, y_test = dataset\n",
    "#         num_classes = len(np.unique(y_train))\n",
    "#         N_train, T, d = X_train.shape\n",
    "#         N_test, _, _  = X_test.shape\n",
    "        \n",
    "#         print(\"Number of Classes:\", num_classes)\n",
    "#         print(\"Dimension of path:\", d)\n",
    "#         print(\"Length:\", T)\n",
    "#         print(\"Train Size, Test Size\", N_train, N_test)\n",
    "#         print()\n",
    "#     else:\n",
    "#         print(\"No dataset found\")\n",
    "#         print()\n",
    "\n",
    "#yes\n",
    "# Dataset: ArticularyWordRecognition\n",
    "# Number of Classes: 25\n",
    "# Dimension of path: 9\n",
    "# Length: 144\n",
    "# Train Size, Test Size 275 300\n",
    "\n",
    "# Dataset: AtrialFibrillation\n",
    "# No dataset found\n",
    "\n",
    "#yes\n",
    "# Dataset: BasicMotions\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 6\n",
    "# Length: 100\n",
    "# Train Size, Test Size 40 40\n",
    "\n",
    "# Dataset: CharacterTrajectories\n",
    "# No dataset found\n",
    "\n",
    "#yes\n",
    "# Dataset: Cricket\n",
    "# Number of Classes: 12\n",
    "# Dimension of path: 6\n",
    "# Length: 1197\n",
    "# Train Size, Test Size 108 72\n",
    "\n",
    "# Dataset: DuckDuckGeese\n",
    "# No dataset found\n",
    "\n",
    "# Dataset: EigenWorms\n",
    "# Number of Classes: 5\n",
    "# Dimension of path: 6\n",
    "# Length: 17984\n",
    "# Train Size, Test Size 128 131\n",
    "\n",
    "#why not\n",
    "# Dataset: Epilepsy\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 3\n",
    "# Length: 206\n",
    "# Train Size, Test Size 137 138\n",
    "\n",
    "#longLength\n",
    "# Dataset: EthanolConcentration\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 3\n",
    "# Length: 1751\n",
    "# Train Size, Test Size 261 263\n",
    "\n",
    "# Dataset: ERing\n",
    "# No dataset found\n",
    "\n",
    "#big\n",
    "# Dataset: FaceDetection\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 144\n",
    "# Length: 62\n",
    "# Train Size, Test Size 5890 3524\n",
    "\n",
    "#yes\n",
    "# Dataset: FingerMovements\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 28\n",
    "# Length: 50\n",
    "# Train Size, Test Size 316 100\n",
    "\n",
    "#why not, maybe big length\n",
    "# Dataset: HandMovementDirection\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 10\n",
    "# Length: 400\n",
    "# Train Size, Test Size 160 74\n",
    "\n",
    "#smallTrain\n",
    "# Dataset: Handwriting\n",
    "# Number of Classes: 26\n",
    "# Dimension of path: 3\n",
    "# Length: 152\n",
    "# Train Size, Test Size 150 850\n",
    "\n",
    "#yes\n",
    "# Dataset: Heartbeat\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 61\n",
    "# Length: 405\n",
    "# Train Size, Test Size 204 205\n",
    "\n",
    "#big\n",
    "# Dataset: InsectWingbeat\n",
    "# Number of Classes: 10\n",
    "# Dimension of path: 200\n",
    "# Length: 22\n",
    "# Train Size, Test Size 25000 25000\n",
    "\n",
    "# Dataset: JapaneseVowels\n",
    "# No dataset found\n",
    "\n",
    "#yes\n",
    "# Dataset: Libras\n",
    "# Number of Classes: 15\n",
    "# Dimension of path: 2\n",
    "# Length: 45\n",
    "# Train Size, Test Size 180 180\n",
    "\n",
    "#TODO I SHOULD INCLUDE\n",
    "# Dataset: LSST\n",
    "# Number of Classes: 14\n",
    "# Dimension of path: 6\n",
    "# Length: 36\n",
    "# Train Size, Test Size 2459 2466\n",
    "\n",
    "#length\n",
    "# Dataset: MotorImagery\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 64\n",
    "# Length: 3000\n",
    "# Train Size, Test Size 278 100\n",
    "\n",
    "#yes\n",
    "# Dataset: NATOPS\n",
    "# Number of Classes: 6\n",
    "# Dimension of path: 24\n",
    "# Length: 51\n",
    "# Train Size, Test Size 180 180\n",
    "\n",
    "#yes\n",
    "# Dataset: PenDigits\n",
    "# Number of Classes: 10\n",
    "# Dimension of path: 2\n",
    "# Length: 8\n",
    "# Train Size, Test Size 7494 3498\n",
    "\n",
    "#TODO SHOULD INCLUDE highDim\n",
    "# Dataset: PEMS-SF\n",
    "# Number of Classes: 7\n",
    "# Dimension of path: 963\n",
    "# Length: 144\n",
    "# Train Size, Test Size 267 173\n",
    "\n",
    "#NO, dim=1, big length, large num classes\n",
    "# Dataset: Phoneme\n",
    "# Number of Classes: 39\n",
    "# Dimension of path: 1\n",
    "# Length: 1024\n",
    "# Train Size, Test Size 214 1896\n",
    "\n",
    "#yes\n",
    "# Dataset: RacketSports\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 6\n",
    "# Length: 30\n",
    "# Train Size, Test Size 151 152\n",
    "\n",
    "#yes\n",
    "# Dataset: SelfRegulationSCP1\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 6\n",
    "# Length: 896\n",
    "# Train Size, Test Size 268 293\n",
    "\n",
    "# Dataset: SelfRegulationSCP2\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 7\n",
    "# Length: 1152\n",
    "# Train Size, Test Size 200 180\n",
    "\n",
    "# Dataset: SpokenArabicDigits\n",
    "# No dataset found\n",
    "\n",
    "#NO, long, also very small set\n",
    "# Dataset: StandWalkJump\n",
    "# Number of Classes: 3\n",
    "# Dimension of path: 4\n",
    "# Length: 2500\n",
    "# Train Size, Test Size 12 15\n",
    "\n",
    "#yes\n",
    "# Dataset: UWaveGestureLibrary\n",
    "# Number of Classes: 8\n",
    "# Dimension of path: 3\n",
    "# Length: 315\n",
    "# Train Size, Test Size 120 320\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cv_tslearn(\n",
    "    dataset_names = [\n",
    "        'Epilepsy',                    # N_corpus = 34      #I should probably further limit this to >100\n",
    "        # 'EthanolConcentration',        # N_corpus = 65\n",
    "        # 'FingerMovements',             # N_corpus = 158\n",
    "        # 'HandMovementDirection',       # N_corpus = 40\n",
    "        # 'Heartbeat',                   # N_corpus = 102\n",
    "        # 'LSST',                        # N_corpus = 176\n",
    "        # 'MotorImagery',                # N_corpus = 139\n",
    "        # 'NATOPS',                      # N_corpus = 30\n",
    "        # 'PenDigits',                   # N_corpus = 749\n",
    "        # 'PEMS-SF',                     # N_corpus = 38\n",
    "        # 'PhonemeSpectra',              # N_corpus = 85\n",
    "        # 'RacketSports',                # N_corpus = 38\n",
    "        # 'SelfRegulationSCP1',          # N_corpus = 134\n",
    "        ],\n",
    "    kernel_names = [\n",
    "        \"linear\",\n",
    "        \"rbf\",\n",
    "        \"poly\",\n",
    "        \"integral rbf\",\n",
    "        \"integral poly\",\n",
    "        \"truncated sig\",\n",
    "        \"truncated sig rbf\",\n",
    "        \"signature pde rbf\",\n",
    "        \"gak\",\n",
    "        ],\n",
    "        k=5,\n",
    "        n_repeats=1,\n",
    "        n_jobs_repeats=3,\n",
    "        n_jobs_gram=1,\n",
    "        verbose=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print CV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_results(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = validate_tslearn(cv_results, n_jobs=4, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_results(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CV data from file and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cross validation results\n",
    "cv_results = join_dicts_from_pickle_paths(\n",
    "    [\n",
    "    \"Data/cv_Epilepsy.pkl\",\n",
    "    #\"Data/cv_EthanolConcentration.pkl\",\n",
    "    #\"Data/cv_FingerMovements.pkl\",\n",
    "    #\"Data/cv_HandMovementDirection.pkl\",\n",
    "    #\"Data/cv_Heartbeat.pkl\",\n",
    "    #\"Data/cv_LSST.pkl\",\n",
    "    #\"Data/cv_MotorImagery.pkl\",\n",
    "    #\"Data/cv_NATOPS.pkl\",\n",
    "    #\"Data/cv_PEMS-SF.pkl\",\n",
    "    #\"Data/cv_PenDigits.pkl\",\n",
    "    #\"Data/cv_PhonemeSpectra.pkl\",\n",
    "    #\"Data/cv_RacketSports.pkl\",\n",
    "    #\"Data/cv_SelfRegulationSCP1.pkl\",\n",
    "    ])\n",
    "print_cv_results(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.experiment_code import print_dataset_stats\n",
    "from experiments.utils import print_latex_results, join_dicts_from_pickle_paths\n",
    "\n",
    "test_results = join_dicts_from_pickle_paths([\n",
    "                                \"Data/results_shorts.pkl\",\n",
    "                                \"Data/results_longs.pkl\",\n",
    "                                             ])\n",
    "\n",
    "test_results = {d:k for d,k in test_results.items() \n",
    "                # if d in [\"EthanolConcentration\",  #datasets with corpus size > 50\n",
    "                #         \"FingerMovements\",\n",
    "                #         \"Heartbeat\",\n",
    "                #         \"LSST\",\n",
    "                #         \"MotorImagery\",\n",
    "                #         \"PenDigits\",\n",
    "                #         \"PhonemeSpectra\",\n",
    "                #         \"SelfRegulationSCP1\",]\n",
    "                }\n",
    "print_latex_results(test_results, 2)\n",
    "print_latex_results(test_results, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
