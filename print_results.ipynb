{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Optional, Dict, Set, Callable, Any, Literal\n",
    "from joblib import Memory, Parallel, delayed\n",
    "import tslearn\n",
    "import tslearn.metrics\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "\n",
    "from experiments.cross_validation import cv_tslearn, print_cv_results\n",
    "from experiments.eval_on_test import validate_tslearn, print_test_results\n",
    "from experiments.utils import join_dicts_from_pickle_paths, save_to_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerate all tslearn datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _datasets = [\n",
    "#             'ArticularyWordRecognition', \n",
    "#             'BasicMotions', \n",
    "#             'Cricket',\n",
    "#             #'ERing',\n",
    "#             'Libras', \n",
    "#             'NATOPS', \n",
    "#             'RacketSports',     \n",
    "#             'FingerMovements',\n",
    "#             'Heartbeat',\n",
    "#             'SelfRegulationSCP1', \n",
    "#             'UWaveGestureLibrary'\n",
    "#             ]\n",
    "\n",
    "# import tslearn\n",
    "# UCR_UEA_datasets = tslearn.datasets.UCR_UEA_datasets()\n",
    "\n",
    "# for dataset_name in UCR_UEA_datasets.list_multivariate_datasets():\n",
    "# #for dataset_name in _datasets:\n",
    "#     print(\"Dataset:\", dataset_name)\n",
    "#     dataset = UCR_UEA_datasets.load_dataset(dataset_name)\n",
    "#     if dataset[0] is not None:\n",
    "#         X_train, y_train, X_test, y_test = dataset\n",
    "#         num_classes = len(np.unique(y_train))\n",
    "#         N_train, T, d = X_train.shape\n",
    "#         N_test, _, _  = X_test.shape\n",
    "        \n",
    "#         print(\"Number of Classes:\", num_classes)\n",
    "#         print(\"Dimension of path:\", d)\n",
    "#         print(\"Length:\", T)\n",
    "#         print(\"Train Size, Test Size\", N_train, N_test)\n",
    "#         print()\n",
    "#     else:\n",
    "#         print(\"No dataset found\")\n",
    "#         print()\n",
    "\n",
    "#yes\n",
    "# Dataset: ArticularyWordRecognition\n",
    "# Number of Classes: 25\n",
    "# Dimension of path: 9\n",
    "# Length: 144\n",
    "# Train Size, Test Size 275 300\n",
    "\n",
    "# Dataset: AtrialFibrillation\n",
    "# No dataset found\n",
    "\n",
    "#yes\n",
    "# Dataset: BasicMotions\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 6\n",
    "# Length: 100\n",
    "# Train Size, Test Size 40 40\n",
    "\n",
    "# Dataset: CharacterTrajectories\n",
    "# No dataset found\n",
    "\n",
    "#yes\n",
    "# Dataset: Cricket\n",
    "# Number of Classes: 12\n",
    "# Dimension of path: 6\n",
    "# Length: 1197\n",
    "# Train Size, Test Size 108 72\n",
    "\n",
    "# Dataset: DuckDuckGeese\n",
    "# No dataset found\n",
    "\n",
    "# Dataset: EigenWorms\n",
    "# Number of Classes: 5\n",
    "# Dimension of path: 6\n",
    "# Length: 17984\n",
    "# Train Size, Test Size 128 131\n",
    "\n",
    "#why not\n",
    "# Dataset: Epilepsy\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 3\n",
    "# Length: 206\n",
    "# Train Size, Test Size 137 138\n",
    "\n",
    "#longLength\n",
    "# Dataset: EthanolConcentration\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 3\n",
    "# Length: 1751\n",
    "# Train Size, Test Size 261 263\n",
    "\n",
    "# Dataset: ERing\n",
    "# No dataset found\n",
    "\n",
    "#big\n",
    "# Dataset: FaceDetection\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 144\n",
    "# Length: 62\n",
    "# Train Size, Test Size 5890 3524\n",
    "\n",
    "#yes\n",
    "# Dataset: FingerMovements\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 28\n",
    "# Length: 50\n",
    "# Train Size, Test Size 316 100\n",
    "\n",
    "#why not, maybe big length\n",
    "# Dataset: HandMovementDirection\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 10\n",
    "# Length: 400\n",
    "# Train Size, Test Size 160 74\n",
    "\n",
    "#smallTrain\n",
    "# Dataset: Handwriting\n",
    "# Number of Classes: 26\n",
    "# Dimension of path: 3\n",
    "# Length: 152\n",
    "# Train Size, Test Size 150 850\n",
    "\n",
    "#yes\n",
    "# Dataset: Heartbeat\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 61\n",
    "# Length: 405\n",
    "# Train Size, Test Size 204 205\n",
    "\n",
    "#big\n",
    "# Dataset: InsectWingbeat\n",
    "# Number of Classes: 10\n",
    "# Dimension of path: 200\n",
    "# Length: 22\n",
    "# Train Size, Test Size 25000 25000\n",
    "\n",
    "# Dataset: JapaneseVowels\n",
    "# No dataset found\n",
    "\n",
    "#yes\n",
    "# Dataset: Libras\n",
    "# Number of Classes: 15\n",
    "# Dimension of path: 2\n",
    "# Length: 45\n",
    "# Train Size, Test Size 180 180\n",
    "\n",
    "#TODO I SHOULD INCLUDE\n",
    "# Dataset: LSST\n",
    "# Number of Classes: 14\n",
    "# Dimension of path: 6\n",
    "# Length: 36\n",
    "# Train Size, Test Size 2459 2466\n",
    "\n",
    "#length\n",
    "# Dataset: MotorImagery\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 64\n",
    "# Length: 3000\n",
    "# Train Size, Test Size 278 100\n",
    "\n",
    "#yes\n",
    "# Dataset: NATOPS\n",
    "# Number of Classes: 6\n",
    "# Dimension of path: 24\n",
    "# Length: 51\n",
    "# Train Size, Test Size 180 180\n",
    "\n",
    "#yes\n",
    "# Dataset: PenDigits\n",
    "# Number of Classes: 10\n",
    "# Dimension of path: 2\n",
    "# Length: 8\n",
    "# Train Size, Test Size 7494 3498\n",
    "\n",
    "#TODO SHOULD INCLUDE highDim\n",
    "# Dataset: PEMS-SF\n",
    "# Number of Classes: 7\n",
    "# Dimension of path: 963\n",
    "# Length: 144\n",
    "# Train Size, Test Size 267 173\n",
    "\n",
    "#NO, dim=1, big length, large num classes\n",
    "# Dataset: Phoneme\n",
    "# Number of Classes: 39\n",
    "# Dimension of path: 1\n",
    "# Length: 1024\n",
    "# Train Size, Test Size 214 1896\n",
    "\n",
    "#yes\n",
    "# Dataset: RacketSports\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 6\n",
    "# Length: 30\n",
    "# Train Size, Test Size 151 152\n",
    "\n",
    "#yes\n",
    "# Dataset: SelfRegulationSCP1\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 6\n",
    "# Length: 896\n",
    "# Train Size, Test Size 268 293\n",
    "\n",
    "# Dataset: SelfRegulationSCP2\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 7\n",
    "# Length: 1152\n",
    "# Train Size, Test Size 200 180\n",
    "\n",
    "# Dataset: SpokenArabicDigits\n",
    "# No dataset found\n",
    "\n",
    "#NO, long, also very small set\n",
    "# Dataset: StandWalkJump\n",
    "# Number of Classes: 3\n",
    "# Dimension of path: 4\n",
    "# Length: 2500\n",
    "# Train Size, Test Size 12 15\n",
    "\n",
    "#yes\n",
    "# Dataset: UWaveGestureLibrary\n",
    "# Number of Classes: 8\n",
    "# Dimension of path: 3\n",
    "# Length: 315\n",
    "# Train Size, Test Size 120 320\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cv_tslearn(\n",
    "    dataset_names = [\n",
    "        'Epilepsy',                    # N_corpus = 34      #I should probably further limit this to >100\n",
    "        # 'EthanolConcentration',        # N_corpus = 65\n",
    "        # 'FingerMovements',             # N_corpus = 158\n",
    "        # 'HandMovementDirection',       # N_corpus = 40\n",
    "        # 'Heartbeat',                   # N_corpus = 102\n",
    "        # 'LSST',                        # N_corpus = 176\n",
    "        # 'MotorImagery',                # N_corpus = 139\n",
    "        # 'NATOPS',                      # N_corpus = 30\n",
    "        # 'PenDigits',                   # N_corpus = 749\n",
    "        # 'PEMS-SF',                     # N_corpus = 38\n",
    "        # 'PhonemeSpectra',              # N_corpus = 85\n",
    "        # 'RacketSports',                # N_corpus = 38\n",
    "        # 'SelfRegulationSCP1',          # N_corpus = 134\n",
    "        ],\n",
    "    kernel_names = [\n",
    "        \"linear\",\n",
    "        \"rbf\",\n",
    "        \"poly\",\n",
    "        \"integral rbf\",\n",
    "        \"integral poly\",\n",
    "        \"truncated sig\",\n",
    "        #\"truncated sig rbf\",\n",
    "        #\"signature pde rbf\",\n",
    "        #\"gak\",\n",
    "        ],\n",
    "        k=5,\n",
    "        n_repeats=1,\n",
    "        n_jobs_repeats=1,\n",
    "        n_jobs_gram=1,\n",
    "        verbose=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print CV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_results(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Results             cv_testing.pkl\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 3\n",
    "# Length: 206\n",
    "# Train: 137\n",
    "# Test: N/A\n",
    "\n",
    "# conf_results\n",
    "\n",
    "# linear\n",
    "# final_score_avgs 1.1737691775296382\n",
    "# params_score_avgs [1.174]\n",
    "# thresh_score_avgs [0.795 0.988 0.995 1.009 1.043 1.054 0.979 0.981 0.953 0.941 0.908 0.875\n",
    "#  0.841 0.833 0.794 0.798 0.763 0.717 0.73  0.699 0.694 0.717 0.741 0.625]\n",
    "# EPILEPSY\n",
    "# {'threshold': 2}\n",
    "# RUNNING\n",
    "# {'threshold': 3}\n",
    "# SAWING\n",
    "# {'threshold': 2}\n",
    "# WALKING\n",
    "# {'threshold': 10}\n",
    "\n",
    "# rbf\n",
    "# final_score_avgs 1.4216664612723662\n",
    "# params_score_avgs [1.174 1.174 1.194 1.319 1.317]\n",
    "# thresh_score_avgs [1.024 1.141 1.06  1.111 1.158 1.171 1.144 1.149 1.07  1.041 1.005 1.022\n",
    "#  1.046 1.042 1.024 1.009 0.973 0.992 0.986 0.986 0.97  0.963 1.18  0.826]\n",
    "# EPILEPSY\n",
    "# {'sigma': 0.001, 'threshold': 2}\n",
    "# RUNNING\n",
    "# {'sigma': 1.0, 'threshold': 27}\n",
    "# SAWING\n",
    "# {'sigma': 10.0, 'threshold': 23}\n",
    "# WALKING\n",
    "# {'sigma': 1.0, 'threshold': 10}\n",
    "\n",
    "# poly\n",
    "# final_score_avgs 1.1743328857450155\n",
    "# params_score_avgs [1.17  1.163 1.155 1.158]\n",
    "# thresh_score_avgs [0.849 0.993 1.002 1.012 1.068 1.081 1.012 0.989 0.957 0.94  0.914 0.88\n",
    "#  0.849 0.859 0.824 0.809 0.782 0.746 0.744 0.72  0.698 0.728 0.763 0.614]\n",
    "# EPILEPSY\n",
    "# {'p': 2, 'threshold': 2}\n",
    "# RUNNING\n",
    "# {'p': 2, 'threshold': 3}\n",
    "# SAWING\n",
    "# {'p': 5, 'threshold': 2}\n",
    "# WALKING\n",
    "# {'p': 2, 'threshold': 8}\n",
    "\n",
    "# integral rbf\n",
    "# final_score_avgs 1.3764592979160106\n",
    "# params_score_avgs [1.18  1.18  1.187 1.292 1.248]\n",
    "# thresh_score_avgs [0.981 1.133 1.153 1.116 1.126 1.089 1.078 1.037 1.071 1.038 1.009 0.987\n",
    "#  0.977 0.999 0.997 0.986 0.959 0.931 0.918 0.905 0.898 0.932 1.177 0.766]\n",
    "# EPILEPSY\n",
    "# {'sigma': 0.001, 'threshold': 2}\n",
    "# RUNNING\n",
    "# {'sigma': 1.0, 'threshold': 27}\n",
    "# SAWING\n",
    "# {'sigma': 10.0, 'threshold': 23}\n",
    "# WALKING\n",
    "# {'sigma': 1.0, 'threshold': 13}\n",
    "\n",
    "# integral poly\n",
    "# final_score_avgs 1.325727324660064\n",
    "# params_score_avgs [1.284 1.259 1.224 1.163]\n",
    "# thresh_score_avgs [1.042 1.175 1.236 1.21  1.149 1.114 1.053 1.032 1.015 0.996 1.022 1.012\n",
    "#  1.018 0.977 0.962 0.958 0.961 0.963 0.939 0.912 0.908 0.979 1.076 0.782]\n",
    "# EPILEPSY\n",
    "# {'p': 3, 'threshold': 2}\n",
    "# RUNNING\n",
    "# {'p': 2, 'threshold': 3}\n",
    "# SAWING\n",
    "# {'p': 3, 'threshold': 4}\n",
    "# WALKING\n",
    "# {'p': 2, 'threshold': 18}\n",
    "\n",
    "# truncated sig\n",
    "# final_score_avgs 1.3093519407707075\n",
    "# params_score_avgs [1.309]\n",
    "# thresh_score_avgs [1.074 1.06  1.063 0.972 1.087 1.076 1.055 1.049 1.041 1.059 1.046 1.087\n",
    "#  1.088 1.046 1.123 0.983 0.971 0.986 0.979 0.976 0.989 0.998 0.99  0.712]\n",
    "# orders_score_avgs [0.95  1.278 1.194 1.087 1.035 1.074 1.026 1.056 1.068 1.053]\n",
    "# EPILEPSY\n",
    "# {'threshold': 15, 'order': 2}\n",
    "# RUNNING\n",
    "# {'threshold': 2, 'order': 1}\n",
    "# SAWING\n",
    "# {'threshold': 13, 'order': 2}\n",
    "# WALKING\n",
    "# {'threshold': 16, 'order': 8}\n",
    "\n",
    "# mahal_results\n",
    "\n",
    "# linear\n",
    "# final_score_avgs 1.0177805635643282\n",
    "# params_score_avgs [1.018]\n",
    "# thresh_score_avgs [0.708 0.931 0.96  0.93  0.908 0.858 0.81  0.769 0.735 0.711 0.685 0.675\n",
    "#  0.659 0.644 0.637 0.627 0.612 0.609 0.603 0.594 0.587 0.562 0.59  0.472]\n",
    "# EPILEPSY\n",
    "# {'threshold': 3}\n",
    "# RUNNING\n",
    "# {'threshold': 1}\n",
    "# SAWING\n",
    "# {'threshold': 2}\n",
    "# WALKING\n",
    "# {'threshold': 28}\n",
    "\n",
    "# rbf\n",
    "# final_score_avgs 1.2733981379422619\n",
    "# params_score_avgs [1.018 1.011 1.008 0.964 0.992]\n",
    "# thresh_score_avgs [0.986 1.186 1.194 1.175 1.169 1.128 1.093 1.056 1.039 1.039 1.028 1.024\n",
    "#  1.02  1.016 1.019 1.017 1.007 0.999 0.992 0.972 0.989 0.954 0.95  0.835]\n",
    "# EPILEPSY\n",
    "# {'sigma': 0.001, 'threshold': 3}\n",
    "# RUNNING\n",
    "# {'sigma': 10.0, 'threshold': 24}\n",
    "# SAWING\n",
    "# {'sigma': 0.001, 'threshold': 2}\n",
    "# WALKING\n",
    "# {'sigma': 0.001, 'threshold': 28}\n",
    "\n",
    "# poly\n",
    "# final_score_avgs 1.0456643672986525\n",
    "# params_score_avgs [1.028 1.028 1.034 1.045]\n",
    "# thresh_score_avgs [0.716 0.939 0.968 0.94  0.921 0.872 0.818 0.771 0.746 0.726 0.701 0.677\n",
    "#  0.665 0.644 0.651 0.642 0.62  0.621 0.616 0.609 0.585 0.598 0.619 0.49 ]\n",
    "# EPILEPSY\n",
    "# {'p': 2, 'threshold': 3}\n",
    "# RUNNING\n",
    "# {'p': 5, 'threshold': 1}\n",
    "# SAWING\n",
    "# {'p': 5, 'threshold': 2}\n",
    "# WALKING\n",
    "# {'p': 5, 'threshold': 27}\n",
    "\n",
    "# integral rbf\n",
    "# final_score_avgs 1.2395262664840416\n",
    "# params_score_avgs [1.015 1.008 1.008 0.937 0.811]\n",
    "# thresh_score_avgs [0.848 1.14  1.197 1.187 1.175 1.136 1.095 1.039 1.02  0.999 0.959 0.951\n",
    "#  0.955 0.933 0.937 0.936 0.92  0.906 0.907 0.904 0.917 0.894 0.908 0.777]\n",
    "# EPILEPSY\n",
    "# {'sigma': 0.001, 'threshold': 3}\n",
    "# RUNNING\n",
    "# {'sigma': 10.0, 'threshold': 4}\n",
    "# SAWING\n",
    "# {'sigma': 0.001, 'threshold': 2}\n",
    "# WALKING\n",
    "# {'sigma': 0.001, 'threshold': 28}\n",
    "\n",
    "# integral poly\n",
    "# final_score_avgs 0.9708220351081185\n",
    "# params_score_avgs [0.971 0.913 0.891 0.886]\n",
    "# thresh_score_avgs [0.847 0.906 0.887 0.885 0.896 0.872 0.868 0.843 0.848 0.826 0.813 0.8\n",
    "#  0.804 0.794 0.778 0.744 0.755 0.746 0.732 0.727 0.712 0.722 0.747 0.559]\n",
    "# EPILEPSY\n",
    "# {'p': 2, 'threshold': 6}\n",
    "# RUNNING\n",
    "# {'p': 2, 'threshold': 1}\n",
    "# SAWING\n",
    "# {'p': 2, 'threshold': 2}\n",
    "# WALKING\n",
    "# {'p': 2, 'threshold': 27}\n",
    "\n",
    "# truncated sig\n",
    "# final_score_avgs 1.4164783869986826\n",
    "# params_score_avgs [1.416]\n",
    "# thresh_score_avgs [1.219 1.228 1.245 1.142 1.067 1.069 1.028 0.985 0.967 0.966 0.984 0.979\n",
    "#  1.033 0.965 0.988 0.918 0.908 0.929 0.938 0.942 0.963 0.968 0.975 0.712]\n",
    "# orders_score_avgs [0.933 1.067 1.03  1.279 1.176 1.151 1.103 1.246 1.186 1.214]\n",
    "# EPILEPSY\n",
    "# {'threshold': 15, 'order': 2}\n",
    "# RUNNING\n",
    "# {'threshold': 1, 'order': 8}\n",
    "# SAWING\n",
    "# {'threshold': 3, 'order': 6}\n",
    "# WALKING\n",
    "# {'threshold': 28, 'order': 3}\n",
    "\n",
    "# End dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from experiments.utils import save_to_pickle\n",
    "# save_to_pickle(cv_results, \"cv_testing.pkl\")\n",
    "\n",
    "\n",
    "from experiments.utils import load_from_pickle\n",
    "cv_results = load_from_pickle(\"Data/cv_Epilepsy.pkl\")\n",
    "#cv_results = load_from_pickle(\"cv_testing.pkl\")\n",
    "del cv_results[\"Epilepsy\"][\"conf_results\"][\"gak\"]\n",
    "del cv_results[\"Epilepsy\"][\"conf_results\"][\"truncated sig rbf\"]\n",
    "del cv_results[\"Epilepsy\"][\"conf_results\"][\"signature pde rbf\"]\n",
    "del cv_results[\"Epilepsy\"][\"mahal_results\"][\"gak\"]\n",
    "del cv_results[\"Epilepsy\"][\"mahal_results\"][\"truncated sig rbf\"]\n",
    "del cv_results[\"Epilepsy\"][\"mahal_results\"][\"signature pde rbf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = validate_tslearn(cv_results, n_jobs=4, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_results(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Results       of cv_Epilepsy.pkl  ---- WRONG????\n",
    "\n",
    "# Dataset: Epilepsy\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 3\n",
    "# Length: 206\n",
    "# Train: 137\n",
    "# Test: 138\n",
    "\n",
    "# Kernel: linear\n",
    "# Conformance AUC: 0.605\n",
    "# Conformance PR AUC: 0.388\n",
    "\n",
    "# Kernel: rbf\n",
    "# Conformance AUC: 0.622\n",
    "# Conformance PR AUC: 0.411\n",
    "\n",
    "# Kernel: poly\n",
    "# Conformance AUC: 0.621\n",
    "# Conformance PR AUC: 0.398\n",
    "\n",
    "# Kernel: truncated sig\n",
    "# Conformance AUC: 0.626\n",
    "# Conformance PR AUC: 0.367\n",
    "\n",
    "# Kernel: integral rbf\n",
    "# Conformance AUC: 0.628\n",
    "# Conformance PR AUC: 0.428\n",
    "\n",
    "# Kernel: integral poly\n",
    "# Conformance AUC: 0.651\n",
    "# Conformance PR AUC: 0.412\n",
    "\n",
    "# Kernel: linear\n",
    "# Mahalanobis AUC: 0.465\n",
    "# Mahalanobis PR AUC: 0.307\n",
    "\n",
    "# Kernel: rbf\n",
    "# Mahalanobis AUC: 0.588\n",
    "# Mahalanobis PR AUC: 0.368\n",
    "\n",
    "# Kernel: poly\n",
    "# Mahalanobis AUC: 0.423\n",
    "# Mahalanobis PR AUC: 0.275\n",
    "\n",
    "# Kernel: truncated sig\n",
    "# Mahalanobis AUC: 0.651\n",
    "# Mahalanobis PR AUC: 0.421\n",
    "\n",
    "# Kernel: integral rbf\n",
    "# Mahalanobis AUC: 0.576\n",
    "# Mahalanobis PR AUC: 0.342\n",
    "\n",
    "# Kernel: integral poly\n",
    "# Mahalanobis AUC: 0.464\n",
    "# Mahalanobis PR AUC: 0.281\n",
    "\n",
    "# End Dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Results   first pool, then z\n",
    "\n",
    "# Dataset: Epilepsy\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 3\n",
    "# Length: 206\n",
    "# Train: 137\n",
    "# Test: 138\n",
    "\n",
    "# Kernel: linear\n",
    "# Conformance AUC: 0.618\n",
    "# Conformance PR AUC: 0.425\n",
    "\n",
    "# Kernel: rbf\n",
    "# Conformance AUC: 0.612\n",
    "# Conformance PR AUC: 0.439\n",
    "\n",
    "# Kernel: poly\n",
    "# Conformance AUC: 0.67\n",
    "# Conformance PR AUC: 0.468\n",
    "\n",
    "# Kernel: integral rbf\n",
    "# Conformance AUC: 0.526\n",
    "# Conformance PR AUC: 0.371\n",
    "\n",
    "# Kernel: integral poly\n",
    "# Conformance AUC: 0.687\n",
    "# Conformance PR AUC: 0.423\n",
    "\n",
    "# Kernel: truncated sig\n",
    "# Conformance AUC: 0.628\n",
    "# Conformance PR AUC: 0.368\n",
    "\n",
    "# Kernel: linear\n",
    "# Mahalanobis AUC: 0.516\n",
    "# Mahalanobis PR AUC: 0.341\n",
    "\n",
    "# Kernel: rbf\n",
    "# Mahalanobis AUC: 0.712\n",
    "# Mahalanobis PR AUC: 0.47\n",
    "\n",
    "# Kernel: poly\n",
    "# Mahalanobis AUC: 0.51\n",
    "# Mahalanobis PR AUC: 0.324\n",
    "\n",
    "# Kernel: integral rbf\n",
    "# Mahalanobis AUC: 0.692\n",
    "# Mahalanobis PR AUC: 0.449\n",
    "\n",
    "# Kernel: integral poly\n",
    "# Mahalanobis AUC: 0.503\n",
    "# Mahalanobis PR AUC: 0.284\n",
    "\n",
    "# Kernel: truncated sig\n",
    "# Mahalanobis AUC: 0.712\n",
    "# Mahalanobis PR AUC: 0.519\n",
    "\n",
    "# End Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Results    first pool, then z, then time augment\n",
    "\n",
    "# Dataset: Epilepsy\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 3\n",
    "# Length: 206\n",
    "# Train: 137\n",
    "# Test: 138\n",
    "\n",
    "# Kernel: linear\n",
    "# Conformance AUC: 0.566\n",
    "# Conformance PR AUC: 0.364\n",
    "\n",
    "# Kernel: rbf\n",
    "# Conformance AUC: 0.487\n",
    "# Conformance PR AUC: 0.341\n",
    "\n",
    "# Kernel: poly\n",
    "# Conformance AUC: 0.579\n",
    "# Conformance PR AUC: 0.374\n",
    "\n",
    "# Kernel: integral rbf\n",
    "# Conformance AUC: 0.469\n",
    "# Conformance PR AUC: 0.334\n",
    "\n",
    "# Kernel: integral poly\n",
    "# Conformance AUC: 0.697\n",
    "# Conformance PR AUC: 0.49\n",
    "\n",
    "# Kernel: truncated sig\n",
    "# Conformance AUC: 0.703\n",
    "# Conformance PR AUC: 0.45\n",
    "\n",
    "# Kernel: linear\n",
    "# Mahalanobis AUC: 0.496\n",
    "# Mahalanobis PR AUC: 0.314\n",
    "\n",
    "# Kernel: rbf\n",
    "# Mahalanobis AUC: 0.689\n",
    "# Mahalanobis PR AUC: 0.431\n",
    "\n",
    "# Kernel: poly\n",
    "# Mahalanobis AUC: 0.502\n",
    "# Mahalanobis PR AUC: 0.317\n",
    "\n",
    "# Kernel: integral rbf\n",
    "# Mahalanobis AUC: 0.682\n",
    "# Mahalanobis PR AUC: 0.426\n",
    "\n",
    "# Kernel: integral poly\n",
    "# Mahalanobis AUC: 0.518\n",
    "# Mahalanobis PR AUC: 0.316\n",
    "\n",
    "# Kernel: truncated sig\n",
    "# Mahalanobis AUC: 0.696\n",
    "# Mahalanobis PR AUC: 0.516\n",
    "\n",
    "# End Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CV data from file and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cross validation results\n",
    "cv_results = join_dicts_from_pickle_paths(\n",
    "    [\n",
    "    \"Data/cv_Epilepsy.pkl\",\n",
    "    #\"Data/cv_EthanolConcentration.pkl\",\n",
    "    #\"Data/cv_FingerMovements.pkl\",\n",
    "    #\"Data/cv_HandMovementDirection.pkl\",\n",
    "    #\"Data/cv_Heartbeat.pkl\",\n",
    "    #\"Data/cv_LSST.pkl\",\n",
    "    #\"Data/cv_MotorImagery.pkl\",\n",
    "    #\"Data/cv_NATOPS.pkl\",\n",
    "    #\"Data/cv_PEMS-SF.pkl\",\n",
    "    #\"Data/cv_PenDigits.pkl\",\n",
    "    #\"Data/cv_PhonemeSpectra.pkl\",\n",
    "    #\"Data/cv_RacketSports.pkl\",\n",
    "    #\"Data/cv_SelfRegulationSCP1.pkl\",\n",
    "    ])\n",
    "print_cv_results(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.experiment_code import print_dataset_stats\n",
    "from experiments.utils import print_latex_results, join_dicts_from_pickle_paths\n",
    "\n",
    "# test_results = join_dicts_from_pickle_paths([\n",
    "#                                 \"Data/results_shorts.pkl\",\n",
    "#                                 \"Data/results_longs.pkl\",\n",
    "#                                              ])\n",
    "\n",
    "test_results = {d:k for d,k in test_results.items() \n",
    "                # if d in [\"EthanolConcentration\",  #datasets with corpus size > 50\n",
    "                #         \"FingerMovements\",\n",
    "                #         \"Heartbeat\",\n",
    "                #         \"LSST\",\n",
    "                #         \"MotorImagery\",\n",
    "                #         \"PenDigits\",\n",
    "                #         \"PhonemeSpectra\",\n",
    "                #         \"SelfRegulationSCP1\",]\n",
    "                }\n",
    "print_latex_results(test_results, 2)\n",
    "print_latex_results(test_results, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
