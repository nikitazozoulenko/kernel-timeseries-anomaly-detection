{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Optional, Dict, Set, Callable, Any, Literal\n",
    "from joblib import Memory, Parallel, delayed\n",
    "import tslearn\n",
    "import tslearn.metrics\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from experiments.cross_validation import cv_tslearn, print_cv_results\n",
    "from experiments.eval_on_test import validate_tslearn, print_test_results\n",
    "from experiments.utils import join_dicts_from_pickle_paths, save_to_pickle, print_latex_results\n",
    "from experiments.experiment_code import run_all_kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cv_tslearn(\n",
    "    dataset_names = [\n",
    "        'Epilepsy',                    # N_corpus = 34\n",
    "        # 'EthanolConcentration',        # N_corpus = 65\n",
    "        # 'FingerMovements',             # N_corpus = 158\n",
    "        # 'HandMovementDirection',       # N_corpus = 40\n",
    "        # 'Heartbeat',                   # N_corpus = 102\n",
    "        # 'LSST',                        # N_corpus = 176\n",
    "        # 'MotorImagery',                # N_corpus = 139\n",
    "        # 'NATOPS',                      # N_corpus = 30\n",
    "        # 'PenDigits',                   # N_corpus = 749\n",
    "        # 'PEMS-SF',                     # N_corpus = 38\n",
    "        # 'PhonemeSpectra',              # N_corpus = 85\n",
    "        # 'RacketSports',                # N_corpus = 38\n",
    "        # 'SelfRegulationSCP1',          # N_corpus = 134\n",
    "        ],\n",
    "    kernel_names = [\n",
    "            #\"flat linear\",\n",
    "            #\"flat rbf\",\n",
    "            # \"flat poly\",\n",
    "            # \"integral rbf\",\n",
    "            # \"integral poly\",\n",
    "            # \"trunc sig linear\",\n",
    "            # \"trunc sig rbf\",\n",
    "            # \"pde sig rbf\",\n",
    "            \"gak\",\n",
    "            # \"reservoir\",\n",
    "        ],\n",
    "        k_folds=5,\n",
    "        n_repeats=1,\n",
    "        verbose=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_results(cv_results)\n",
    "save_to_pickle(cv_results, \"Data/cv_dummy.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = validate_tslearn(cv_results, verbose=False, device=\"cuda\")\n",
    "print_test_results(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate on Test and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name, cv_res in cv_results.items():\n",
    "    if dataset_name == \"Epilepsy\":\n",
    "        test_results = validate_tslearn({dataset_name : cv_res}, verbose=True, device=\"cuda\")\n",
    "        save_to_pickle(test_results, f\"Data/results_{dataset_name}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CV data from file and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cross validation results\n",
    "cv_results = join_dicts_from_pickle_paths(\n",
    "    [\n",
    "    \"Data/cv_Epilepsy.pkl\",\n",
    "    \"Data/cv_EthanolConcentration.pkl\",\n",
    "    \"Data/cv_FingerMovements.pkl\",\n",
    "    \"Data/cv_HandMovementDirection.pkl\",\n",
    "    \"Data/cv_Heartbeat.pkl\",\n",
    "    \"Data/cv_LSST.pkl\",\n",
    "    \"Data/cv_MotorImagery.pkl\",\n",
    "    \"Data/cv_NATOPS.pkl\",\n",
    "    \"Data/cv_PEMS-SF.pkl\",\n",
    "    # \"Data/cv_PhonemeSpectra.pkl\",\n",
    "    \"Data/cv_RacketSports.pkl\",\n",
    "    \"Data/cv_SelfRegulationSCP1.pkl\",\n",
    "    \"Data/cv_SelfRegulationSCP2.pkl\",\n",
    "    ])\n",
    "print_cv_results(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = join_dicts_from_pickle_paths([\n",
    "    \"Data/results_Epilepsy.pkl\",\n",
    "    \"Data/results_EthanolConcentration.pkl\",\n",
    "    \"Data/results_FingerMovements.pkl\",\n",
    "    \"Data/results_HandMovementDirection.pkl\",\n",
    "    \"Data/results_Heartbeat.pkl\",\n",
    "    \"Data/results_LSST.pkl\",\n",
    "    \"Data/results_MotorImagery.pkl\",\n",
    "    \"Data/results_NATOPS.pkl\",\n",
    "    \"Data/results_PEMS-SF.pkl\",\n",
    "    # \"Data/results_PhonemeSpectra.pkl\",\n",
    "    \"Data/results_RacketSports.pkl\",\n",
    "    \"Data/results_SelfRegulationSCP1.pkl\",\n",
    "    \"Data/results_SelfRegulationSCP2.pkl\",\n",
    "                                             ])\n",
    "print_latex_results(test_results, round_digits=2)\n",
    "print_latex_results(test_results, round_digits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerate all UCR UEA datasets in 'tslearn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCR_UEA_datasets = UCR_UEA_datasets()\n",
    "\n",
    "for dataset_name in UCR_UEA_datasets.list_multivariate_datasets():\n",
    "#for dataset_name in _datasets:\n",
    "    print(\"Dataset:\", dataset_name)\n",
    "    dataset = UCR_UEA_datasets.load_dataset(dataset_name)\n",
    "    if dataset[0] is not None:\n",
    "        X_train, y_train, X_test, y_test = dataset\n",
    "        num_classes = len(np.unique(y_train))\n",
    "        N_train, T, d = X_train.shape\n",
    "        N_test, _, _  = X_test.shape\n",
    "        \n",
    "        print(\"Number of Classes:\", num_classes)\n",
    "        print(\"Dimension of path:\", d)\n",
    "        print(\"Length:\", T)\n",
    "        print(\"Train Size, Test Size\", N_train, N_test)\n",
    "        print()\n",
    "    else:\n",
    "        print(\"No dataset found\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print distribution of CV params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_datasets = [\n",
    "    \"Epilepsy\",\n",
    "    \"EthanolConcentration\",\n",
    "    \"FingerMovements\",\n",
    "    \"HandMovementDirection\",\n",
    "    \"Heartbeat\",\n",
    "    \"LSST\",\n",
    "    \"MotorImagery\",\n",
    "    \"NATOPS\",\n",
    "    \"PEMS-SF\",\n",
    "    \"PhonemeSpectra\",\n",
    "    \"RacketSports\",\n",
    "    \"SelfRegulationSCP1\",\n",
    "    \"SelfRegulationSCP2\",\n",
    "    ]\n",
    "\n",
    "all_kernels = [\n",
    "    \"flat linear\",\n",
    "    \"flat rbf\",\n",
    "    \"flat poly\",\n",
    "    \"integral rbf\",\n",
    "    \"integral poly\",\n",
    "    \"trunc sig linear\",\n",
    "    \"trunc sig rbf\",\n",
    "    \"pde sig rbf\",\n",
    "    \"gak\",\n",
    "    \"reservoir\",\n",
    "    ]\n",
    "\n",
    "\n",
    "def plot_cv_params_single_kernel(\n",
    "        cv_results:Dict,\n",
    "        param_name:str = \"sigma\", \n",
    "        kernel_name:str = \"flat rbf\", \n",
    "        datasets:Optional[List[str]] = None, \n",
    "        n_bins:int = 30,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    For each dataset, plot the histogram of the best parameter\n",
    "    values specified by 'param_name' for the kerenl \"kernel_name\".\n",
    "    \"\"\"\n",
    "    if datasets is None:\n",
    "        datasets = list(cv_results.keys())\n",
    "\n",
    "    l = []\n",
    "    for dataset_name, results in cv_results.items():\n",
    "        for anomaly_method in [\"conf_results\", \"mahal_results\"]:\n",
    "            kernelwise_dict = results[anomaly_method]\n",
    "            for ker, labelwise_dict in kernelwise_dict.items():\n",
    "                for label, param_dict in labelwise_dict.items():\n",
    "                    if ker == kernel_name:\n",
    "                        l.append(param_dict[param_name])\n",
    "    l = np.array(l)\n",
    "    l.sort()\n",
    "    l = l.astype(str)\n",
    "\n",
    "    plt.hist(l, n_bins)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"Kernel: {kernel_name}\")\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_cv_params_all_kernels(\n",
    "        cv_results:Dict,\n",
    "        param_name:str = \"sigma\",\n",
    "        kernels:Optional[List[str]] = None, \n",
    "        datasets:Optional[List[str]] = None,\n",
    "        n_bins:int = 30,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    For each dataset, plot the histogram of the best parameter\n",
    "    values specified by 'param_name' for all the kernels.\n",
    "    \"\"\"\n",
    "    if datasets is None:\n",
    "        datasets = list(cv_results.keys())\n",
    "    if kernels is None:\n",
    "        kernels = list(cv_results[datasets[0]][\"conf_results\"].keys())\n",
    "\n",
    "    l = []\n",
    "    for dataset_name, results in cv_results.items():\n",
    "        for anomaly_method in [\"conf_results\", \"mahal_results\"]:\n",
    "            kernelwise_dict = results[anomaly_method]\n",
    "            for kernel_name, labelwise_dict in kernelwise_dict.items():\n",
    "                for label, param_dict in labelwise_dict.items():\n",
    "                    if kernel_name == kernel_name:\n",
    "                        if param_name in param_dict:\n",
    "                            l.append(param_dict[param_name])\n",
    "    l = np.array(l)\n",
    "    l.sort()\n",
    "    l = l.astype(str)\n",
    "\n",
    "    plt.hist(l, n_bins)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"All datasets: {param_name}\")\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv_params_all_kernels(cv_results, \"alpha\", kernels=[\"trunc sig pde\"])\n",
    "plot_cv_params_all_kernels(cv_results, \"threshold\",kernels=[\"trunc sig pde\"])\n",
    "plot_cv_params_all_kernels(cv_results, \"normalize\",kernels=[\"trunc sig pde\"])\n",
    "plot_cv_params_all_kernels(cv_results, \"time\",kernels=[\"trunc sig pde\"])\n",
    "plot_cv_params_all_kernels(cv_results, \"basepoint\",kernels=[\"trunc sig pde\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv_params_single_kernel(cv_results, \"scale\", \"trunc sig linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run specific param_dict on specific dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Dict\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "from experiments.experiment_code import run_all_kernels\n",
    "import numpy as np\n",
    "def run_specific_param_dict(\n",
    "        dataset_name:str, \n",
    "        param_dict:Dict,\n",
    "        verbose:bool = False,\n",
    "        device=\"cuda\",\n",
    "    ):    \n",
    "    \"\"\"Runs the specific param_dict on a dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset_name (str): Name of the dataset.\n",
    "        param_dict (Dict): Dictionary of parameters.\n",
    "        verbose (bool): Verbosity.\n",
    "        device (str): Device for PyTorch computation.\n",
    "        \"\"\"\n",
    "    X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(dataset_name)\n",
    "    X_train = torch.from_numpy(X_train).to(device)\n",
    "    X_test = torch.from_numpy(X_test).to(device)\n",
    "    unique_labels = np.unique(y_train)\n",
    "    kernel_name = param_dict[\"kernel_name\"]\n",
    "\n",
    "    #create kernelwise dict\n",
    "    kernelwise_dict = {kernel_name: {label: param_dict for label in unique_labels}}\n",
    "\n",
    "    results = run_all_kernels(X_train, y_train, X_test, y_test, \n",
    "                        unique_labels, kernelwise_dict, verbose)\n",
    "    aucs = results[kernel_name]\n",
    "    print(\"Conf ROCAUC\\t\", aucs[0,0])\n",
    "    print(\"Conf PRAUC\\t\", aucs[0,1])\n",
    "    print(\"Mah ROCAUC\\t\", aucs[1,0])\n",
    "    print(\"Mah PRAUC\\t\", aucs[1,1])\n",
    "    return results\n",
    "\n",
    "\n",
    "# General Parameters\n",
    "param_dict = {\n",
    "    \"alpha\": 0.00000000001,\n",
    "    \"threshold\": 5,\n",
    "    \"normalize\": True,\n",
    "    \"time\": \"\",\n",
    "    \"basepoint\": \"\",\n",
    "}\n",
    "\n",
    "\n",
    "# Kernel Specific Parameters\n",
    "param_dict[\"kernel_name\"] = \"gak\"\n",
    "param_dict[\"order\"] = 5\n",
    "param_dict[\"sigma\"] = 1.4\n",
    "param_dict[\"scale\"] = 0.5\n",
    "param_dict[\"gak_factor\"] = 16\n",
    "param_dict[\"dyadic_order\"] = 3\n",
    "param_dict[\"gamma\"] = 0.9999999\n",
    "param_dict[\"tau\"] = 1/5.5/np.sqrt(10)\n",
    "\n",
    "\n",
    "res = run_specific_param_dict(\"Epilepsy\", param_dict, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
