{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import sklearn.utils\n",
    "import sklearn.metrics\n",
    "import iisignature\n",
    "import torch\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import List, Optional, Dict, Set, Callable, Any\n",
    "from joblib import Memory, Parallel, delayed\n",
    "import tslearn\n",
    "import tslearn.metrics\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "import sigkernel\n",
    "import scipy\n",
    "from scipy.interpolate import interp1d\n",
    "from numba import njit\n",
    "import pickle\n",
    "\n",
    "from signature import streams_to_sigs, transform_stream\n",
    "from conformance import BaseclassConformanceScore, stream_to_torch\n",
    "from kernels import linear_kernel_gram, rbf_kernel_gram, poly_kernel_gram\n",
    "from kernels import pairwise_kernel_gram, integral_kernel_gram, sig_kernel_gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tslearn datasets (equal length)\n",
    "\n",
    "* equal length (in time) UCR_UEA multivariate time series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #run experiments\n",
    "\n",
    "# experiments = run_tslearn_experiments(\n",
    "#     dataset_names = [\n",
    "#         #'ArticularyWordRecognition', \n",
    "#         #'BasicMotions', \n",
    "#         #'Cricket',\n",
    "#          ##########'ERing', #cant find dataset\n",
    "#         'Libras', \n",
    "#         #'NATOPS', \n",
    "#         #'RacketSports',     \n",
    "#         #'FingerMovements',\n",
    "#         #'Heartbeat',\n",
    "#         #'SelfRegulationSCP1', \n",
    "#         #'UWaveGestureLibrary'\n",
    "#         ],\n",
    "#     kernel_names = [\n",
    "#         \"linear\",\n",
    "#         #\"rbf\",\n",
    "#         #\"poly\",\n",
    "#         #\"gak\",\n",
    "#         #\"truncated sig\",\n",
    "#         #\"truncated sig rbf\",\n",
    "#         #\"truncated sig poly\",\n",
    "#         #\"signature pde\",\n",
    "#         #\"signature pde rbf\",\n",
    "#         #\"signature pde poly\",\n",
    "#         #\"integral linear\",\n",
    "#         #\"integral rbf\",\n",
    "#         #\"integral poly\",\n",
    "#         ],\n",
    "#         verbose=True\n",
    "#         )\n",
    "\n",
    "\n",
    "# def print_experiment_results(experiments, round_digits=5):\n",
    "#     for dataset_name, results in experiments.items():\n",
    "#         #Dataset:\n",
    "#         print(\"\\nStart Dataset {dataset_name} results:\", dataset_name)\n",
    "#         print_dataset_stats(results[\"num_classes\"], results[\"dim\"], \n",
    "#                             results[\"ts_length\"], results[\"N_train\"], \n",
    "#                             results[\"N_test\"])\n",
    "\n",
    "#         #Results for each kernel:\n",
    "#         for kernel_name, scores in results[\"results\"].items():\n",
    "#             print(\"\\nKernel:\", kernel_name)\n",
    "#             scores = np.mean(scores, axis=2)\n",
    "#             print(\"Conformance AUC:\", round(scores[0, 0], round_digits))\n",
    "#             print(\"Mahalanobis AUC:\", round(scores[1, 0], round_digits))\n",
    "#             print(\"Conformance PR AUC:\", round(scores[0, 1], round_digits))\n",
    "#             print(\"Mahalanobis PR AUC:\", round(scores[1, 1], round_digits))\n",
    "\n",
    "#         print(\"\\nEnd Dataset {dataset_name} results\\n\\n\\n\")\n",
    "        \n",
    "# print_experiment_results(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comments\n",
    "\n",
    "# Kernel: truncated sig\n",
    "# Conformance AUC: 0.90757\n",
    "# Mahalanobis AUC: 0.90728\n",
    "# Conformance PR AUC: 0.99236\n",
    "# Mahalanobis PR AUC: 0.99235\n",
    "\n",
    "# Kernel: linear\n",
    "# Conformance AUC: 0.94646\n",
    "# Mahalanobis AUC: 0.93737\n",
    "# Conformance PR AUC: 0.99506\n",
    "# Mahalanobis PR AUC: 0.99445\n",
    "\n",
    "# Kernel: rbf\n",
    "# Conformance AUC: 0.7671\n",
    "# Mahalanobis AUC: 0.08571\n",
    "# Conformance PR AUC: 0.95905\n",
    "# Mahalanobis PR AUC: 0.84199\n",
    "\n",
    "# Kernel: integral linear\n",
    "# Conformance AUC: 0.94686\n",
    "# Mahalanobis AUC: 0.93849\n",
    "# Conformance PR AUC: 0.99512\n",
    "# Mahalanobis PR AUC: 0.99451\n",
    "\n",
    "# End Dataset {dataset_name} results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all tslearn datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _datasets = [\n",
    "#             'ArticularyWordRecognition', \n",
    "#             'BasicMotions', \n",
    "#             'Cricket',\n",
    "#             #'ERing',\n",
    "#             'Libras', \n",
    "#             'NATOPS', \n",
    "#             'RacketSports',     \n",
    "#             'FingerMovements',\n",
    "#             'Heartbeat',\n",
    "#             'SelfRegulationSCP1', \n",
    "#             'UWaveGestureLibrary'\n",
    "#             ]\n",
    "\n",
    "# import tslearn\n",
    "# UCR_UEA_datasets = tslearn.datasets.UCR_UEA_datasets()\n",
    "\n",
    "# for dataset_name in UCR_UEA_datasets.list_multivariate_datasets():\n",
    "# #for dataset_name in _datasets:\n",
    "#     print(\"Dataset:\", dataset_name)\n",
    "#     dataset = UCR_UEA_datasets.load_dataset(dataset_name)\n",
    "#     if dataset[0] is not None:\n",
    "#         X_train, y_train, X_test, y_test = dataset\n",
    "#         num_classes = len(np.unique(y_train))\n",
    "#         N_train, T, d = X_train.shape\n",
    "#         N_test, _, _  = X_test.shape\n",
    "        \n",
    "#         print(\"Number of Classes:\", num_classes)\n",
    "#         print(\"Dimension of path:\", d)\n",
    "#         print(\"Length:\", T)\n",
    "#         print(\"Train Size, Test Size\", N_train, N_test)\n",
    "#         print()\n",
    "#     else:\n",
    "#         print(\"No dataset found\")\n",
    "#         print()\n",
    "\n",
    "#yes\n",
    "# Dataset: ArticularyWordRecognition\n",
    "# Number of Classes: 25\n",
    "# Dimension of path: 9\n",
    "# Length: 144\n",
    "# Train Size, Test Size 275 300\n",
    "\n",
    "# Dataset: AtrialFibrillation\n",
    "# No dataset found\n",
    "\n",
    "#yes\n",
    "# Dataset: BasicMotions\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 6\n",
    "# Length: 100\n",
    "# Train Size, Test Size 40 40\n",
    "\n",
    "# Dataset: CharacterTrajectories\n",
    "# No dataset found\n",
    "\n",
    "#yes\n",
    "# Dataset: Cricket\n",
    "# Number of Classes: 12\n",
    "# Dimension of path: 6\n",
    "# Length: 1197\n",
    "# Train Size, Test Size 108 72\n",
    "\n",
    "# Dataset: DuckDuckGeese\n",
    "# No dataset found\n",
    "\n",
    "# Dataset: EigenWorms\n",
    "# Number of Classes: 5\n",
    "# Dimension of path: 6\n",
    "# Length: 17984\n",
    "# Train Size, Test Size 128 131\n",
    "\n",
    "#why not\n",
    "# Dataset: Epilepsy\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 3\n",
    "# Length: 206\n",
    "# Train Size, Test Size 137 138\n",
    "\n",
    "#longLength\n",
    "# Dataset: EthanolConcentration\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 3\n",
    "# Length: 1751\n",
    "# Train Size, Test Size 261 263\n",
    "\n",
    "# Dataset: ERing\n",
    "# No dataset found\n",
    "\n",
    "#big\n",
    "# Dataset: FaceDetection\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 144\n",
    "# Length: 62\n",
    "# Train Size, Test Size 5890 3524\n",
    "\n",
    "#yes\n",
    "# Dataset: FingerMovements\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 28\n",
    "# Length: 50\n",
    "# Train Size, Test Size 316 100\n",
    "\n",
    "#why not, maybe big length\n",
    "# Dataset: HandMovementDirection\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 10\n",
    "# Length: 400\n",
    "# Train Size, Test Size 160 74\n",
    "\n",
    "#smallTrain\n",
    "# Dataset: Handwriting\n",
    "# Number of Classes: 26\n",
    "# Dimension of path: 3\n",
    "# Length: 152\n",
    "# Train Size, Test Size 150 850\n",
    "\n",
    "#yes\n",
    "# Dataset: Heartbeat\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 61\n",
    "# Length: 405\n",
    "# Train Size, Test Size 204 205\n",
    "\n",
    "#big\n",
    "# Dataset: InsectWingbeat\n",
    "# Number of Classes: 10\n",
    "# Dimension of path: 200\n",
    "# Length: 22\n",
    "# Train Size, Test Size 25000 25000\n",
    "\n",
    "# Dataset: JapaneseVowels\n",
    "# No dataset found\n",
    "\n",
    "#yes\n",
    "# Dataset: Libras\n",
    "# Number of Classes: 15\n",
    "# Dimension of path: 2\n",
    "# Length: 45\n",
    "# Train Size, Test Size 180 180\n",
    "\n",
    "#TODO I SHOULD INCLUDE\n",
    "# Dataset: LSST\n",
    "# Number of Classes: 14\n",
    "# Dimension of path: 6\n",
    "# Length: 36\n",
    "# Train Size, Test Size 2459 2466\n",
    "\n",
    "#length\n",
    "# Dataset: MotorImagery\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 64\n",
    "# Length: 3000\n",
    "# Train Size, Test Size 278 100\n",
    "\n",
    "#yes\n",
    "# Dataset: NATOPS\n",
    "# Number of Classes: 6\n",
    "# Dimension of path: 24\n",
    "# Length: 51\n",
    "# Train Size, Test Size 180 180\n",
    "\n",
    "#TODO NOT TSLEARN. LENGTH WRONG\n",
    "# Dataset: PenDigits\n",
    "# Number of Classes: 10\n",
    "# Dimension of path: 2\n",
    "# Length: 8\n",
    "# Train Size, Test Size 7494 3498\n",
    "\n",
    "#highDim\n",
    "# Dataset: PEMS-SF\n",
    "# Number of Classes: 7\n",
    "# Dimension of path: 963\n",
    "# Length: 144\n",
    "# Train Size, Test Size 267 173\n",
    "\n",
    "#dim=1, big length\n",
    "# Dataset: Phoneme\n",
    "# Number of Classes: 39\n",
    "# Dimension of path: 1\n",
    "# Length: 1024\n",
    "# Train Size, Test Size 214 1896\n",
    "\n",
    "#yes\n",
    "# Dataset: RacketSports\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 6\n",
    "# Length: 30\n",
    "# Train Size, Test Size 151 152\n",
    "\n",
    "#yes\n",
    "# Dataset: SelfRegulationSCP1\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 6\n",
    "# Length: 896\n",
    "# Train Size, Test Size 268 293\n",
    "\n",
    "# Dataset: SelfRegulationSCP2\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 7\n",
    "# Length: 1152\n",
    "# Train Size, Test Size 200 180\n",
    "\n",
    "# Dataset: SpokenArabicDigits\n",
    "# No dataset found\n",
    "\n",
    "#long, also very small set\n",
    "# Dataset: StandWalkJump\n",
    "# Number of Classes: 3\n",
    "# Dimension of path: 4\n",
    "# Length: 2500\n",
    "# Train Size, Test Size 12 15\n",
    "\n",
    "#yes\n",
    "# Dataset: UWaveGestureLibrary\n",
    "# Number of Classes: 8\n",
    "# Dimension of path: 3\n",
    "# Length: 315\n",
    "# Train Size, Test Size 120 320\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation code (for anomaly detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Libras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Label for linear: 100%|██████████| 15/15 [00:06<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for kernel linear: 6.8868889808654785 seconds\n",
      "Time taken for dataset Libras: 6.905257940292358 seconds\n",
      "\n",
      "\n",
      "\n",
      "{'Libras': {'kernel_results': {'linear': {'1': {'kernel_name': 'linear', 'normal_class_label': '1', 'threshold': 1, 'CV_train_auc': 0.746825396825397, 'auc_params': array([0.7468254]), 'auc_thresh': 0.746825396825397}, '10': {'kernel_name': 'linear', 'normal_class_label': '10', 'threshold': 1, 'CV_train_auc': 0.8356261022927691, 'auc_params': array([0.8356261]), 'auc_thresh': 0.8356261022927691}, '11': {'kernel_name': 'linear', 'normal_class_label': '11', 'threshold': 1, 'CV_train_auc': 0.9572222222222222, 'auc_params': array([0.95722222]), 'auc_thresh': 0.9572222222222222}, '12': {'kernel_name': 'linear', 'normal_class_label': '12', 'threshold': 1, 'CV_train_auc': 0.8649250440917109, 'auc_params': array([0.86492504]), 'auc_thresh': 0.8649250440917109}, '13': {'kernel_name': 'linear', 'normal_class_label': '13', 'threshold': 1, 'CV_train_auc': 0.9071516754850089, 'auc_params': array([0.90715168]), 'auc_thresh': 0.9071516754850089}, '14': {'kernel_name': 'linear', 'normal_class_label': '14', 'threshold': 1, 'CV_train_auc': 0.8731966490299823, 'auc_params': array([0.87319665]), 'auc_thresh': 0.8731966490299823}, '15': {'kernel_name': 'linear', 'normal_class_label': '15', 'threshold': 1, 'CV_train_auc': 0.7906172839506174, 'auc_params': array([0.79061728]), 'auc_thresh': 0.7906172839506174}, '2': {'kernel_name': 'linear', 'normal_class_label': '2', 'threshold': 1, 'CV_train_auc': 0.7705335097001764, 'auc_params': array([0.77053351]), 'auc_thresh': 0.7705335097001764}, '3': {'kernel_name': 'linear', 'normal_class_label': '3', 'threshold': 1, 'CV_train_auc': 0.779488536155203, 'auc_params': array([0.77948854]), 'auc_thresh': 0.779488536155203}, '4': {'kernel_name': 'linear', 'normal_class_label': '4', 'threshold': 1, 'CV_train_auc': 0.8934082892416226, 'auc_params': array([0.89340829]), 'auc_thresh': 0.8934082892416226}, '5': {'kernel_name': 'linear', 'normal_class_label': '5', 'threshold': 1, 'CV_train_auc': 0.9144797178130512, 'auc_params': array([0.91447972]), 'auc_thresh': 0.9144797178130512}, '6': {'kernel_name': 'linear', 'normal_class_label': '6', 'threshold': 1, 'CV_train_auc': 0.807804232804233, 'auc_params': array([0.80780423]), 'auc_thresh': 0.807804232804233}, '7': {'kernel_name': 'linear', 'normal_class_label': '7', 'threshold': 1, 'CV_train_auc': 0.9010273368606703, 'auc_params': array([0.90102734]), 'auc_thresh': 0.9010273368606703}, '8': {'kernel_name': 'linear', 'normal_class_label': '8', 'threshold': 1, 'CV_train_auc': 0.863994708994709, 'auc_params': array([0.86399471]), 'auc_thresh': 0.863994708994709}, '9': {'kernel_name': 'linear', 'normal_class_label': '9', 'threshold': 1, 'CV_train_auc': 0.9068915343915344, 'auc_params': array([0.90689153]), 'auc_thresh': 0.9068915343915344}}}, 'num_classes': 15, 'path dim': 2, 'ts_length': 45, 'N_train': 180}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from cross_validation import cv_tslearn\n",
    "\n",
    "cv_best_models = cv_tslearn(\n",
    "    dataset_names = [\n",
    "        #'ArticularyWordRecognition', \n",
    "        #'BasicMotions', \n",
    "        #'Cricket',\n",
    "         ##########'ERing', #cant find dataset\n",
    "        'Libras', \n",
    "        #'NATOPS', \n",
    "        #'RacketSports',     \n",
    "        #'FingerMovements',\n",
    "        #'Heartbeat',\n",
    "        #'SelfRegulationSCP1', \n",
    "        #'UWaveGestureLibrary'\n",
    "        ],\n",
    "    kernel_names = [\n",
    "        \"linear\",\n",
    "        #\"rbf\",\n",
    "        #\"poly\",\n",
    "        #\"gak\",\n",
    "        #\"truncated sig\",\n",
    "        #\"truncated sig rbf\",\n",
    "        #\"truncated sig poly\",\n",
    "        #\"signature pde\",\n",
    "        #\"signature pde rbf\",\n",
    "        #\"signature pde poly\",\n",
    "        #\"integral linear\",\n",
    "        #\"integral rbf\",\n",
    "        #\"integral poly\",\n",
    "        ],\n",
    "        k=5,\n",
    "        n_repeats=10,\n",
    "        n_jobs_repeats=4\n",
    "        )\n",
    "\n",
    "print(cv_best_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
