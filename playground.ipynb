{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import sklearn.utils\n",
    "import sklearn.metrics\n",
    "import iisignature\n",
    "import torch\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import List, Optional, Dict, Set, Callable, Any\n",
    "from joblib import Memory, Parallel, delayed\n",
    "import tslearn\n",
    "import tslearn.metrics\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "import sigkernel\n",
    "import scipy\n",
    "from scipy.interpolate import interp1d\n",
    "from numba import njit\n",
    "import pickle\n",
    "\n",
    "from signature import streams_to_sigs, transform_stream\n",
    "from conformance import BaseclassConformanceScore, stream_to_torch\n",
    "from kernels import linear_kernel_gram, rbf_kernel_gram, poly_kernel_gram\n",
    "from kernels import pairwise_kernel_gram, integral_kernel_gram, sig_kernel_gram\n",
    "from experiment_code import print_dataset_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all tslearn datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _datasets = [\n",
    "#             'ArticularyWordRecognition', \n",
    "#             'BasicMotions', \n",
    "#             'Cricket',\n",
    "#             #'ERing',\n",
    "#             'Libras', \n",
    "#             'NATOPS', \n",
    "#             'RacketSports',     \n",
    "#             'FingerMovements',\n",
    "#             'Heartbeat',\n",
    "#             'SelfRegulationSCP1', \n",
    "#             'UWaveGestureLibrary'\n",
    "#             ]\n",
    "\n",
    "# import tslearn\n",
    "# UCR_UEA_datasets = tslearn.datasets.UCR_UEA_datasets()\n",
    "\n",
    "# for dataset_name in UCR_UEA_datasets.list_multivariate_datasets():\n",
    "# #for dataset_name in _datasets:\n",
    "#     print(\"Dataset:\", dataset_name)\n",
    "#     dataset = UCR_UEA_datasets.load_dataset(dataset_name)\n",
    "#     if dataset[0] is not None:\n",
    "#         X_train, y_train, X_test, y_test = dataset\n",
    "#         num_classes = len(np.unique(y_train))\n",
    "#         N_train, T, d = X_train.shape\n",
    "#         N_test, _, _  = X_test.shape\n",
    "        \n",
    "#         print(\"Number of Classes:\", num_classes)\n",
    "#         print(\"Dimension of path:\", d)\n",
    "#         print(\"Length:\", T)\n",
    "#         print(\"Train Size, Test Size\", N_train, N_test)\n",
    "#         print()\n",
    "#     else:\n",
    "#         print(\"No dataset found\")\n",
    "#         print()\n",
    "\n",
    "#yes\n",
    "# Dataset: ArticularyWordRecognition\n",
    "# Number of Classes: 25\n",
    "# Dimension of path: 9\n",
    "# Length: 144\n",
    "# Train Size, Test Size 275 300\n",
    "\n",
    "# Dataset: AtrialFibrillation\n",
    "# No dataset found\n",
    "\n",
    "#yes\n",
    "# Dataset: BasicMotions\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 6\n",
    "# Length: 100\n",
    "# Train Size, Test Size 40 40\n",
    "\n",
    "# Dataset: CharacterTrajectories\n",
    "# No dataset found\n",
    "\n",
    "#yes\n",
    "# Dataset: Cricket\n",
    "# Number of Classes: 12\n",
    "# Dimension of path: 6\n",
    "# Length: 1197\n",
    "# Train Size, Test Size 108 72\n",
    "\n",
    "# Dataset: DuckDuckGeese\n",
    "# No dataset found\n",
    "\n",
    "# Dataset: EigenWorms\n",
    "# Number of Classes: 5\n",
    "# Dimension of path: 6\n",
    "# Length: 17984\n",
    "# Train Size, Test Size 128 131\n",
    "\n",
    "#why not\n",
    "# Dataset: Epilepsy\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 3\n",
    "# Length: 206\n",
    "# Train Size, Test Size 137 138\n",
    "\n",
    "#longLength\n",
    "# Dataset: EthanolConcentration\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 3\n",
    "# Length: 1751\n",
    "# Train Size, Test Size 261 263\n",
    "\n",
    "# Dataset: ERing\n",
    "# No dataset found\n",
    "\n",
    "#big\n",
    "# Dataset: FaceDetection\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 144\n",
    "# Length: 62\n",
    "# Train Size, Test Size 5890 3524\n",
    "\n",
    "#yes\n",
    "# Dataset: FingerMovements\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 28\n",
    "# Length: 50\n",
    "# Train Size, Test Size 316 100\n",
    "\n",
    "#why not, maybe big length\n",
    "# Dataset: HandMovementDirection\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 10\n",
    "# Length: 400\n",
    "# Train Size, Test Size 160 74\n",
    "\n",
    "#smallTrain\n",
    "# Dataset: Handwriting\n",
    "# Number of Classes: 26\n",
    "# Dimension of path: 3\n",
    "# Length: 152\n",
    "# Train Size, Test Size 150 850\n",
    "\n",
    "#yes\n",
    "# Dataset: Heartbeat\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 61\n",
    "# Length: 405\n",
    "# Train Size, Test Size 204 205\n",
    "\n",
    "#big\n",
    "# Dataset: InsectWingbeat\n",
    "# Number of Classes: 10\n",
    "# Dimension of path: 200\n",
    "# Length: 22\n",
    "# Train Size, Test Size 25000 25000\n",
    "\n",
    "# Dataset: JapaneseVowels\n",
    "# No dataset found\n",
    "\n",
    "#yes\n",
    "# Dataset: Libras\n",
    "# Number of Classes: 15\n",
    "# Dimension of path: 2\n",
    "# Length: 45\n",
    "# Train Size, Test Size 180 180\n",
    "\n",
    "#TODO I SHOULD INCLUDE\n",
    "# Dataset: LSST\n",
    "# Number of Classes: 14\n",
    "# Dimension of path: 6\n",
    "# Length: 36\n",
    "# Train Size, Test Size 2459 2466\n",
    "\n",
    "#length\n",
    "# Dataset: MotorImagery\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 64\n",
    "# Length: 3000\n",
    "# Train Size, Test Size 278 100\n",
    "\n",
    "#yes\n",
    "# Dataset: NATOPS\n",
    "# Number of Classes: 6\n",
    "# Dimension of path: 24\n",
    "# Length: 51\n",
    "# Train Size, Test Size 180 180\n",
    "\n",
    "#TODO NOT TSLEARN. LENGTH WRONG\n",
    "# Dataset: PenDigits\n",
    "# Number of Classes: 10\n",
    "# Dimension of path: 2\n",
    "# Length: 8\n",
    "# Train Size, Test Size 7494 3498\n",
    "\n",
    "#highDim\n",
    "# Dataset: PEMS-SF\n",
    "# Number of Classes: 7\n",
    "# Dimension of path: 963\n",
    "# Length: 144\n",
    "# Train Size, Test Size 267 173\n",
    "\n",
    "#dim=1, big length\n",
    "# Dataset: Phoneme\n",
    "# Number of Classes: 39\n",
    "# Dimension of path: 1\n",
    "# Length: 1024\n",
    "# Train Size, Test Size 214 1896\n",
    "\n",
    "#yes\n",
    "# Dataset: RacketSports\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 6\n",
    "# Length: 30\n",
    "# Train Size, Test Size 151 152\n",
    "\n",
    "#yes\n",
    "# Dataset: SelfRegulationSCP1\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 6\n",
    "# Length: 896\n",
    "# Train Size, Test Size 268 293\n",
    "\n",
    "# Dataset: SelfRegulationSCP2\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 7\n",
    "# Length: 1152\n",
    "# Train Size, Test Size 200 180\n",
    "\n",
    "# Dataset: SpokenArabicDigits\n",
    "# No dataset found\n",
    "\n",
    "#long, also very small set\n",
    "# Dataset: StandWalkJump\n",
    "# Number of Classes: 3\n",
    "# Dimension of path: 4\n",
    "# Length: 2500\n",
    "# Train Size, Test Size 12 15\n",
    "\n",
    "#yes\n",
    "# Dataset: UWaveGestureLibrary\n",
    "# Number of Classes: 8\n",
    "# Dimension of path: 3\n",
    "# Length: 315\n",
    "# Train Size, Test Size 120 320\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (tslearn) Cross Validation on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Libras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Label for rbf: 100%|██████████| 15/15 [00:23<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for kernel rbf: 23.18761444091797 seconds\n",
      "Time taken for dataset Libras: 23.19777750968933 seconds\n",
      "\n",
      "\n",
      "\n",
      "{'Libras': {'kernel_results': {'rbf': {'1': {'sigma': 1.0, 'kernel_name': 'rbf', 'normal_class_label': '1', 'threshold': 8, 'CV_train_auc': 0.8432539682539686, 'auc_params': array([0.83690476, 0.83650794, 0.80039683, 0.76269841, 0.82579365,\n",
      "       0.84325397]), 'auc_thresh': array([0.61904762, 0.79801587, 0.82579365, 0.7734127 , 0.73373016,\n",
      "       0.79365079, 0.79920635, 0.84325397, 0.83650794])}, '10': {'sigma': 1.0, 'kernel_name': 'rbf', 'normal_class_label': '10', 'threshold': 6, 'CV_train_auc': 0.869047619047619, 'auc_params': array([0.86785714, 0.86388889, 0.8484127 , 0.79880952, 0.84960317,\n",
      "       0.86904762]), 'auc_thresh': array([0.75039683, 0.83134921, 0.80039683, 0.84444444, 0.84960317,\n",
      "       0.86904762, 0.85277778, 0.86785714, 0.83134921])}, '11': {'sigma': 0.006737946999085467, 'kernel_name': 'rbf', 'normal_class_label': '11', 'threshold': 3, 'CV_train_auc': 0.9773809523809524, 'auc_params': array([0.97738095, 0.96230159, 0.86785714, 0.80952381, 0.79801587,\n",
      "       0.76706349]), 'auc_thresh': array([0.91706349, 0.97460317, 0.97738095, 0.96984127, 0.95674603,\n",
      "       0.92857143, 0.92936508, 0.89365079, 0.86388889])}, '12': {'sigma': 0.006737946999085467, 'kernel_name': 'rbf', 'normal_class_label': '12', 'threshold': 8, 'CV_train_auc': 0.9638888888888889, 'auc_params': array([0.96388889, 0.96388889, 0.9515873 , 0.85436508, 0.88293651,\n",
      "       0.9547619 ]), 'auc_thresh': array([0.75992063, 0.71865079, 0.83968254, 0.85396825, 0.94801587,\n",
      "       0.96150794, 0.96309524, 0.96388889, 0.93492063])}, '13': {'sigma': 0.36787944117144233, 'kernel_name': 'rbf', 'normal_class_label': '13', 'threshold': 4, 'CV_train_auc': 0.9575396825396825, 'auc_params': array([0.94960317, 0.94206349, 0.92698413, 0.93095238, 0.95753968,\n",
      "       0.89246032]), 'auc_thresh': array([0.76269841, 0.89880952, 0.93095238, 0.95753968, 0.94960317,\n",
      "       0.94285714, 0.91547619, 0.88928571, 0.84801587])}, '14': {'sigma': 0.049787068367863944, 'kernel_name': 'rbf', 'normal_class_label': '14', 'threshold': 8, 'CV_train_auc': 0.9670634920634921, 'auc_params': array([0.95357143, 0.95952381, 0.96706349, 0.95753968, 0.90515873,\n",
      "       0.91865079]), 'auc_thresh': array([0.79325397, 0.85238095, 0.90515873, 0.91865079, 0.9047619 ,\n",
      "       0.93134921, 0.95198413, 0.96706349, 0.94166667])}, '15': {'sigma': 0.36787944117144233, 'kernel_name': 'rbf', 'normal_class_label': '15', 'threshold': 2, 'CV_train_auc': 0.9507936507936507, 'auc_params': array([0.90436508, 0.90595238, 0.91230159, 0.93134921, 0.95079365,\n",
      "       0.93928571]), 'auc_thresh': array([0.93928571, 0.95079365, 0.89563492, 0.8781746 , 0.85793651,\n",
      "       0.85079365, 0.90238095, 0.86785714, 0.7734127 ])}, '2': {'sigma': 1.0, 'kernel_name': 'rbf', 'normal_class_label': '2', 'threshold': 8, 'CV_train_auc': 0.9257936507936508, 'auc_params': array([0.88928571, 0.875     , 0.83888889, 0.77896825, 0.80992063,\n",
      "       0.92579365]), 'auc_thresh': array([0.77579365, 0.79047619, 0.83214286, 0.8531746 , 0.85992063,\n",
      "       0.84444444, 0.85992063, 0.92579365, 0.85833333])}, '3': {'sigma': 0.01831563888873418, 'kernel_name': 'rbf', 'normal_class_label': '3', 'threshold': 8, 'CV_train_auc': 0.9527777777777778, 'auc_params': array([0.94960317, 0.95277778, 0.94801587, 0.91547619, 0.82777778,\n",
      "       0.90714286]), 'auc_thresh': array([0.62063492, 0.90714286, 0.81666667, 0.7765873 , 0.82103175,\n",
      "       0.86468254, 0.90634921, 0.95277778, 0.90873016])}, '4': {'sigma': 0.006737946999085467, 'kernel_name': 'rbf', 'normal_class_label': '4', 'threshold': 7, 'CV_train_auc': 0.9964285714285716, 'auc_params': array([0.99642857, 0.99444444, 0.98730159, 0.96150794, 0.91388889,\n",
      "       0.96269841]), 'auc_thresh': array([0.67619048, 0.83809524, 0.85952381, 0.98928571, 0.97380952,\n",
      "       0.98968254, 0.99642857, 0.98134921, 0.9468254 ])}, '5': {'sigma': 0.006737946999085467, 'kernel_name': 'rbf', 'normal_class_label': '5', 'threshold': 8, 'CV_train_auc': 0.9892857142857142, 'auc_params': array([0.98928571, 0.98293651, 0.97539683, 0.95      , 0.93214286,\n",
      "       0.92936508]), 'auc_thresh': array([0.69325397, 0.92142857, 0.95357143, 0.93214286, 0.92777778,\n",
      "       0.95436508, 0.97103175, 0.98928571, 0.98134921])}, '6': {'sigma': 0.049787068367863944, 'kernel_name': 'rbf', 'normal_class_label': '6', 'threshold': 6, 'CV_train_auc': 0.9222222222222222, 'auc_params': array([0.88531746, 0.89365079, 0.92222222, 0.91547619, 0.83690476,\n",
      "       0.84126984]), 'auc_thresh': array([0.62579365, 0.61031746, 0.81587302, 0.83690476, 0.8968254 ,\n",
      "       0.92222222, 0.89365079, 0.87777778, 0.84484127])}, '7': {'sigma': 0.006737946999085467, 'kernel_name': 'rbf', 'normal_class_label': '7', 'threshold': 6, 'CV_train_auc': 0.9706349206349205, 'auc_params': array([0.97063492, 0.94126984, 0.92103175, 0.8952381 , 0.89246032,\n",
      "       0.92261905]), 'auc_thresh': array([0.80595238, 0.86388889, 0.89920635, 0.94801587, 0.94960317,\n",
      "       0.97063492, 0.95952381, 0.94761905, 0.9452381 ])}, '8': {'sigma': 0.006737946999085467, 'kernel_name': 'rbf', 'normal_class_label': '8', 'threshold': 8, 'CV_train_auc': 0.9384920634920635, 'auc_params': array([0.93849206, 0.93253968, 0.92619048, 0.90515873, 0.90952381,\n",
      "       0.89404762]), 'auc_thresh': array([0.6797619 , 0.75515873, 0.90238095, 0.91904762, 0.93650794,\n",
      "       0.93492063, 0.9297619 , 0.93849206, 0.91349206])}, '9': {'sigma': 0.006737946999085467, 'kernel_name': 'rbf', 'normal_class_label': '9', 'threshold': 8, 'CV_train_auc': 0.994047619047619, 'auc_params': array([0.99404762, 0.98849206, 0.98293651, 0.94761905, 0.85396825,\n",
      "       0.9015873 ]), 'auc_thresh': array([0.61746032, 0.87063492, 0.9015873 , 0.93968254, 0.9765873 ,\n",
      "       0.98492063, 0.98452381, 0.99404762, 0.98650794])}}}, 'num_classes': 15, 'path dim': 2, 'ts_length': 45, 'N_train': 180}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from cross_validation import cv_tslearn\n",
    "\n",
    "cv_best_models = cv_tslearn(\n",
    "    dataset_names = [\n",
    "        #'ArticularyWordRecognition', \n",
    "        #'BasicMotions', \n",
    "        #'Cricket',\n",
    "         ##########'ERing', #cant find dataset\n",
    "        'Libras', \n",
    "        #'NATOPS', \n",
    "        #'RacketSports',     \n",
    "        #'FingerMovements',\n",
    "        #'Heartbeat',\n",
    "        #'SelfRegulationSCP1', \n",
    "        #'UWaveGestureLibrary'\n",
    "        ],\n",
    "    kernel_names = [\n",
    "        #\"linear\",\n",
    "        \"rbf\",\n",
    "        #\"poly\",\n",
    "        #\"gak\",\n",
    "        #\"truncated sig\",\n",
    "        #\"truncated sig rbf\",\n",
    "        #\"truncated sig poly\",\n",
    "        #\"signature pde\",\n",
    "        #\"signature pde rbf\",\n",
    "        #\"signature pde poly\",\n",
    "        #\"integral linear\",\n",
    "        #\"integral rbf\",\n",
    "        #\"integral poly\",\n",
    "        ],\n",
    "        k=4,\n",
    "        n_repeats=5,\n",
    "        n_jobs_repeats=4\n",
    "        )\n",
    "\n",
    "print(cv_best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_labels(labelwise_dict:Dict[str, Dict[str, Any]],\n",
    "                          field:str):\n",
    "    \"\"\"Averages the values of a field over the labels.\"\"\"\n",
    "    return np.mean([param_dict[field] for param_dict in labelwise_dict.values()],\n",
    "                   axis=0)\n",
    "\n",
    "\n",
    "def print_cv_tslearn_results(\n",
    "        dataset_kernel_label_paramdict : Dict[str, Dict[str, Dict[str, Any]]],\n",
    "        ):\n",
    "\n",
    "    # return experiments\n",
    "    for dataset_name, results in dataset_kernel_label_paramdict.items():\n",
    "        print(dataset_name)\n",
    "        kernelwise_dict = results[\"kernel_results\"]\n",
    "        n_classes = results['num_classes']\n",
    "        ts_length = results['ts_length']\n",
    "        n_train = results['N_train']\n",
    "        path_dim = results['path dim']\n",
    "        from experiment_code import print_dataset_stats\n",
    "        print_dataset_stats(n_classes, path_dim, ts_length, n_train, \"unknown\")\n",
    "        for kernel_name, labelwise_dict in kernelwise_dict.items():\n",
    "            final_auc_avgs = average_labels(labelwise_dict, \"CV_train_auc\")\n",
    "            params_auc_avgs = average_labels(labelwise_dict, \"auc_params\")\n",
    "            thresh_auc_avgs = average_labels(labelwise_dict, \"auc_thresh\")\n",
    "            print(f\"\\n{kernel_name}\")\n",
    "            print(\"final_auc_avgs\", final_auc_avgs)\n",
    "            print(\"params_auc_avgs\", params_auc_avgs)\n",
    "            print(\"thresh_auc_avgs\", thresh_auc_avgs)\n",
    "            if \"truncated sig\" in kernel_name:\n",
    "                trunc_auc_avgs = average_labels(labelwise_dict, \"auc_truncs\")\n",
    "                print(\"trunc_auc_avgs\", trunc_auc_avgs)\n",
    "        print(\"\\nEnd dataset \\n\\n\\n\")\n",
    "\n",
    "print_cv_tslearn_results(cv_best_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (tslearn) Validate on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libras\n",
      "Number of Classes: 15\n",
      "Dimension of path: 2\n",
      "Length: 45\n",
      "Train: 180\n",
      "Test: 180\n",
      "Covariance operator numerical rank = 11\n",
      "Covariance operator numerical rank = 11\n",
      "Covariance operator numerical rank = 9\n",
      "Covariance operator numerical rank = 11\n",
      "Covariance operator numerical rank = 10\n",
      "Covariance operator numerical rank = 11\n",
      "Covariance operator numerical rank = 9\n",
      "Covariance operator numerical rank = 11\n",
      "Covariance operator numerical rank = 11\n",
      "Covariance operator numerical rank = 10\n",
      "Covariance operator numerical rank = 11\n",
      "Covariance operator numerical rank = 11\n",
      "Covariance operator numerical rank = 11\n",
      "Covariance operator numerical rank = 11\n",
      "Covariance operator numerical rank = 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Libras': {'results': {'rbf': array([[0.93875661, 0.99490023],\n",
       "          [0.7223545 , 0.95405502]])},\n",
       "  'num_classes': 15,\n",
       "  'path dim': 2,\n",
       "  'ts_length': 45,\n",
       "  'N_train': 180,\n",
       "  'N_test': 180}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiment_code import validate_tslearn\n",
    "\n",
    "validate_tslearn(cv_best_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print CV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libras\n",
      "Number of Classes: 15\n",
      "Dimension of path: 2\n",
      "Length: 45\n",
      "Train: 180\n",
      "Test: unknown\n",
      "\n",
      "rbf\n",
      "final_auc_avgs 0.9479100529100528\n",
      "params_auc_avgs [0.93777778 0.93301587 0.91843915 0.8876455  0.87642857 0.89793651]\n",
      "thresh_auc_avgs [0.7357672  0.83878307 0.87706349 0.89272487 0.90283069 0.91624339\n",
      " 0.92103175 0.92666667 0.89433862]\n",
      "\n",
      "End dataset \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
