{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import sklearn.utils\n",
    "import sklearn.metrics\n",
    "import iisignature\n",
    "import torch\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Optional, Dict, Set, Callable\n",
    "from joblib import Memory, Parallel, delayed\n",
    "import tslearn\n",
    "import tslearn.metrics\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "import sigkernel\n",
    "import scipy\n",
    "from scipy.interpolate import interp1d\n",
    "from numba import njit\n",
    "\n",
    "from signature import streams_to_sigs, transform_stream\n",
    "from conformance import BaseclassConformanceScore, pairwise_kernel_gram, stream_to_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: ArticularyWordRecognition\n",
    "# Number of Classes: 25\n",
    "# Dimension of path: 9\n",
    "# Length: 144\n",
    "# Train Size, Test Size 275 300\n",
    "\n",
    "# Dataset: AtrialFibrillation\n",
    "# No dataset found\n",
    "\n",
    "# Dataset: BasicMotions\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 6\n",
    "# Length: 100\n",
    "# Train Size, Test Size 40 40\n",
    "\n",
    "# Dataset: CharacterTrajectories\n",
    "# No dataset found\n",
    "\n",
    "# Dataset: Cricket\n",
    "# Number of Classes: 12\n",
    "# Dimension of path: 6\n",
    "# Length: 1197\n",
    "# Train Size, Test Size 108 72\n",
    "\n",
    "# Dataset: DuckDuckGeese\n",
    "# No dataset found\n",
    "\n",
    "# Dataset: EigenWorms\n",
    "# Number of Classes: 5\n",
    "# Dimension of path: 6\n",
    "# Length: 17984\n",
    "# Train Size, Test Size 128 131\n",
    "\n",
    "# Dataset: Epilepsy\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 3\n",
    "# Length: 206\n",
    "# Train Size, Test Size 137 138\n",
    "\n",
    "# Dataset: EthanolConcentration\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 3\n",
    "# Length: 1751\n",
    "# Train Size, Test Size 261 263\n",
    "\n",
    "# Dataset: ERing\n",
    "# No dataset found\n",
    "\n",
    "# Dataset: FaceDetection\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 144\n",
    "# Length: 62\n",
    "# Train Size, Test Size 5890 3524\n",
    "\n",
    "# Dataset: FingerMovements\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 28\n",
    "# Length: 50\n",
    "# Train Size, Test Size 316 100\n",
    "\n",
    "# Dataset: HandMovementDirection\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 10\n",
    "# Length: 400\n",
    "# Train Size, Test Size 160 74\n",
    "\n",
    "# Dataset: Handwriting\n",
    "# Number of Classes: 26\n",
    "# Dimension of path: 3\n",
    "# Length: 152\n",
    "# Train Size, Test Size 150 850\n",
    "\n",
    "# Dataset: Heartbeat\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 61\n",
    "# Length: 405\n",
    "# Train Size, Test Size 204 205\n",
    "\n",
    "# Dataset: InsectWingbeat\n",
    "# Number of Classes: 10\n",
    "# Dimension of path: 200\n",
    "# Length: 22\n",
    "# Train Size, Test Size 25000 25000\n",
    "\n",
    "# Dataset: JapaneseVowels\n",
    "# No dataset found\n",
    "\n",
    "# Dataset: Libras\n",
    "# Number of Classes: 15\n",
    "# Dimension of path: 2\n",
    "# Length: 45\n",
    "# Train Size, Test Size 180 180\n",
    "\n",
    "# Dataset: LSST\n",
    "# Number of Classes: 14\n",
    "# Dimension of path: 6\n",
    "# Length: 36\n",
    "# Train Size, Test Size 2459 2466\n",
    "\n",
    "# Dataset: MotorImagery\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 64\n",
    "# Length: 3000\n",
    "# Train Size, Test Size 278 100\n",
    "\n",
    "# Dataset: NATOPS\n",
    "# Number of Classes: 6\n",
    "# Dimension of path: 24\n",
    "# Length: 51\n",
    "# Train Size, Test Size 180 180\n",
    "\n",
    "# Dataset: PenDigits\n",
    "# Number of Classes: 10\n",
    "# Dimension of path: 2\n",
    "# Length: 8\n",
    "# Train Size, Test Size 7494 3498\n",
    "\n",
    "# Dataset: PEMS-SF\n",
    "# Number of Classes: 7\n",
    "# Dimension of path: 963\n",
    "# Length: 144\n",
    "# Train Size, Test Size 267 173\n",
    "\n",
    "# Dataset: Phoneme\n",
    "# Number of Classes: 39\n",
    "# Dimension of path: 1\n",
    "# Length: 1024\n",
    "# Train Size, Test Size 214 1896\n",
    "\n",
    "# Dataset: RacketSports\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 6\n",
    "# Length: 30\n",
    "# Train Size, Test Size 151 152\n",
    "\n",
    "# Dataset: SelfRegulationSCP1\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 6\n",
    "# Length: 896\n",
    "# Train Size, Test Size 268 293\n",
    "\n",
    "# Dataset: SelfRegulationSCP2\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 7\n",
    "# Length: 1152\n",
    "# Train Size, Test Size 200 180\n",
    "\n",
    "# Dataset: SpokenArabicDigits\n",
    "# No dataset found\n",
    "\n",
    "# Dataset: StandWalkJump\n",
    "# Number of Classes: 3\n",
    "# Dimension of path: 4\n",
    "# Length: 2500\n",
    "# Train Size, Test Size 12 15\n",
    "\n",
    "# Dataset: UWaveGestureLibrary\n",
    "# Number of Classes: 8\n",
    "# Dimension of path: 3\n",
    "# Length: 315\n",
    "# Train Size, Test Size 120 320\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tslearn datasets (equal length)\n",
    "\n",
    "* equal length (in time) UCR_UEA multivariate time series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "######################## Static Kernels on R^d ###########################\n",
    "##########################################################################\n",
    "\n",
    "def _check_gram_dims(X:np.ndarray, \n",
    "                     Y:np.ndarray,\n",
    "                     diag:bool = False,):\n",
    "    \"\"\"Stacks the input into a Gram matrix shape (N1, N2, ..., d) or\n",
    "    into a diagonal Gram shape (N1, ..., d) if diag and N1==N2.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Shape (N1, ... , d).\n",
    "        Y (np.ndarray): Shape (N2, ... , d).\n",
    "        diag (bool): If True, use diagonal Gram shape.\n",
    "    \"\"\"\n",
    "    len1 = len(X.shape)\n",
    "    len2 = len(Y.shape)\n",
    "    if (len1<2) or (len2<2):\n",
    "        raise ValueError(\"X and Y must have at least 2 dimensions, found {len1} and {len2}.\")\n",
    "    if X.shape[1:] != Y.shape[1:]:\n",
    "        raise ValueError(\"X and Y must have the same dimensions except for the first axis.\")\n",
    "\n",
    "    N1 = X.shape[0]\n",
    "    N2 = Y.shape[0]\n",
    "    if diag and N1!=N2:\n",
    "        raise ValueError(\"If 'diag' is True, X and Y must have the same number of samples.\")\n",
    "\n",
    "\n",
    "def linear_kernel_gram(X:np.ndarray, \n",
    "                       Y:np.ndarray,\n",
    "                       diag:bool = False,\n",
    "                       ):\n",
    "    \"\"\"Computes the Rd inner product matrix <x_i, y_j> or diagonal <x_i, y_i>.\n",
    "    The inputs dimensions can only differ in the first axis.\n",
    "    \n",
    "    Args:\n",
    "        X (np.ndarray): Shape (N1, ... , d).\n",
    "        Y (np.ndarray): Shape (N2, ... , d).\n",
    "        diag (bool): If True, computes the diagonal of the gram matrix.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of shape (N1, N2, ...) or (N1, ...) if diag=True.\n",
    "    \"\"\"\n",
    "    pass\n",
    "    _check_gram_dims(X, Y, diag)\n",
    "    if diag:\n",
    "        #out_i... = sum(X_i...k * Y_i...k)\n",
    "        return np.einsum('i...k,i...k -> i...', X, Y)\n",
    "    else:\n",
    "        #out_ij... = sum(X_i...k * Y_j...k)\n",
    "        return np.einsum('i...k,j...k -> ij...', X, Y)\n",
    "\n",
    "\n",
    "def rbf_kernel_gram(X:np.ndarray, \n",
    "                    Y:np.ndarray,\n",
    "                    gamma:float,\n",
    "                    diag:bool = False,\n",
    "                    ):\n",
    "    \"\"\"Computes the RBF gram matrix k(x_i, y_j) or diagonal k(x_i, y_i).\n",
    "    The inputs dimensions can only differ in the first axis.\n",
    "    \n",
    "    Args:\n",
    "        X (np.ndarray): Shape (N1, ... , d).\n",
    "        Y (np.ndarray): Shape (N2, ... , d).\n",
    "        gamma (float): RBF parameter\n",
    "        diag (bool): If True, computes the diagonal of the gram matrix.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of shape (N1, N2, ...) or (N1, ...) if diag=True.\n",
    "    \"\"\"\n",
    "    if diag:\n",
    "        diff = X-Y\n",
    "        norms_squared = linear_kernel_gram(diff, diff, diag=True)\n",
    "    else:\n",
    "        xx = linear_kernel_gram(X, X, diag=True)\n",
    "        xy = linear_kernel_gram(X, Y, diag=False)\n",
    "        yy = linear_kernel_gram(Y, Y, diag=True)\n",
    "        norms_squared = xx[:, np.newaxis] -2*xy + yy[np.newaxis, :]\n",
    "\n",
    "    d= X.shape[-1]\n",
    "    return np.exp(-gamma * norms_squared/d)\n",
    "\n",
    "\n",
    "def poly_kernel_gram(X:np.ndarray, \n",
    "                     Y:np.ndarray,\n",
    "                     p:float, #eg 2 or 3\n",
    "                     diag:bool = False):\n",
    "    \"\"\"Computes the polynomial kernel (<x_i, y_j> + 1)^p.\n",
    "    The inputs dimensions can only differ in the first axis.\n",
    "    \n",
    "    Args:\n",
    "        X (np.ndarray): Shape (N1, ... , d).\n",
    "        Y (np.ndarray): Shape (N2, ... , d).\n",
    "        p (float): Polynomial degree.\n",
    "        diag (bool): If True, computes the diagonal of the gram matrix.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of shape (N1, N2, ...) or (N1, ...) if diag=True.\n",
    "    \"\"\"\n",
    "    d = X.shape[-1]\n",
    "    xy = linear_kernel_gram(X, Y, diag)\n",
    "    return (xy + d)**p\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "################### time series Integral Kernel of static kernel ######################\n",
    "#######################################################################################\n",
    "\n",
    "\n",
    "def integral_kernel(s1: np.ndarray,\n",
    "                    s2: np.ndarray,\n",
    "                    static_diag_kernel:Callable,\n",
    "                    )-> float:\n",
    "    \"\"\"Computes the integral kernel K(x, y) = \\int k(x_t, y_t) dt \n",
    "    given static kernel and two piecewise linear paths.\n",
    "\n",
    "    Args:\n",
    "        s1 (np.ndarray): A time series of shape (T1, d).\n",
    "        s2 (np.ndarray): A time series of shape (T2, d).\n",
    "        static_diag_kernel_gram (Callable): Takes in two arrays of shape (M, d) \n",
    "                        and outputs the diagonal Gram <x_m, y_m> of shape (M).\n",
    "    \"\"\"\n",
    "    #Find all breakpoints of the piecewise linear paths\n",
    "    T1, d = s1.shape\n",
    "    T2, d = s2.shape\n",
    "    times = np.concatenate([np.linspace(0, 1, T1), np.linspace(0, 1, T2)])\n",
    "    times = sorted(np.unique(times))\n",
    "\n",
    "    #Add the extra breakpoints to the paths\n",
    "    f1 = interp1d(np.linspace(0, 1, T1), s1, axis=0, assume_sorted=True)\n",
    "    f2 = interp1d(np.linspace(0, 1, T2), s2, axis=0, assume_sorted=True)\n",
    "    x = f1(times) #shape (len(times), d)\n",
    "    y = f2(times)\n",
    "\n",
    "    #calculate k(x_t, y_t) for each t\n",
    "    Kt = static_diag_kernel(x, y)\n",
    "\n",
    "    #return integral of k(x_t, y_t) dt\n",
    "    return np.trapz(Kt, times)\n",
    "\n",
    "\n",
    "def integral_kernel_gram(\n",
    "        X:List[np.ndarray],\n",
    "        Y:List[np.ndarray],\n",
    "        static_kernel_gram:Callable, #either linear_kernel_gram or rbf_kernel_gram with \"diag\" argument\n",
    "        variable_length:bool,\n",
    "        sym:bool = False,\n",
    "    ):\n",
    "    \"\"\"Computes the Gram matrix K(X_i, Y_j) of the integral kernel \n",
    "    K(x, y) = \\int k(x_t, y_t) dt.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        static_kernel_gram (Callable): Gram kernel function taking in two ndarrays and\n",
    "                    one boolean \"diag\" argument, see e.g. 'linear_kernel_gram' or \n",
    "                    'rbf_kernel_gram'.\n",
    "        X (List[np.ndarray]): List of time series of shape (T_i, d).\n",
    "        Y (List[np.ndarray]): List of time series of shape (T_j, d).\n",
    "        variable_length (bool): If False, uses the optimized kernels for equal \n",
    "                                length time series.\n",
    "        sym (bool): If True, computes the symmetric Gram matrix.\n",
    "    \"\"\"\n",
    "    if not variable_length:\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        ijKt = static_kernel_gram(X, Y, False) #diag=False\n",
    "\n",
    "        #return integral of k(x_t, y_t) dt for each pair x and y\n",
    "        N, T, d = X.shape\n",
    "        return np.trapz(ijKt, dx=1/T, axis=-1)\n",
    "    else:\n",
    "        # static kernel with diag=True\n",
    "        static_ker = lambda a,b : static_kernel_gram(a,b, True) #diag=True\n",
    "        pairwise_int_ker = lambda s1, s2 : integral_kernel(s1, s2, static_ker)\n",
    "        return pairwise_kernel_gram(X,\n",
    "                                    Y,\n",
    "                                    pairwise_int_ker,\n",
    "                                    sym)\n",
    "\n",
    "############################################################################\n",
    "################# signature kernels of static kernels ######################\n",
    "############################################################################\n",
    "\n",
    "\n",
    "def sig_kernel(s1:np.ndarray, \n",
    "               s2:np.ndarray, \n",
    "               order:int,\n",
    "               static_kernel_gram:Callable = linear_kernel_gram,\n",
    "               only_last:bool = True):\n",
    "    \"\"\"s1 and s2 are time series of shape (T_i, d)\"\"\"\n",
    "    K = static_kernel_gram(s1, s2)\n",
    "    nabla = K[1:, 1:] + K[:-1, :-1] - K[1:, :-1] - K[:-1, 1:]\n",
    "    sig_kers = jitted_trunc_sig_kernel(nabla, order)\n",
    "    if only_last:\n",
    "        return sig_kers[-1]\n",
    "    else:\n",
    "        return sig_kers\n",
    "\n",
    "\n",
    "@njit\n",
    "def reverse_cumsum(arr:np.ndarray, axis:int): #ndim=2\n",
    "    \"\"\"JITed reverse cumulative sum along the specified axis.\n",
    "    (np.cumsum with axis is not natively supported by Numba)\"\"\"\n",
    "    A = arr.copy()\n",
    "    if axis==0:\n",
    "        for i in np.arange(A.shape[0]-2, -1, -1):\n",
    "            A[i, :] += A[i+1, :]\n",
    "    else: #axis==1\n",
    "        for i in np.arange(A.shape[1]-2, -1, -1):\n",
    "            A[:,i] += A[:,i+1]\n",
    "    return A\n",
    "\n",
    "\n",
    "@njit\n",
    "def jitted_trunc_sig_kernel(nabla:np.ndarray, # gram matrix (T_1, T_2)\n",
    "                            order:int,\n",
    "                            ):\n",
    "    \"\"\"Given difference matrix nabla_ij = K[i+1, j+1] + K[i, j] - K[i+1, j] - K[i, j+1],\n",
    "    computes the truncated signature kernel of all orders up to 'order'.\"\"\"\n",
    "    B = np.ones((order+1, order+1, order+1, *nabla.shape))\n",
    "    for d in np.arange(order):\n",
    "        for n in np.arange(order-d):\n",
    "            for m in np.arange(order-d):\n",
    "                B[d+1,n,m] = 1 + nabla/(n+1)/(m+1)*B[d, n+1, m+1]\n",
    "                r1 = reverse_cumsum(nabla * B[d, n+1, 1] / (n+1), axis=0)\n",
    "                B[d+1,n,m, :-1, :] += r1[1:, :]\n",
    "                r2 = reverse_cumsum(nabla * B[d, 1, m+1] / (m+1), axis=1)\n",
    "                B[d+1,n,m, :, :-1] += r2[:, 1:]\n",
    "                rr = reverse_cumsum(nabla * B[d, 1, 1], axis=0)\n",
    "                rr = reverse_cumsum(rr, axis=1)\n",
    "                B[d+1,n,m, :-1, :-1] += rr[1:, 1:]\n",
    "\n",
    "    return B[:,0,0,0,0]\n",
    "\n",
    "\n",
    "def sig_kernel_gram(\n",
    "        X:List[np.ndarray],\n",
    "        Y:List[np.ndarray],\n",
    "        order:int,\n",
    "        static_kernel_gram:Callable,\n",
    "        only_last:bool = True,\n",
    "        sym:bool = False,\n",
    "    ):\n",
    "    \"\"\"Computes the Gram matrix k_sig(X_i, Y_j) of the signature kernel,\n",
    "    given the static kernel k(x, y) and the truncation order.\n",
    "\n",
    "    Args:\n",
    "        X (List[np.ndarray]): List of time series of shape (T_i, d).\n",
    "        Y (List[np.ndarray]): List of time series of shape (T_j, d).\n",
    "        static_kernel_gram (Callable): Gram kernel function taking in two ndarrays,\n",
    "                            see e.g. 'linear_kernel_gram' or 'rbf_kernel_gram'.\n",
    "        order (int): Truncation level of the signature kernel.\n",
    "        only_last (bool): If False, returns results of all truncation levels up to 'order'.\n",
    "        sym (bool): If True, computes the symmetric Gram matrix.\n",
    "    \"\"\"\n",
    "    pairwise_ker = lambda s1, s2 : sig_kernel(s1, s2, order, static_kernel_gram, only_last)\n",
    "    return pairwise_kernel_gram(X,\n",
    "                                Y,\n",
    "                                pairwise_ker,\n",
    "                                sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_stats(num_classes, d, T, N_train, N_test):\n",
    "    print(\"Number of Classes:\", num_classes)\n",
    "    print(\"Dimension of path:\", d)\n",
    "    print(\"Length:\", T)\n",
    "    print(\"Train:\", N_train)\n",
    "    print(\"Test:\", N_test)\n",
    "\n",
    "\n",
    "def case_static(train:np.ndarray, \n",
    "                test:np.ndarray,\n",
    "                static_kernel_gram:Callable):\n",
    "    \"\"\"Calculates the gram matrices of equal length time series for \n",
    "    a static kernel on R^d. Train and test are of shape (N1, T, d) \n",
    "    and (N2, T, d). Static kernel should take in two arrays of shape \n",
    "    (M, T*d) and return the Gram matrix.\"\"\"\n",
    "    N1, T = train.shape[:2]\n",
    "    N2, T = test.shape[:2]\n",
    "    train = train.reshape(N1, -1)\n",
    "    test = test.reshape(N2, -1)\n",
    "    vv_gram = static_kernel_gram(train, train)/T\n",
    "    uv_gram = static_kernel_gram(test, train)/T\n",
    "    return vv_gram, uv_gram\n",
    "\n",
    "\n",
    "def case_linear(train:np.ndarray, \n",
    "                test:np.ndarray):\n",
    "    \"\"\"Calculates the gram matrices for the euclidean inner product.\n",
    "    Train and test are of shape (N1, T, d) and (N2, T, d).\"\"\"\n",
    "    return case_static(train, test, linear_kernel_gram)\n",
    "\n",
    "\n",
    "def case_rbf(train:np.ndarray, \n",
    "                   test:np.ndarray,\n",
    "                   gamma:float):\n",
    "    \"\"\"Calculates the gram matrices for the rbf kernel.\n",
    "    Train and test are of shape (N1, T, d) and (N2, T, d).\"\"\"\n",
    "    rbf_ker = lambda X, Y : rbf_kernel_gram(X, Y, gamma)\n",
    "    return case_static(train, test, rbf_ker)\n",
    "\n",
    "\n",
    "def case_poly(train:np.ndarray, \n",
    "            test:np.ndarray,\n",
    "            p:float):\n",
    "    \"\"\"Calculates the gram matrices for the rbf kernel.\n",
    "    Train and test are of shape (N1, T, d) and (N2, T, d).\"\"\"\n",
    "    poly_ker = lambda X, Y : poly_kernel_gram(X, Y, p)\n",
    "    return case_static(train, test, poly_ker)\n",
    "\n",
    "\n",
    "def case_gak(train:List[np.ndarray], \n",
    "                   test:List[np.ndarray], \n",
    "                   variable_length:bool,\n",
    "                   sigma:float = 1.0,):\n",
    "    \"\"\"Calculates the gram matrices for the gak kernel.\n",
    "    Train and test are lists of possibly variable length multidimension \n",
    "    time series of shape (T_i, d)\"\"\"\n",
    "    #pick sigma parameter according to GAK paper\n",
    "    if not variable_length:\n",
    "        sigma = tslearn.metrics.sigma_gak(np.array(train))\n",
    "\n",
    "    #compute gram matrices\n",
    "    kernel = lambda s1, s2 : tslearn.metrics.gak(s1, s2, sigma)\n",
    "    vv_gram = pairwise_kernel_gram(train, train, kernel, sym=True, disable_tqdm=False)\n",
    "    uv_gram = pairwise_kernel_gram(test, train, kernel, sym=False, disable_tqdm=False)\n",
    "    return vv_gram, uv_gram\n",
    "\n",
    "\n",
    "def case_sig_pde(train:List[np.ndarray], \n",
    "                 test:List[np.ndarray], \n",
    "                 dyadic_order:int = 3,\n",
    "                 static_kernel = sigkernel.LinearKernel(),\n",
    "                ):\n",
    "    \"\"\"Calculates the signature kernel gram matrices of the train and test.\n",
    "    Train and test are lists of possibly variable length multidimension \n",
    "    time series of shape (T_i, d)\"\"\"\n",
    "    sig_kernel = sigkernel.SigKernel(static_kernel, dyadic_order)\n",
    "    kernel = lambda s1, s2 : sig_kernel.compute_kernel(\n",
    "                                stream_to_torch(s1), \n",
    "                                stream_to_torch(s2)).numpy()[0]\n",
    "    vv_gram = pairwise_kernel_gram(train, train, kernel, sym=True, disable_tqdm=False)\n",
    "    uv_gram = pairwise_kernel_gram(test, train, kernel, sym=False, disable_tqdm=False)\n",
    "    return vv_gram, uv_gram\n",
    "\n",
    "\n",
    "def calc_grams(train:List[np.ndarray], \n",
    "               test:List[np.ndarray],\n",
    "               kernel_name:str, \n",
    "               variable_length:bool, \n",
    "               dyadic_order:int,        #for signature pde\n",
    "               order:int,  #for truncated signature\n",
    "               gamma:float = 2,       #for rbf\n",
    "               p:float = 2,             #for polynomial\n",
    "               ):   \n",
    "    \"\"\"Calculates gram matrices <train, train>, <test, train> given a kernel.\n",
    "    Train and test are lists of possibly variable length multidimension time \n",
    "    series of shape (T_i, d)\"\"\"\n",
    "\n",
    "    #Transform to array if possible\n",
    "    if not variable_length:\n",
    "        train = np.array(train)\n",
    "        test = np.array(test)\n",
    "    \n",
    "    #choose method based on kernel name\n",
    "    if kernel_name == \"linear\":\n",
    "        return case_linear(train, test)\n",
    "    \n",
    "    elif kernel_name == \"rbf\":\n",
    "        return case_rbf(train, test, gamma)\n",
    "    \n",
    "    elif kernel_name == \"poly\":\n",
    "        return case_poly(train, test, p)\n",
    "\n",
    "    elif kernel_name == \"gak\":\n",
    "        return case_gak(train, test, variable_length)\n",
    "\n",
    "    elif kernel_name == \"truncated sig\":\n",
    "        vv_gram = sig_kernel_gram(train, train, order, linear_kernel_gram, sym=True)\n",
    "        uv_gram = sig_kernel_gram(test, train, order, linear_kernel_gram)\n",
    "        return vv_gram, uv_gram\n",
    "    \n",
    "    elif kernel_name == \"truncated sig rbf\":\n",
    "        ker = lambda X, Y, diag: rbf_kernel_gram(X, Y, gamma, diag)\n",
    "        vv_gram = sig_kernel_gram(train, train, order, ker, sym=True)\n",
    "        uv_gram = sig_kernel_gram(test, train, order, ker)\n",
    "        return vv_gram, uv_gram\n",
    "    \n",
    "    elif kernel_name == \"truncated sig poly\":\n",
    "        ker = lambda X, Y, diag : poly_kernel_gram(X, Y, p, diag)\n",
    "        vv_gram = sig_kernel_gram(train, train, order, ker, sym=True)\n",
    "        uv_gram = sig_kernel_gram(test, train, order, ker)\n",
    "        return vv_gram, uv_gram\n",
    "    \n",
    "    elif kernel_name == \"signature pde\":\n",
    "        return case_sig_pde(train, \n",
    "                        test, \n",
    "                        variable_length,\n",
    "                        dyadic_order=dyadic_order, \n",
    "                        static_kernel=sigkernel.LinearKernel(),)\n",
    "    \n",
    "    elif kernel_name == \"signature pde RBF\":\n",
    "        return case_sig_pde(train, \n",
    "                        test, \n",
    "                        variable_length,\n",
    "                        dyadic_order=dyadic_order, \n",
    "                        static_kernel=sigkernel.RBFKernel(sigma=0.5),)\n",
    "    \n",
    "    elif kernel_name == \"integral linear\":\n",
    "        vv_gram = integral_kernel_gram(train, train, linear_kernel_gram, variable_length, sym=True)\n",
    "        uv_gram = integral_kernel_gram(test, train, linear_kernel_gram, variable_length)\n",
    "        return vv_gram, uv_gram\n",
    "\n",
    "    elif kernel_name == \"integral rbf\":\n",
    "        ker = lambda X, Y, diag: rbf_kernel_gram(X, Y, gamma, diag)\n",
    "        vv_gram = integral_kernel_gram(train, train, ker, variable_length, sym=True)\n",
    "        uv_gram = integral_kernel_gram(test, train, ker, variable_length)\n",
    "        return vv_gram, uv_gram\n",
    "\n",
    "    elif kernel_name == \"integral poly\":\n",
    "        ker = lambda X, Y, diag : poly_kernel_gram(X, Y, p, diag)\n",
    "        vv_gram = integral_kernel_gram(train, train, ker, variable_length, sym=True)\n",
    "        uv_gram = integral_kernel_gram(test, train, ker, variable_length)\n",
    "        return vv_gram, uv_gram\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Invalid kernel name:\", kernel_name)\n",
    "\n",
    "\n",
    "def normalize_streams(train:np.ndarray, \n",
    "                      test:np.ndarray,\n",
    "                      ):\n",
    "    \"\"\"Inputs are 3D arrays of shape (N, T, d) where N is the number of time series, \n",
    "    T is the length of each time series, and d is the dimension of each time series.\"\"\"\n",
    "    # Normalize data by training set mean and std\n",
    "    mean = np.mean(train, axis=0, keepdims=True)\n",
    "    std = np.std(train, axis=0, keepdims=True)\n",
    "    train = (train - mean) / std\n",
    "    test = (test - mean) / std\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def run_single_kernel(X_train:List[np.ndarray], \n",
    "                    y_train:np.array, \n",
    "                    X_test:List[np.ndarray], \n",
    "                    y_test:np.array, \n",
    "                    labels:np.array, \n",
    "                    kernel_name:str,\n",
    "                    variable_length:bool,\n",
    "                    normalize:bool,\n",
    "                    dyadic_order:int = 3,   #for signature pde\n",
    "                    order:int = 10, #for truncated signature\n",
    "                    SVD_threshold:float = 0.01,\n",
    "                    SVD_max_rank:Optional[int] = None,\n",
    "                    gamma:float = 2,       #for rbf\n",
    "                    ):\n",
    "    \"\"\"Computes the AUC scores (weighted one vs rest) for a single kernel,\n",
    "    using kernelized nearest neighbour variance adjusted distances.\n",
    "\n",
    "    Args:\n",
    "        X_train (List[np.ndarray]): List of time series of shape (T_i, d).\n",
    "        y_train (np.array): 1-dim array of class labels.\n",
    "        X_test (List[np.ndarray]): List of time series of shape (T_i, d).\n",
    "        y_test (np.array): 1-dim array of class labels.\n",
    "        labels (np.array): Array of unique class labels.\n",
    "        kernel_name (str): Name of the kernel to use.\n",
    "        variable_length (bool): If False, uses the optimized kernels for equal \n",
    "                                length time series.\n",
    "        normalize (bool): If True, normalizes train and test by the training set\n",
    "                          mean and std.\n",
    "        dyadic_order (int): Dyadic order for PDE solver \n",
    "                            (int > 0, higher = more accurate but slower).\n",
    "        max_batch (int): Batch size in sig kernel computations.\n",
    "        trunc_sig_dim_bound (int): Upper bound on the dimensionality of the \n",
    "                                  truncated signature.\n",
    "        SVD_threshold (float): Sets all eigenvalues below this threshold to be 0.\n",
    "        SVD_max_rank (int): Sets all SVD eigenvalues to be 0 beyond 'SVD_max_rank'.\n",
    "    \"\"\"\n",
    "    # 2 methods (conf, mahal), 2 metrics (roc_auc, pr_auc), C classes\n",
    "    C = len(labels)\n",
    "    aucs = np.zeros( (2, 2, C) ) \n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        # Get all samples of the current class\n",
    "        idxs = np.where(y_train == label)[0]\n",
    "        corpus = [X_train[k] for k in idxs]\n",
    "        test = X_test\n",
    "        if normalize and not variable_length:\n",
    "            corpus, test = normalize_streams(np.array(corpus), test)\n",
    "\n",
    "        # Calculate amomaly distancce scores for all test samples\n",
    "        vv_gram, uv_gram = calc_grams(corpus, test, kernel_name, \n",
    "                            variable_length, dyadic_order,\n",
    "                            order, gamma=gamma)\n",
    "        scorer = BaseclassConformanceScore(vv_gram, SVD_threshold, print_rank=True, \n",
    "                                           SVD_max_rank=SVD_max_rank)\n",
    "        dists = np.array([scorer._anomaly_distance(sample, method=\"both\") \n",
    "                          for sample in uv_gram]).T\n",
    "        distances_conf, distances_mahal = dists\n",
    "\n",
    "        # Calculate one vs rest AUC, weighted by size of class\n",
    "        for idx_conf_mahal, distances in enumerate([distances_conf, distances_mahal]):\n",
    "            ovr_labels = y_test != label\n",
    "            average=\"weighted\" #average = \"macro\"\n",
    "            roc_auc = sklearn.metrics.roc_auc_score(ovr_labels, distances, average=average)\n",
    "            pr_auc = sklearn.metrics.average_precision_score(ovr_labels, distances, average=average)\n",
    "            aucs[idx_conf_mahal, 0, i] = roc_auc\n",
    "            aucs[idx_conf_mahal, 1, i] = pr_auc\n",
    "    \n",
    "    return aucs\n",
    "\n",
    "\n",
    "def run_tslearn_experiments(dataset_names:List[str], \n",
    "                            kernel_names:List[str],\n",
    "                            gamma:float = 2,\n",
    "                            order:int=10\n",
    "                            ):\n",
    "    \"\"\"Runs a series of time series anomaly detection experiments on the specified \n",
    "    tslearn datasets using kernel conformance scores.\"\"\"\n",
    "    experiments = {}\n",
    "    for dataset_name in dataset_names:\n",
    "        # Load dataset\n",
    "        X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(dataset_name)\n",
    "\n",
    "        # stats\n",
    "        labels = np.unique(y_train)\n",
    "        num_classes = len(labels)\n",
    "        N_train, T, d = X_train.shape\n",
    "        N_test, _, _  = X_test.shape\n",
    "        print_dataset_stats(num_classes, d, T, N_train, N_test)\n",
    "\n",
    "        # Run each kernel\n",
    "        kernel_results = {}\n",
    "        for kernel_name in kernel_names:\n",
    "            print(\"Kernel:\", kernel_name)\n",
    "            scores = run_single_kernel(X_train, y_train, X_test, y_test, labels, \n",
    "                            kernel_name, SVD_threshold=0.001, SVD_max_rank=100,\n",
    "                            variable_length=False, normalize=True, gamma=gamma,\n",
    "                            order=order)\n",
    "            kernel_results[kernel_name] = scores\n",
    "        \n",
    "        #log dataset experiment\n",
    "        experiments[dataset_name] = {\"results\": kernel_results, \n",
    "                                     \"num_classes\": num_classes, \n",
    "                                     \"dim\":d,\n",
    "                                     \"ts_length\":T, \n",
    "                                     \"N_train\":N_train, \n",
    "                                     \"N_test\":N_test}\n",
    "    return experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes: 15\n",
      "Dimension of path: 2\n",
      "Length: 45\n",
      "Train: 180\n",
      "Test: 180\n",
      "Kernel: truncated sig\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kernel Gram Matrix: 100%|██████████| 78/78 [00:00<00:00, 224.53it/s]\n",
      "Kernel Gram Matrix: 100%|██████████| 2160/2160 [00:08<00:00, 241.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance operator numerical rank = 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kernel Gram Matrix: 100%|██████████| 78/78 [00:00<00:00, 223.90it/s]\n",
      "Kernel Gram Matrix: 100%|██████████| 2160/2160 [00:08<00:00, 245.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance operator numerical rank = 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kernel Gram Matrix: 100%|██████████| 78/78 [00:00<00:00, 244.97it/s]\n",
      "Kernel Gram Matrix: 100%|██████████| 2160/2160 [00:08<00:00, 248.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance operator numerical rank = 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kernel Gram Matrix: 100%|██████████| 78/78 [00:00<00:00, 222.59it/s]\n",
      "Kernel Gram Matrix: 100%|██████████| 2160/2160 [00:08<00:00, 249.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance operator numerical rank = 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kernel Gram Matrix: 100%|██████████| 78/78 [00:00<00:00, 247.56it/s]\n",
      "Kernel Gram Matrix: 100%|██████████| 2160/2160 [00:09<00:00, 239.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance operator numerical rank = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kernel Gram Matrix: 100%|██████████| 78/78 [00:00<00:00, 206.42it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m experiments \u001b[38;5;241m=\u001b[39m \u001b[43mrun_tslearn_experiments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#'ArticularyWordRecognition', \u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#'BasicMotions', \u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#'Cricket',\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;66;43;03m##########'ERing', #cant find dataset\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLibras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#'NATOPS', \u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#'RacketSports',     \u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#'FingerMovements',\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#'Heartbeat',\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#'SelfRegulationSCP1', \u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#'UWaveGestureLibrary'\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#\"linear\", \u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#\"rbf\",\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#\"poly\",\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#\"gak\",\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtruncated sig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtruncated sig rbf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtruncated sig poly\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msignature pde\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msignature pde RBF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msignature pde RBF poly\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintegral linear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintegral rbf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintegral poly\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_experiment_results\u001b[39m(experiments, round_digits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dataset_name, results \u001b[38;5;129;01min\u001b[39;00m experiments\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;66;03m#Dataset:\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 274\u001b[0m, in \u001b[0;36mrun_tslearn_experiments\u001b[0;34m(dataset_names, kernel_names, gamma, order)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kernel_name \u001b[38;5;129;01min\u001b[39;00m kernel_names:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKernel:\u001b[39m\u001b[38;5;124m\"\u001b[39m, kernel_name)\n\u001b[0;32m--> 274\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mrun_single_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mkernel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSVD_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSVD_max_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvariable_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m                    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m     kernel_results[kernel_name] \u001b[38;5;241m=\u001b[39m scores\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m#log dataset experiment\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 230\u001b[0m, in \u001b[0;36mrun_single_kernel\u001b[0;34m(X_train, y_train, X_test, y_test, labels, kernel_name, variable_length, normalize, dyadic_order, order, SVD_threshold, SVD_max_rank, gamma)\u001b[0m\n\u001b[1;32m    227\u001b[0m     corpus, test \u001b[38;5;241m=\u001b[39m normalize_streams(np\u001b[38;5;241m.\u001b[39marray(corpus), test)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# Calculate amomaly distancce scores for all test samples\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m vv_gram, uv_gram \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_grams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvariable_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdyadic_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m                    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m scorer \u001b[38;5;241m=\u001b[39m BaseclassConformanceScore(vv_gram, SVD_threshold, print_rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m    234\u001b[0m                                    SVD_max_rank\u001b[38;5;241m=\u001b[39mSVD_max_rank)\n\u001b[1;32m    235\u001b[0m dists \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([scorer\u001b[38;5;241m.\u001b[39m_anomaly_distance(sample, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m    236\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m uv_gram])\u001b[38;5;241m.\u001b[39mT\n",
      "Cell \u001b[0;32mIn[17], line 118\u001b[0m, in \u001b[0;36mcalc_grams\u001b[0;34m(train, test, kernel_name, variable_length, dyadic_order, order, gamma, p)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m kernel_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruncated sig\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    117\u001b[0m     vv_gram \u001b[38;5;241m=\u001b[39m sig_kernel_gram(train, train, order, linear_kernel_gram, sym\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 118\u001b[0m     uv_gram \u001b[38;5;241m=\u001b[39m \u001b[43msig_kernel_gram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinear_kernel_gram\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vv_gram, uv_gram\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m kernel_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruncated sig rbf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "Cell \u001b[0;32mIn[13], line 257\u001b[0m, in \u001b[0;36msig_kernel_gram\u001b[0;34m(X, Y, order, static_kernel_gram, only_last, sym)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the Gram matrix k_sig(X_i, Y_j) of the signature kernel,\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03mgiven the static kernel k(x, y) and the truncation order.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m    sym (bool): If True, computes the symmetric Gram matrix.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m pairwise_ker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m s1, s2 : sig_kernel(s1, s2, order, static_kernel_gram, only_last)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpairwise_kernel_gram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mpairwise_ker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msym\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/kernel-timeseries-anomaly-detection/conformance.py:40\u001b[0m, in \u001b[0;36mpairwise_kernel_gram\u001b[0;34m(X, Y, pairwise_kernel, sym, n_jobs, disable_tqdm)\u001b[0m\n\u001b[1;32m     37\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(np\u001b[38;5;241m.\u001b[39mmeshgrid(np\u001b[38;5;241m.\u001b[39marange(N), np\u001b[38;5;241m.\u001b[39marange(M)))\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#Calculate kernel Gram matrix\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m inner_products \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpairwise_kernel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mKernel Gram Matrix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#Populate matrix\u001b[39;00m\n\u001b[1;32m     45\u001b[0m inner_prod_Gram_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((N,M, \u001b[38;5;241m*\u001b[39minner_products[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape), \n\u001b[1;32m     46\u001b[0m                                   dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n",
      "File \u001b[0;32m~/Code/kernel-timeseries-anomaly-detection/.conda/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Code/kernel-timeseries-anomaly-detection/.conda/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "Cell \u001b[0;32mIn[13], line 256\u001b[0m, in \u001b[0;36msig_kernel_gram.<locals>.<lambda>\u001b[0;34m(s1, s2)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msig_kernel_gram\u001b[39m(\n\u001b[1;32m    237\u001b[0m         X:List[np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[1;32m    238\u001b[0m         Y:List[np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m         sym:\u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    243\u001b[0m     ):\n\u001b[1;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Computes the Gram matrix k_sig(X_i, Y_j) of the signature kernel,\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m    given the static kernel k(x, y) and the truncation order.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m        sym (bool): If True, computes the symmetric Gram matrix.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m     pairwise_ker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m s1, s2 : \u001b[43msig_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_kernel_gram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_last\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pairwise_kernel_gram(X,\n\u001b[1;32m    258\u001b[0m                                 Y,\n\u001b[1;32m    259\u001b[0m                                 pairwise_ker,\n\u001b[1;32m    260\u001b[0m                                 sym)\n",
      "Cell \u001b[0;32mIn[13], line 193\u001b[0m, in \u001b[0;36msig_kernel\u001b[0;34m(s1, s2, order, static_kernel_gram, only_last)\u001b[0m\n\u001b[1;32m    191\u001b[0m K \u001b[38;5;241m=\u001b[39m static_kernel_gram(s1, s2)\n\u001b[1;32m    192\u001b[0m nabla \u001b[38;5;241m=\u001b[39m K[\u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m+\u001b[39m K[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m K[\u001b[38;5;241m1\u001b[39m:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m K[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 193\u001b[0m sig_kers \u001b[38;5;241m=\u001b[39m \u001b[43mjitted_trunc_sig_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnabla\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m only_last:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sig_kers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Code/kernel-timeseries-anomaly-detection/.conda/lib/python3.11/site-packages/numba/core/serialize.py:30\u001b[0m, in \u001b[0;36m_numba_unpickle\u001b[0;34m(address, bytedata, hashed)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Keep unpickled object via `numba_unpickle` alive.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m _unpickled_memo \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numba_unpickle\u001b[39m(address, bytedata, hashed):\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Used by `numba_unpickle` from _helperlib.c\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m        unpickled object\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     key \u001b[38;5;241m=\u001b[39m (address, hashed)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "experiments = run_tslearn_experiments(\n",
    "    dataset_names = [\n",
    "        #'ArticularyWordRecognition', \n",
    "        #'BasicMotions', \n",
    "        #'Cricket',\n",
    "         ##########'ERing', #cant find dataset\n",
    "        'Libras', \n",
    "        #'NATOPS', \n",
    "        #'RacketSports',     \n",
    "        #'FingerMovements',\n",
    "        #'Heartbeat',\n",
    "        #'SelfRegulationSCP1', \n",
    "        #'UWaveGestureLibrary'\n",
    "        ],\n",
    "    kernel_names = [\n",
    "        #\"linear\", \n",
    "        #\"rbf\",\n",
    "        #\"poly\",\n",
    "        #\"gak\",\n",
    "        \"truncated sig\",\n",
    "        \"truncated sig rbf\",\n",
    "        \"truncated sig poly\",\n",
    "        \"signature pde\",\n",
    "        \"signature pde RBF\",\n",
    "        #\"signature pde RBF poly\",\n",
    "        \"integral linear\",\n",
    "        \"integral rbf\",\n",
    "        \"integral poly\",\n",
    "        ],\n",
    "        gamma=0.01,\n",
    "        order=5)\n",
    "\n",
    "\n",
    "def print_experiment_results(experiments, round_digits=5):\n",
    "    for dataset_name, results in experiments.items():\n",
    "        #Dataset:\n",
    "        print(\"Dataset:\", dataset_name)\n",
    "        print_dataset_stats(results[\"num_classes\"], results[\"dim\"], \n",
    "                            results[\"ts_length\"], results[\"N_train\"], \n",
    "                            results[\"N_test\"])\n",
    "\n",
    "        #Results for each kernel:\n",
    "        for kernel_name, scores in results[\"results\"].items():\n",
    "            print(\"\\nKernel:\", kernel_name)\n",
    "            scores = np.mean(scores, axis=2)\n",
    "            print(\"Conformance AUC:\", round(scores[0, 0], round_digits))\n",
    "            print(\"Mahalanobis AUC:\", round(scores[1, 0], round_digits))\n",
    "            print(\"Conformance PR AUC:\", round(scores[0, 1], round_digits))\n",
    "            print(\"Mahalanobis PR AUC:\", round(scores[1, 1], round_digits))\n",
    "\n",
    "        print(\"\\nEnd Dataset\\n\\n\\n\")\n",
    "        \n",
    "print_experiment_results(experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PenDigits dataset (Variable Length) \n",
    "\n",
    "* Can't use ts-learn since it interpolated and homogenized the length of all time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################\n",
    "## Loading code taken from https://github.com/pafoster/conformance_distance_experiments_cochrane_et_al_2020    ##\n",
    "## DATASET_URLS = ['https://archive.ics.uci.edu/ml/machine-learning-databases/pendigits/pendigits-orig.tes.Z', ##\n",
    "##                 'https://archive.ics.uci.edu/ml/machine-learning-databases/pendigits/pendigits-orig.tra.Z'] ##\n",
    "#################################################################################################################\n",
    "\n",
    "def read_pendigits_dataset(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data_lines = f.readlines()\n",
    "\n",
    "    data = []\n",
    "    data_labels = []\n",
    "    current_digit = None\n",
    "    for line in data_lines:\n",
    "        if line == \"\\n\":\n",
    "            continue\n",
    "\n",
    "        if line[0] == \".\":\n",
    "            if \"SEGMENT DIGIT\" in line[1:]:\n",
    "                if current_digit is not None:\n",
    "                    data.append(np.array(current_digit))\n",
    "                    data_labels.append(digit_label)\n",
    "\n",
    "                current_digit = []\n",
    "                digit_label = int(line.split('\"')[1])\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            x, y = map(float, line.split())\n",
    "            current_digit.append([x, y])\n",
    "            \n",
    "    data.append(np.array(current_digit))\n",
    "    data_labels.append(digit_label)\n",
    "    return data, np.array(data_labels)\n",
    "\n",
    "\n",
    "def create_pendigits_dataframe(data):\n",
    "    dataframes = []\n",
    "    for subset, data in data.items():\n",
    "        df = pd.DataFrame(data).T\n",
    "        df.columns = ['data', 'label']\n",
    "        df['subset'] = subset\n",
    "        dataframes.append(df)\n",
    "    return pd.concat(dataframes)\n",
    "\n",
    "data = {'train': read_pendigits_dataset(\"Data/pendigits-orig.tra\"),\n",
    "        'test': read_pendigits_dataset(\"Data/pendigits-orig.tes\")}\n",
    "\n",
    "df_pendigits_raw = create_pendigits_dataframe(data)\n",
    "\n",
    "def plot_pendigits_entry(sample):\n",
    "    df = pd.DataFrame(sample[\"data\"], columns=[\"x\", \"y\"])\n",
    "    fig = px.line(df, x=\"x\", y=\"y\", text=df.index, width=500, height=500)\n",
    "    fig.update_traces(textposition=\"bottom right\")\n",
    "    fig.show()\n",
    "\n",
    "plot_pendigits_entry(df_pendigits_raw.iloc[20])\n",
    "print(df_pendigits_raw.head()) \n",
    "# Each data point is a timeseries of the form ([x_t1, y_t1], ... , [x_tn, y_tn]) \n",
    "# of variable length, that is an array of shape (N_i, 2) for each i in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################## |\n",
    "################################### PenDigits experiments #################################### |\n",
    "############################################################################################## \\/\n",
    "\n",
    "def run_pendigits_experiments(df:pd.DataFrame, \n",
    "                              kernel_names:List[str],\n",
    "                              stream_transforms = [\"time_enhance\", \"min_max_normalize\"],):\n",
    "    \"\"\"Calculates AUCs for each kernel on the PenDigits dataset.\n",
    "    df has columns [\"data\", \"label\", \"subset\"]. Each data point \n",
    "    is a timeseries of shape (T_i, d) of variable length.\"\"\"\n",
    "    #transform streams\n",
    "    df[\"data\"] = df[\"data\"].apply(lambda x : transform_stream(x, stream_transforms))\n",
    "\n",
    "    #Gather dataset info\n",
    "    X_train = df[df[\"subset\"]==\"train\"][\"data\"].values\n",
    "    y_train = np.array(df[df[\"subset\"]==\"train\"][\"label\"].values)\n",
    "    X_test = df[df[\"subset\"]==\"test\"][\"data\"].values\n",
    "    y_test = np.array(df[df[\"subset\"]==\"test\"][\"label\"].values)\n",
    "    labels = sorted(df[\"label\"].unique())\n",
    "    num_classes = len(labels)\n",
    "    d = X_train[0].shape[1]\n",
    "    T = \"variable length\"\n",
    "    N_train = len(X_train)\n",
    "    N_test = len(X_test)\n",
    "    print_dataset_stats(num_classes, d, T, N_train, N_test)\n",
    "\n",
    "    # Run each kernel\n",
    "    kernel_results = {}\n",
    "    for kernel_name in kernel_names:\n",
    "        print(kernel_name)\n",
    "        scores = run_single_kernel(X_train, y_train, X_test, y_test, labels, \n",
    "                        kernel_name, variable_length=True, normalize=False,\n",
    "                        trunc_sig_dim_bound=200, SVD_max_rank=None)\n",
    "        kernel_results[kernel_name] = scores\n",
    "\n",
    "    #log results\n",
    "    pendigits_results = {\"results\": kernel_results, \n",
    "                         \"num_classes\": num_classes,\n",
    "                         \"dim\": d,\n",
    "                         \"ts_length\":T, \n",
    "                         \"N_train\":N_train, \n",
    "                         \"N_test\":N_test}\n",
    "    return pendigits_results\n",
    "\n",
    "# pendigits_results = run_pendigits_experiments(\n",
    "#     df_pendigits_raw, \n",
    "#     kernel_names=[\n",
    "#         #\"gak\",\n",
    "#         \"truncated signature\", \n",
    "#         #\"signature pde\", \n",
    "#         #\"signature pde RBF\"\n",
    "#         ],\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: Libras\n",
    "# Number of Classes: 15\n",
    "# Dimension of path: 2\n",
    "# Length: 45\n",
    "# Train: 180\n",
    "# Test: 180\n",
    "\n",
    "# Kernel: linear\n",
    "# Conformance AUC: 0.9471891534391536\n",
    "# Mahalanobis AUC: 0.9460978835978835\n",
    "# Conformance PR AUC: 0.9952856063472626\n",
    "# Mahalanobis PR AUC: 0.9953123143532209\n",
    "\n",
    "# Kernel: rbf\n",
    "# Conformance AUC: 0.6121858465608465\n",
    "# Mahalanobis AUC: 0.235896164021164\n",
    "# Conformance PR AUC: 0.9543784983385764\n",
    "# Mahalanobis PR AUC: 0.9073331474510873\n",
    "\n",
    "# Kernel: gak\n",
    "# Conformance AUC: 0.8303240740740742\n",
    "# Mahalanobis AUC: 0.056779100529100526\n",
    "# Conformance PR AUC: 0.9720553520740843\n",
    "# Mahalanobis PR AUC: 0.8271237492596946\n",
    "\n",
    "# Kernel: truncated signature\n",
    "# Conformance AUC: 0.8772486772486773\n",
    "# Mahalanobis AUC: 0.8711970899470899\n",
    "# Conformance PR AUC: 0.9884586491342986\n",
    "# Mahalanobis PR AUC: 0.9880448383038575\n",
    "\n",
    "# Kernel: signature pde\n",
    "# Conformance AUC: 0.8616071428571429\n",
    "# Mahalanobis AUC: 0.8559854497354498\n",
    "# Conformance PR AUC: 0.9860276339146576\n",
    "# Mahalanobis PR AUC: 0.9856341293618142\n",
    "\n",
    "# Kernel: signature pde RBF\n",
    "# Conformance AUC: 0.48647486772486775\n",
    "# Mahalanobis AUC: 0.5124669312169311\n",
    "# Conformance PR AUC: 0.9148945413486355\n",
    "# Mahalanobis PR AUC: 0.9149847211152167\n",
    "\n",
    "# End Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_experiment_results({\"PenDigits\": pendigits_results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing ksig  ---- clearly something wrong, since the values dont converge as order->infty for ksig\n",
    "\n",
    "import time\n",
    "\n",
    "def calc_iisig_kernel(X, Y, order):\n",
    "    sig_X, sig_Y = streams_to_sigs([X,Y], order, disable_tqdm=True)\n",
    "    dot = 1 + np.dot(sig_X, sig_Y)\n",
    "    return dot\n",
    "\n",
    "\n",
    "def calc_sigpde_kernel(X,Y):\n",
    "    dyadic_order = 5\n",
    "    static_kernel = sigkernel.LinearKernel()\n",
    "    vv, uv = case_sig_pde([X], [Y], dyadic_order, static_kernel)\n",
    "    return uv[0,0]\n",
    "\n",
    "\n",
    "def trunc_sig_kernel(s1:np.ndarray, \n",
    "                    s2:np.ndarray, \n",
    "                    order:int,\n",
    "                    static_kernel_gram:Callable = linear_kernel_gram,\n",
    "                    only_last:bool = True):\n",
    "    \"\"\"s1 and s2 are time series of shape (T_i, d)\"\"\"\n",
    "    K = static_kernel_gram(s1, s2)\n",
    "    nabla = K[1:, 1:] + K[:-1, :-1] - K[1:, :-1] - K[:-1, 1:]\n",
    "    sig_kers = jitted_trunc_sig_kernel(nabla, order)\n",
    "    if only_last:\n",
    "        return sig_kers[-1]\n",
    "    else:\n",
    "        return sig_kers\n",
    "\n",
    "\n",
    "\n",
    "@njit\n",
    "def reverse_cumsum(arr:np.ndarray, axis:int): #ndim=2\n",
    "    \"\"\"JITed reverse cumulative sum along the specified axis.\n",
    "    (np.cumsum with axis is not natively supported by Numba)\"\"\"\n",
    "    A = arr.copy()\n",
    "    if axis==0:\n",
    "        for i in np.arange(A.shape[0]-2, -1, -1):\n",
    "            A[i, :] += A[i+1, :]\n",
    "    else: #axis==1\n",
    "        for i in np.arange(A.shape[1]-2, -1, -1):\n",
    "            A[:,i] += A[:,i+1]\n",
    "    return A\n",
    "\n",
    "\n",
    "@njit\n",
    "def jitted_trunc_sig_kernel(nabla:np.ndarray, # gram matrix (T_1, T_2)\n",
    "                            order:int,\n",
    "                            ):\n",
    "    \"\"\"Given difference matrix nabla_ij = K[i+1, j+1] + K[i, j] - K[i+1, j] - K[i, j+1],\n",
    "    computes the truncated signature kernel of all orders up to 'order'.\"\"\"\n",
    "    B = np.ones((order+1, order+1, order+1, *nabla.shape))\n",
    "    for d in np.arange(order):\n",
    "        for n in np.arange(order-d):\n",
    "            for m in np.arange(order-d):\n",
    "                B[d+1,n,m] = 1 + nabla/(n+1)/(m+1)*B[d, n+1, m+1]\n",
    "                r1 = reverse_cumsum(nabla * B[d, n+1, 1] / (n+1), axis=0)\n",
    "                B[d+1,n,m, :-1, :] += r1[1:, :]\n",
    "                r2 = reverse_cumsum(nabla * B[d, 1, m+1] / (m+1), axis=1)\n",
    "                B[d+1,n,m, :, :-1] += r2[:, 1:]\n",
    "                rr = reverse_cumsum(nabla * B[d, 1, 1], axis=0)\n",
    "                rr = reverse_cumsum(rr, axis=1)\n",
    "                B[d+1,n,m, :-1, :-1] += rr[1:, 1:]\n",
    "\n",
    "    return B[:,0,0,0,0]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "d = 2\n",
    "MAX_ORDER = 20\n",
    "times_iisig = np.zeros( (MAX_ORDER) )\n",
    "times_sigker  = np.zeros( (MAX_ORDER) )\n",
    "np.random.seed(99)\n",
    "X, Y = np.random.randn(2, 35, d)/np.sqrt(d)\n",
    "for order in range(1, MAX_ORDER+1):\n",
    "    print(\"\\norder\", order)\n",
    "    t0= time.time()\n",
    "    dot1=calc_iisig_kernel(X, Y, order)\n",
    "    t1 = time.time()\n",
    "    dot2=trunc_sig_kernel(X, Y, order)\n",
    "    t2 = time.time()\n",
    "    times_iisig[order-1] = t1-t0\n",
    "    times_sigker[order-1] = t2-t1\n",
    "    print(\"dot1\", dot1)\n",
    "    print(\"dot2\", dot2)\n",
    "\n",
    "print(\"\\n\")\n",
    "dot3 = calc_sigpde_kernel(X, Y)\n",
    "print(\"dot_pde\", dot3)\n",
    "\n",
    "\n",
    "print(\"\\ncomparison\", times_iisig[1:]/times_sigker[1:])\n",
    "print(\"\\niisig\", times_iisig[1:])\n",
    "print(\"\\nksig\", times_sigker[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tslearn\n",
    "\n",
    "_datasets = [\n",
    "            'ArticularyWordRecognition', \n",
    "            'BasicMotions', \n",
    "            'Cricket',\n",
    "            #'ERing',\n",
    "            'Libras', \n",
    "            'NATOPS', \n",
    "            'RacketSports',     \n",
    "            'FingerMovements',\n",
    "            'Heartbeat',\n",
    "            'SelfRegulationSCP1', \n",
    "            'UWaveGestureLibrary'\n",
    "            ]\n",
    "\n",
    "\n",
    "#for dataset_name in ucr_datasets.list_multivariate_datasets():\n",
    "for dataset_name in _datasets:\n",
    "    print(\"Dataset:\", dataset_name)\n",
    "    dataset = tslearn.datasets.UCR_UEA_datasets().load_dataset(dataset_name)\n",
    "    if dataset[0] is not None:\n",
    "        X_train, y_train, X_test, y_test = dataset\n",
    "        num_classes = len(np.unique(y_train))\n",
    "        N_train, T, d = X_train.shape\n",
    "        N_test, _, _  = X_test.shape\n",
    "\n",
    "        # is_irregular = dataset[\"is_irregular\"]\n",
    "        \n",
    "        print(\"Number of Classes:\", num_classes)\n",
    "        print(\"Dimension of path:\", d)\n",
    "        print(\"Length:\", T)\n",
    "        print(\"Train Size, Test Size\", N_train, N_test)\n",
    "        print()\n",
    "    else:\n",
    "        print(\"No dataset found\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: ArticularyWordRecognition\n",
    "# Number of Classes: 25\n",
    "# Dimension of path: 9\n",
    "# Length: 144\n",
    "# Train Size, Test Size 275 300\n",
    "\n",
    "# Dataset: BasicMotions\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 6\n",
    "# Length: 100\n",
    "# Train Size, Test Size 40 40\n",
    "\n",
    "# Dataset: Cricket\n",
    "# Number of Classes: 12\n",
    "# Dimension of path: 6\n",
    "# Length: 1197\n",
    "# Train Size, Test Size 108 72\n",
    "\n",
    "# Dataset: Libras\n",
    "# Number of Classes: 15\n",
    "# Dimension of path: 2\n",
    "# Length: 45\n",
    "# Train Size, Test Size 180 180\n",
    "\n",
    "# Dataset: NATOPS\n",
    "# Number of Classes: 6\n",
    "# Dimension of path: 24\n",
    "# Length: 51\n",
    "# Train Size, Test Size 180 180\n",
    "\n",
    "# Dataset: RacketSports\n",
    "# Number of Classes: 4\n",
    "# Dimension of path: 6\n",
    "# Length: 30\n",
    "# Train Size, Test Size 151 152\n",
    "\n",
    "# Dataset: FingerMovements\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 28\n",
    "# Length: 50\n",
    "# Train Size, Test Size 316 100\n",
    "\n",
    "# Dataset: Heartbeat\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 61\n",
    "# Length: 405\n",
    "# Train Size, Test Size 204 205\n",
    "\n",
    "# Dataset: SelfRegulationSCP1\n",
    "# Number of Classes: 2\n",
    "# Dimension of path: 6\n",
    "# Length: 896\n",
    "# Train Size, Test Size 268 293\n",
    "\n",
    "# Dataset: UWaveGestureLibrary\n",
    "# Number of Classes: 8\n",
    "# Dimension of path: 3\n",
    "# Length: 315\n",
    "# Train Size, Test Size 120 320"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
