{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from typing import Callable, List, Any, Optional\n",
    "import sigkernel\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from typing import List, Optional, Dict, Set, Callable, Any\n",
    "from joblib import Memory, Parallel, delayed\n",
    "import tslearn\n",
    "import tslearn.metrics\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "from scipy.interpolate import interp1d\n",
    "from numba import njit\n",
    "import numba as nb\n",
    "import pickle\n",
    "\n",
    "from experiments.experiment_code import print_dataset_stats, run_all_kernels\n",
    "\n",
    "from models.kernels import linear_kernel_gram, pairwise_kernel_gram\n",
    "from models.normalize_streams import normalize_streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test variability of sig between datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$  \\|x\\|_{TV} = \\sum_{i=1}^L \\|x_{i}- x_{i-1}\\|_{R^d} $\n",
    "\n",
    "$ \\|y\\|_{R^d} = \\sqrt{\\sum_{k=1}^d y_k^2} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epilepsy\n",
      "med 1.2610700519106626 mean 1.5205588421265313\n",
      "med 1.2290120868118444 mean 1.5207301150051347\n",
      "med 1.3267892560589827 mean 1.5204710826157752\n",
      "med 1.3088157171252381 mean 1.520454898347889\n",
      "EthanolConcentration\n",
      "med 0.5672365740287332 mean 1.5208513052588808\n",
      "med 0.6732680694023478 mean 1.5208514267957227\n",
      "med 0.8539969471218722 mean 1.520851428331664\n",
      "med 0.7684349192110888 mean 1.5208514502401749\n",
      "FingerMovements\n",
      "med 1.0737076638768044 mean 1.9492185255187546\n",
      "med 1.006104055967552 mean 1.8656553373570854\n",
      "HandMovementDirection\n",
      "med 1.2406616238719776 mean 1.806652803918013\n",
      "med 1.2805861296462075 mean 1.8066528373681658\n",
      "med 1.2333585318909144 mean 1.8066528241861715\n",
      "med 1.2588020571977865 mean 1.8066527454444181\n",
      "Heartbeat\n",
      "med 0.07442443482165645 mean 1.2368718506602259\n",
      "med 0.3750203552781456 mean 1.6295796207863196\n",
      "LSST\n",
      "med 0.1862502236668958 mean 1.1103918214141022\n",
      "med 0.1623116290916115 mean 1.240177408312023\n",
      "med 0.07043697570782877 mean 0.7298623853163824\n",
      "med 0.24752953966971225 mean 1.3383226864542803\n",
      "med 1.1356722235206655 mean 1.693084009213486\n",
      "med 0.08432992419706052 mean 1.5581351697034087\n",
      "med 0.15548498728370444 mean 1.1168795003582332\n",
      "med 1.0988599339497884 mean 1.6930542273926812\n",
      "med 0.15033505942558012 mean 1.511068040091251\n",
      "med 0.26801804116752465 mean 1.3257382086504852\n",
      "med 0.0997711916952418 mean 1.2542396240057365\n",
      "med 0.07529278061306013 mean 0.528441522314099\n",
      "med 1.0712040402452634 mean 1.686688398154786\n",
      "med 0.08593466717473996 mean 1.4682676208333505\n",
      "MotorImagery\n",
      "med 1.1428289460074534 mean 1.646463932629155\n",
      "med 1.3285861209274645 mean 1.8804945313678834\n",
      "NATOPS\n",
      "med 1.5622075075197621 mean 1.8875360089789317\n",
      "med 1.5883184820251768 mean 1.8875094010940456\n",
      "med 1.3722355482920503 mean 1.8877853176233155\n",
      "med 1.4750987906010549 mean 1.8888151310592844\n",
      "med 1.4440841440449315 mean 1.8888984902617183\n",
      "med 1.5236077942328192 mean 1.8881907298892269\n",
      "PenDigits\n",
      "med 0.7912271939079921 mean 1.2472456202587974\n",
      "med 0.7818609871388061 mean 1.263277518732009\n",
      "med 0.7181647381494511 mean 1.210440576667418\n",
      "med 0.7448219632154051 mean 1.31980858352849\n",
      "med 0.7331052374507991 mean 1.2524408488001093\n",
      "med 0.9589325779012318 mean 1.314243745026377\n",
      "med 0.7590453607800969 mean 1.178947430537495\n",
      "med 0.7906360491723747 mean 1.3055261122767021\n",
      "med 0.9265175018356364 mean 1.2786878956902066\n",
      "med 0.7726861993272631 mean 1.2554991647115024\n",
      "PEMS-SF\n",
      "med 1.7913735974313028 mean 1.8948881672424063\n",
      "med 1.7602630507648123 mean 1.9110370554187792\n",
      "med 1.9334359387326407 mean 1.9090340661243927\n",
      "med 2.0093497527813717 mean 1.9105431727274966\n",
      "med 2.011194153630303 mean 1.9128167656913393\n",
      "med 1.7912555840764717 mean 1.9092764610762305\n",
      "med 2.0127117895743 mean 1.898407804064784\n",
      "PhonemeSpectra\n",
      "med 0.6660370678579269 mean 1.720614572252539\n",
      "med 0.627495458162167 mean 1.7161172254496642\n",
      "med 0.5819545356688239 mean 1.730668933023511\n",
      "med 0.6198836091039748 mean 1.7375261204025414\n",
      "med 0.6031057215527185 mean 1.7409431671226197\n",
      "med 0.5577332333899089 mean 1.7122643852549915\n",
      "med 0.6629205035835233 mean 1.7429693887388151\n",
      "med 0.36111808831400205 mean 1.7076726940006115\n",
      "med 0.6006683265889476 mean 1.7183479186056592\n",
      "med 0.5689309621186804 mean 1.7281480243536302\n",
      "med 0.6214456129194452 mean 1.725476649172476\n",
      "med 0.48847672184960755 mean 1.7602200653334321\n",
      "med 0.5671508872820135 mean 1.7440594666177955\n",
      "med 0.3539286452064184 mean 1.7223701852752618\n",
      "med 0.5938106624105747 mean 1.7377031999108294\n",
      "med 0.17651974923992222 mean 1.70973544964462\n",
      "med 0.5632321539889248 mean 1.7324331049744166\n",
      "med 0.5262702953940728 mean 1.7656729062141023\n",
      "med 0.5981819294832726 mean 1.7227022691410554\n",
      "med 0.297593171814084 mean 1.687645726519255\n",
      "med 0.4289888226135237 mean 1.6604635454953598\n",
      "med 0.4324762129391466 mean 1.6595280618041692\n",
      "med 0.5540901507005633 mean 1.7507353554693261\n",
      "med 0.5224386756688638 mean 1.7580582681494767\n",
      "med 0.5120751461560972 mean 1.7380800810355128\n",
      "med 0.5919965189149456 mean 1.7462083968621667\n",
      "med 0.355565219528135 mean 1.726878083711862\n",
      "med 0.5221778310823686 mean 1.7129997330366238\n",
      "med 0.5210899073704014 mean 1.7344929732012229\n",
      "med 0.5784295186513493 mean 1.7505454302848211\n",
      "med 0.3827075527878685 mean 1.695171659647343\n",
      "med 0.454296155372389 mean 1.725808082669583\n",
      "med 0.6306566310505566 mean 1.7412068970937582\n",
      "med 0.6424758868823269 mean 1.747222239144408\n",
      "med 0.5939609415301704 mean 1.7411633161526325\n",
      "med 0.4282788515819512 mean 1.7005780053088828\n",
      "med 0.41018689025298694 mean 1.7264711034504887\n",
      "med 0.5793197232031112 mean 1.7478582122940696\n",
      "med 0.7068169719926679 mean 1.749367803110474\n",
      "RacketSports\n",
      "med 0.9416186830991604 mean 1.6785200455929188\n",
      "med 1.0584328621123076 mean 1.6809369731063257\n",
      "med 1.09225890163558 mean 1.681834933634191\n",
      "med 1.1018731592156117 mean 1.6800582700216327\n",
      "SelfRegulationSCP1\n",
      "med 0.5704771671171358 mean 1.6477096296260334\n",
      "med 0.7085089114525108 mean 1.7484590993927323\n"
     ]
    }
   ],
   "source": [
    "from experiments.experiment_code import normalize_streams, calc_grams\n",
    "\n",
    "\n",
    "\n",
    "# def do_trunc_sig_gram(train, test, factor:float = 1.0):\n",
    "#     ORDER = 10\n",
    "#     ker = lambda X, Y: linear_kernel_gram(X, Y, param_dict[\"sigma\"], custom_factor=factor) #TODO assumes fixed length\n",
    "#     return case_truncated_sig(train, test, ORDER, \n",
    "#                                 linear_kernel_gram, sig_kernel_only_last, \n",
    "#                                 n_jobs, verbose)\n",
    "\n",
    "\n",
    "\n",
    "def total_variation(X:np.ndarray, \n",
    "                    channelwise:bool = False,\n",
    "                    mean:bool = True,\n",
    "                    ):\n",
    "    \"\"\"Calculates the total variation of time series.\n",
    "    X has shape (..., T, d)\"\"\"\n",
    "    #Total Variation\n",
    "    diffs = np.diff(X, axis=-2)\n",
    "    if channelwise:\n",
    "        TV = np.abs(diffs).sum(axis=-2) #shape (..., d)\n",
    "    else:\n",
    "        TV = np.linalg.norm(diffs, axis=-1).sum(axis=-1) #shape (...,)\n",
    "    \n",
    "    # Average\n",
    "    if mean:\n",
    "        ndim = TV.ndim - int(channelwise)\n",
    "        if ndim > 0:\n",
    "            TV = np.mean(TV, axis=tuple(range(ndim)))\n",
    "\n",
    "    return TV\n",
    "\n",
    "\n",
    "def mean_distance_between_times(X:np.ndarray, \n",
    "                                n_samples_N:int = 100,\n",
    "                                n_samples_T:int = 100):\n",
    "    \"\"\" X shape (N, T, d)\"\"\"\n",
    "\n",
    "    #Sample at timesteps and instances\n",
    "    N, T, d = X.shape\n",
    "    n_samples_N = min(n_samples_N, N)\n",
    "    n_samples_T = min(n_samples_T, T)\n",
    "    choice_N = np.random.choice(N, size=n_samples_N, replace=False)\n",
    "    choice_T = np.random.choice(T, size=n_samples_T, replace=False)\n",
    "    X = X[choice_N][:, choice_T] #shape (n_samples_N, n_samples_T, d)\n",
    "\n",
    "    # #out: (N, T, T))\n",
    "    # new = X.transpose(1, 0, 2)\n",
    "    # xx = linear_kernel_gram(new, new, diag=True, divide_by_dims=False)\n",
    "    # xy = linear_kernel_gram(new, new, diag=False, divide_by_dims=False)\n",
    "    # norms_squared = -2*xy + xx[:, np.newaxis] + xx[np.newaxis, :]\n",
    "    # return np.mean(np.sqrt(norms_squared))\n",
    "\n",
    "    #out: (N, T, T)) TAKE MAXIMUM ALONG T's\n",
    "    new = X.transpose(1, 0, 2)\n",
    "    xx = linear_kernel_gram(new, new, diag=True, divide_by_dims=False)\n",
    "    xy = linear_kernel_gram(new, new, diag=False, divide_by_dims=False)\n",
    "    norms_squared = -2*xy + xx[:, np.newaxis] + xx[np.newaxis, :]\n",
    "    max_distances = np.max(np.sqrt(norms_squared), axis=(-1,-2))\n",
    "    return np.mean(max_distances)\n",
    "\n",
    "\n",
    "\n",
    "def test_variability(dataset_name:str):\n",
    "    X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(dataset_name)\n",
    "    print(dataset_name)\n",
    "    unique_labels = np.unique(y_train)\n",
    "    num_classes = len(unique_labels)\n",
    "    N_train, T, d = X_train.shape\n",
    "\n",
    "    corpus, test = normalize_streams(X_train, X_test)\n",
    "    print(\"corpus\", corpus.shape)\n",
    "    s = tslearn.metrics.sigma_gak(dataset=corpus,\n",
    "          n_samples=100,\n",
    "          random_state=0)\n",
    " \n",
    "    ### calculate the kernel\n",
    "    choice = np.random.choice(N_train, size=20)\n",
    "    choice_test = np.random.choice(len(X_test), size=8)\n",
    "    TRAIN = np.array([corpus[i] for i in choice])\n",
    "    TEST = np.array([test[i] for i in choice_test])\n",
    "    # param_dict = {\"kernel_name\": \"gak\",\n",
    "    #                 \"gak_factor\" : 1}\n",
    "    param_dict = {\"kernel_name\": \"truncated sig\",\n",
    "                    \"order\" : 5}\n",
    "    # param_dict = {\"kernel_name\": \"signature pde\",\n",
    "    #                 \"dyadic_order\" : 3}\n",
    "    vv, uv = calc_grams(TRAIN, TEST, param_dict, sig_kernel_only_last=False, n_jobs=4, verbose=False)\n",
    "    print(uv.shape)\n",
    "    abs = np.mean(np.abs(uv), axis=(-1,-2))\n",
    "    print(\"abs\", abs)\n",
    "    print(\"\\n\")\n",
    "    pass\n",
    "\n",
    "def med_time_dist(corpus:np.ndarray, \n",
    "                n_samples_N:int = 100,\n",
    "                n_samples_T:int = 70):\n",
    "    \"\"\" corpus shape (N, T, d)\"\"\"  #for flattened kernels, first reshape to (N, 1, T*d)\n",
    "\n",
    "    #Sample at timesteps and instances\n",
    "    N, T, d = corpus.shape\n",
    "    n_samples_N = min(n_samples_N, N)\n",
    "    n_samples_T = min(n_samples_T, T)\n",
    "    choice_N = np.random.choice(N, size=n_samples_N, replace=False)\n",
    "    choice_T = np.random.choice(T, size=n_samples_T, replace=False)\n",
    "    X = corpus[choice_N][:, choice_T] #shape (n_samples_N, n_samples_T, d)\n",
    "\n",
    "    # calculate ||x_i - x_j||^2 for all i,j\n",
    "    X = X.reshape(-1, d)\n",
    "    xx = linear_kernel_gram(X, X, diag=True, divide_by_dims=True)  #shape (N1, ...)\n",
    "    xy = linear_kernel_gram(X, X, diag=False, divide_by_dims=True) #shape (N1, N2, ...)\n",
    "    yy = xx  #shape (N2, ...)\n",
    "    norms_squared = -2*xy + xx[:, np.newaxis] + yy[np.newaxis, :] \n",
    "    return np.median(norms_squared), np.mean(norms_squared)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_var(dataset_name:str):\n",
    "    print(dataset_name)\n",
    "    X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(dataset_name)\n",
    "    for label in np.unique(y_train):\n",
    "        X = X_train[y_train == label]\n",
    "        corpus, test = normalize_streams(X, X_test)\n",
    "        med, mean = med_time_dist(corpus)\n",
    "        print(\"med\", med, \"mean\", mean)\n",
    "\n",
    "\n",
    "for dataset_name in [\n",
    "        'Epilepsy',                    # N_corpus = 34\n",
    "        'EthanolConcentration',        # N_corpus = 65\n",
    "        'FingerMovements',             # N_corpus = 158\n",
    "        'HandMovementDirection',       # N_corpus = 40\n",
    "        'Heartbeat',                   # N_corpus = 102\n",
    "        'LSST',                        # N_corpus = 176\n",
    "        'MotorImagery',                # N_corpus = 139\n",
    "        'NATOPS',                      # N_corpus = 30\n",
    "        'PenDigits',                   # N_corpus = 749\n",
    "        'PEMS-SF',                     # N_corpus = 38\n",
    "        'PhonemeSpectra',              # N_corpus = 85\n",
    "        'RacketSports',                # N_corpus = 38\n",
    "        'SelfRegulationSCP1',          # N_corpus = 134\n",
    "        ]:\n",
    "    test_var(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArticularyWordRecognition T=144, d=9\n",
    "# (10, 8, 9)\n",
    "# abs [1.29565776 2.27435506 2.87972308 4.07389224 5.01688708 6.38028238\n",
    "#  7.11759463 7.86446547 8.08651308 8.29304982]\n",
    "\n",
    "\n",
    "# BasicMotions T=100, d=6\n",
    "# (10, 8, 9)\n",
    "# abs [1.04759194e+00 7.15178976e+01 1.40339471e+02 4.10876657e+03\n",
    "#  1.92255294e+04 2.50874495e+05 1.49520768e+06 1.27200498e+07\n",
    "#  7.06710438e+07 4.39333097e+08]\n",
    "\n",
    "\n",
    "# Libras T=45, d=2\n",
    "# (10, 8, 9)\n",
    "# abs [1.89531427 3.83885875 4.15721433 6.99827019 7.40133744 8.93425362\n",
    "#  9.22978483 9.44218473 9.4780136  9.49202141]\n",
    "\n",
    "\n",
    "# NATOPS T=51, d=24\n",
    "# (10, 8, 9)\n",
    "# abs [ 1.01604486  1.53247836  2.82986402  4.49605307  7.90352287 12.42609689\n",
    "#  18.56948677 24.6321559  29.69169966 33.1874835 ]\n",
    "\n",
    "\n",
    "# RacketSports T=30, d=6\n",
    "# (10, 8, 9)\n",
    "# abs [ 1.16522057  4.40396722  9.04935699 15.67076359 30.32986175 39.15169919\n",
    "#  61.60201888 72.30843763 90.79824697 99.62780377]\n",
    "\n",
    "\n",
    "# FingerMovements T=50, d=28\n",
    "# (10, 8, 9)\n",
    "# abs [0.97984797 1.04719032 1.04531916 1.04813437 1.04803513 1.04810413\n",
    "#  1.04810097 1.048102   1.04810194 1.04810195]\n",
    "\n",
    "\n",
    "# Heartbeat T=405, d=61\n",
    "# (10, 8, 9)\n",
    "# abs [1.08550586e+00 7.23266419e+02 9.05013282e+04 5.82884262e+06\n",
    "#  8.83717077e+08 6.35578512e+10 2.92053048e+12 8.94131107e+13\n",
    "#  4.99193194e+15 3.01476687e+17]\n",
    "\n",
    "\n",
    "# UWaveGestureLibrary T=315, d=3\n",
    "# (10, 8, 9)\n",
    "# abs [  1.20473682   9.60296452  14.84277035  39.26442477  67.65798534\n",
    "#  121.57540175 170.10270738 231.90516802 276.56580554 318.60532653]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$          <x, x>  + <y, y> - <x, y>  - <y, x>  =  <x-y, x> + <x-y, y> = <x-y, x-y>      $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.experiment_code import normalize_streams\n",
    "import plotly.express as px\n",
    "\n",
    "def plot_dataset(dataset_name:str):\n",
    "    X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(dataset_name)\n",
    "    print(dataset_name)\n",
    "    unique_labels = np.unique(y_train)\n",
    "    num_classes = len(unique_labels)\n",
    "    N_train, T, d = X_train.shape\n",
    "\n",
    "    corpus, test = normalize_streams(X_train, X_test)\n",
    "\n",
    "    choice = np.random.choice(N_train, size=9)\n",
    "    TRAIN = np.array([corpus[i] for i in choice])\n",
    "    fig = px.line(TRAIN[0])\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\n",
    "for dataset_name in [\n",
    "        'ArticularyWordRecognition', \n",
    "        'BasicMotions', \n",
    "         ###'Cricket',             # fuck cricket, too big and n_samples=10...\n",
    "         ##########'ERing', #cant find dataset\n",
    "        'Libras', \n",
    "        'NATOPS', \n",
    "        'RacketSports',     \n",
    "        'FingerMovements',      # estimates a bit low, 10e-3\n",
    "        'Heartbeat',\n",
    "        'SelfRegulationSCP1',   # CAN RESAMPLE 2x or even 3x, 4x\n",
    "        'UWaveGestureLibrary',\n",
    "        \"PenDigits\",\n",
    "        \"\"\n",
    "        ]:\n",
    "    plot_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.normalize_streams import normalize_streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"UWaveGestureLibrary\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 5\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"SelfRegulationSCP1\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 2\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"SelfRegulationSCP2\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 3\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"Heartbeat\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 2\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"BasicMotions\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 8\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"Libras\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 2\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"EthanolConcentration\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 200\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"HandMovementDirection\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 20\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"LSST\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 28\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"PenDigits\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 7\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"MotorImagery\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 7\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"Epilepsy\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 10\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.experiment_code import normalize_streams\n",
    "import plotly.express as px\n",
    "from tslearn.datasets import UCR_UEA_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epilepsy 34\n",
    "# EthanolConcentration 65\n",
    "# FaceDetection 2945\n",
    "# FingerMovements 158\n",
    "# HandMovementDirection 40\n",
    "# Heartbeat 102\n",
    "# LSST 176\n",
    "# MotorImagery 139\n",
    "# NATOPS 30\n",
    "# PenDigits 749\n",
    "# PEMS-SF 38\n",
    "# PhonemeSpectra 85\n",
    "# RacketSports 38\n",
    "# SelfRegulationSCP1 134\n",
    "\n",
    "for dataset_name in [\n",
    "    \"Epilepsy\",\n",
    "    \"EthanolConcentration\",\n",
    "    \"FaceDetection\",\n",
    "    \"FingerMovements\",\n",
    "    \"HandMovementDirection\",\n",
    "    \"Heartbeat\",\n",
    "    \"LSST\",\n",
    "    \"MotorImagery\",   #NO --- 3000 length too big, too oscillatory\n",
    "    \"NATOPS\",\n",
    "    \"PenDigits\",\n",
    "    \"PEMS-SF\",\n",
    "    \"PhonemeSpectra\",\n",
    "    \"RacketSports\",\n",
    "    \"SelfRegulationSCP1\",\n",
    "]:\n",
    "    X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(dataset_name)\n",
    "    print(dataset_name)\n",
    "    print(X_train.shape)\n",
    "    idx=0\n",
    "    px.line(X_train[idx]).show()\n",
    "    X_train, X_test = normalize_streams(X_train, X_test)\n",
    "    print(X_train.shape)\n",
    "    px.line(X_train[idx]).show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
