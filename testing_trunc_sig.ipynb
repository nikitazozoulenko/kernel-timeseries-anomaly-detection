{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (3, 2)\n",
      "Y (3, 2)\n",
      "\n",
      "order 1\n",
      "d [[ 0.48835662 -0.56098211]\n",
      " [ 1.21184376 -1.06183991]]\n",
      "iisig\t\t 1.0773783588346009\n",
      "trunc\t\t 1.0773783588346006\n",
      "ksig_infty\t 1.0773783588346006\n",
      "\n",
      "order 2\n",
      "d [[ 0.48835662 -0.56098211]\n",
      " [ 1.21184376 -1.06183991]]\n",
      "iisig\t\t 1.1595082714865306\n",
      "trunc\t\t 1.1595082714865304\n",
      "ksig_infty\t 1.0788752114385847\n",
      "\n",
      "order 3\n",
      "d [[ 0.48835662 -0.56098211]\n",
      " [ 1.21184376 -1.06183991]]\n",
      "iisig\t\t 1.1528540644251608\n",
      "trunc\t\t 1.1528540644251606\n",
      "ksig_infty\t 1.0788880807716863\n",
      "\n",
      "order 4\n",
      "d [[ 0.48835662 -0.56098211]\n",
      " [ 1.21184376 -1.06183991]]\n",
      "iisig\t\t 1.1526890212930374\n",
      "trunc\t\t 1.1526890212930372\n",
      "ksig_infty\t 1.0788881430096784\n",
      "\n",
      "order 5\n",
      "d [[ 0.48835662 -0.56098211]\n",
      " [ 1.21184376 -1.06183991]]\n",
      "iisig\t\t 1.1527229483873154\n",
      "trunc\t\t 1.1527229483873151\n",
      "ksig_infty\t 1.0788881432023134\n",
      "\n",
      "order 6\n",
      "d [[ 0.48835662 -0.56098211]\n",
      " [ 1.21184376 -1.06183991]]\n",
      "iisig\t\t 1.152722327789788\n",
      "trunc\t\t 1.1527223277897876\n",
      "ksig_infty\t 1.0788881432027273\n",
      "\n",
      "order 7\n",
      "d [[ 0.48835662 -0.56098211]\n",
      " [ 1.21184376 -1.06183991]]\n",
      "iisig\t\t 1.1527223040042525\n",
      "trunc\t\t 1.1527223040042518\n",
      "ksig_infty\t 1.078888143202728\n",
      "\n",
      "order 8\n",
      "d [[ 0.48835662 -0.56098211]\n",
      " [ 1.21184376 -1.06183991]]\n",
      "iisig\t\t 1.1527223047964903\n",
      "trunc\t\t 1.15272230479649\n",
      "ksig_infty\t 1.078888143202728\n",
      "\n",
      "order 9\n",
      "d [[ 0.48835662 -0.56098211]\n",
      " [ 1.21184376 -1.06183991]]\n",
      "iisig\t\t 1.1527223047954445\n",
      "trunc\t\t 1.1527223047954442\n",
      "ksig_infty\t 1.078888143202728\n",
      "\n",
      "order 10\n",
      "d [[ 0.48835662 -0.56098211]\n",
      " [ 1.21184376 -1.06183991]]\n",
      "iisig\t\t 1.15272230479525\n",
      "trunc\t\t 1.1527223047952495\n",
      "ksig_infty\t 1.078888143202728\n",
      "\n",
      "order 11\n",
      "d [[ 0.48835662 -0.56098211]\n",
      " [ 1.21184376 -1.06183991]]\n",
      "iisig\t\t 1.1527223047952517\n",
      "trunc\t\t 1.1527223047952515\n",
      "ksig_infty\t 1.078888143202728\n",
      "\n",
      "order 12\n",
      "d [[ 0.48835662 -0.56098211]\n",
      " [ 1.21184376 -1.06183991]]\n",
      "iisig\t\t 1.152722304795252\n",
      "trunc\t\t 1.1527223047952515\n",
      "ksig_infty\t 1.078888143202728\n",
      "\n",
      "order 13\n",
      "d [[ 0.48835662 -0.56098211]\n",
      " [ 1.21184376 -1.06183991]]\n",
      "iisig\t\t 1.1527223047952517\n",
      "trunc\t\t 1.1527223047952515\n",
      "ksig_infty\t 1.078888143202728\n",
      "\n",
      "order 14\n",
      "d [[ 0.48835662 -0.56098211]\n",
      " [ 1.21184376 -1.06183991]]\n",
      "iisig\t\t 1.1527223047952517\n",
      "trunc\t\t 1.1527223047952515\n",
      "ksig_infty\t 1.078888143202728\n",
      "\n",
      "order 15\n",
      "d [[ 0.48835662 -0.56098211]\n",
      " [ 1.21184376 -1.06183991]]\n",
      "iisig\t\t 1.1527223047952517\n",
      "trunc\t\t 1.1527223047952515\n",
      "ksig_infty\t 1.078888143202728\n",
      "\n",
      "comparison [3.96862906 2.6675282  2.02566203 1.85461346 1.11229194 0.84766111\n",
      " 0.64393205 0.53896461 0.50211359 0.37359371 0.73377811 0.52765029\n",
      " 2.87723933 2.76610112]\n",
      "\n",
      "iisig [0.00018558 0.00013314 0.00012867 0.00018498 0.00013051 0.00013471\n",
      " 0.00014014 0.00015361 0.00019243 0.0002275  0.00053849 0.00119461\n",
      " 0.00787126 0.00971568]\n",
      "\n",
      "sigker [4.67629998e-05 4.99110001e-05 6.35179995e-05 9.97409998e-05\n",
      " 1.17337000e-04 1.58922000e-04 2.17627000e-04 2.85015000e-04\n",
      " 3.83234001e-04 6.08961000e-04 7.33854001e-04 2.26400900e-03\n",
      " 2.73569700e-03 3.51241100e-03]\n",
      "\n",
      "pde [2.15000000e-07 2.71000317e-07 2.42000169e-07 2.48000106e-07\n",
      " 2.20999937e-07 2.26999873e-07 2.68999429e-07 1.83999873e-07\n",
      " 1.97999725e-07 4.08000233e-07 4.05999344e-07 8.06000571e-07\n",
      " 6.44000465e-07 1.09000030e-06]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from typing import Callable, List, Any, Optional\n",
    "import sigkernel\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from typing import List, Optional, Dict, Set, Callable, Any\n",
    "from joblib import Memory, Parallel, delayed\n",
    "import tslearn\n",
    "import tslearn.metrics\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "from scipy.interpolate import interp1d\n",
    "from numba import njit\n",
    "import numba as nb\n",
    "import pickle\n",
    "\n",
    "from experiments.experiment_code import print_dataset_stats, run_all_kernels\n",
    "\n",
    "from models.signature import streams_to_sigs\n",
    "from models.kernels import linear_kernel_gram, pairwise_kernel_gram\n",
    "from models.conformance import stream_to_torch\n",
    "\n",
    "def calc_iisig_kernel(X, Y, order):\n",
    "    sig_X, sig_Y = streams_to_sigs([X,Y], order, disable_tqdm=True)\n",
    "    dot = 1 + np.dot(sig_X, sig_Y)\n",
    "    return dot\n",
    "\n",
    "\n",
    "def case_sig_pde(train:List[np.ndarray], \n",
    "                 test:List[np.ndarray], \n",
    "                 dyadic_order:int = 5,\n",
    "                 static_kernel = sigkernel.LinearKernel(),\n",
    "                 n_jobs:int = 1,\n",
    "                 verbose:bool = False,\n",
    "                ):\n",
    "    \"\"\"Calculates the signature kernel gram matrices of the train and test.\n",
    "    Train and test are lists of possibly variable length multidimension \n",
    "    time series of shape (T_i, d)\"\"\"\n",
    "    sig_kernel = sigkernel.SigKernel(static_kernel, dyadic_order)\n",
    "    kernel = lambda s1, s2 : sig_kernel.compute_kernel(\n",
    "                                stream_to_torch(s1), \n",
    "                                stream_to_torch(s2)).numpy()[0]\n",
    "    vv_gram = pairwise_kernel_gram(train, train, kernel, sym=True, n_jobs=n_jobs, verbose=verbose)\n",
    "    uv_gram = pairwise_kernel_gram(test, train, kernel, sym=False, n_jobs=n_jobs, verbose=verbose)\n",
    "    return vv_gram, uv_gram\n",
    "\n",
    "\n",
    "def calc_sigpde_kernel(X,Y):\n",
    "    dyadic_order = 3\n",
    "    T, d = X.shape\n",
    "    static_kernel = sigkernel.LinearKernel(scale=1) #TODO change here\n",
    "    vv, uv = case_sig_pde([X], [Y], dyadic_order, static_kernel)\n",
    "    return uv[0,0]\n",
    "\n",
    "\n",
    "# def calc_ksig_kernel(X,Y, order):\n",
    "#     import ksig\n",
    "#     static_kernel = ksig.static.kernels.LinearKernel() \n",
    "#     sig_kernel = ksig.kernels.SignatureKernel(n_levels=order, order=1, static_kernel=static_kernel, normalize=False)\n",
    "#     dot = sig_kernel(np.array([X,X]), np.array([Y,Y]))[0,0]\n",
    "#     return dot\n",
    "\n",
    "\n",
    "def trunc_sig_kernel(s1:np.ndarray, \n",
    "                    s2:np.ndarray, \n",
    "                    order:int, #order is truncation level of the signature\n",
    "                    static_kernel_gram:Callable,\n",
    "                    only_last:bool = True,\n",
    "\n",
    "                    ):\n",
    "    \"\"\"s1 and s2 are time series of shape (T_i, d)\"\"\"\n",
    "    T,d = s1.shape\n",
    "    K = static_kernel_gram(s1, s2)\n",
    "    nabla = K[1:, 1:] + K[:-1, :-1] - K[1:, :-1] - K[:-1, 1:]\n",
    "    sig_kers = jitted_trunc_sig_kernel(nabla, order)\n",
    "    if only_last:\n",
    "        return sig_kers[-1]\n",
    "    else:\n",
    "        return sig_kers\n",
    "\n",
    "\n",
    "\n",
    "@njit(fastmath=True, cache=True)\n",
    "def reverse_cumsum(arr:np.ndarray, axis:int): #ndim=2\n",
    "    \"\"\"JITed reverse cumulative sum along the specified axis.\n",
    "    (np.cumsum with axis is not natively supported by Numba)\"\"\"\n",
    "    A = arr.copy()\n",
    "    if axis==0:\n",
    "        for i in np.arange(A.shape[0]-2, -1, -1):\n",
    "            A[i, :] += A[i+1, :]\n",
    "    else: #axis==1\n",
    "        for i in np.arange(A.shape[1]-2, -1, -1):\n",
    "            A[:,i] += A[:,i+1]\n",
    "    return A\n",
    "\n",
    "\n",
    "@njit(fastmath=True, cache=True)\n",
    "def jitted_trunc_sig_kernel(nabla:np.ndarray, # gram matrix (T_1, T_2)\n",
    "                            order:int,\n",
    "                            ):\n",
    "    \"\"\"Given difference matrix nabla_ij = K[i+1, j+1] + K[i, j] - K[i+1, j] - K[i, j+1],\n",
    "    computes the truncated signature kernel of all orders up to 'order'.\"\"\"\n",
    "    B = np.ones((order+1, order+1, order+1, *nabla.shape))\n",
    "    for d in np.arange(order):\n",
    "        for n in np.arange(order-d):\n",
    "            for m in np.arange(order-d):\n",
    "                B[d+1,n,m] = 1 + nabla/(n+1)/(m+1)*B[d, n+1, m+1]\n",
    "                r1 = reverse_cumsum(nabla * B[d, n+1, 1] / (n+1), axis=0)\n",
    "                B[d+1,n,m, :-1, :] += r1[1:, :]\n",
    "                r2 = reverse_cumsum(nabla * B[d, 1, m+1] / (m+1), axis=1)\n",
    "                B[d+1,n,m, :, :-1] += r2[:, 1:]\n",
    "                rr = reverse_cumsum(nabla * B[d, 1, 1], axis=0)\n",
    "                rr = reverse_cumsum(rr, axis=1)\n",
    "                B[d+1,n,m, :-1, :-1] += rr[1:, 1:]\n",
    "\n",
    "    return B[:,0,0,0,0]\n",
    "\n",
    "\n",
    "@njit((nb.float64, nb.int64), fastmath=True, cache=True)\n",
    "def bessel_2sqrt(z:float,\n",
    "                level:int = 10, #truncation level\n",
    "           ):\n",
    "    \"\"\"Computes I_0( 2sqrt(z) ) where I_0 is the Bessel function of the \n",
    "    first kind, via its power series expansion truncated at 'level'.\"\"\"\n",
    "\n",
    "    out = 1\n",
    "    for i in np.arange(level, 0, -1):\n",
    "        out = 1 + z/i**2 * out\n",
    "    return out\n",
    "    \n",
    "\n",
    "def ksig_infty(x:np.ndarray, \n",
    "            y:np.ndarray, \n",
    "            order:int, #order is truncation level of the signature\n",
    "            static_kernel_gram:Callable,\n",
    "            ):\n",
    "    # print(\"x\", x.shape)\n",
    "    # print(\"y\", y.shape)\n",
    "    xdiff = np.diff(x, axis=0)\n",
    "    ydiff = np.diff(y, axis=0)\n",
    "    # print(\"xdiff\", xdiff.shape)\n",
    "    # print(\"ydiff\", ydiff.shape)\n",
    "\n",
    "    derivatives = static_kernel_gram(xdiff, ydiff)\n",
    "    d = derivatives\n",
    "    print(\"d\", d)\n",
    "    # print(\"derivatives\", derivatives.shape)\n",
    "    # return bessel_2sqrt(np.sum(derivatives), level=order)\n",
    "    #TODO CHANGE HERE\n",
    "    s = d[1,1] +d[0,0] + d[0,1] + d[1,0]\n",
    "    return bessel_2sqrt(s, level=order)\n",
    "\n",
    "\n",
    "d = 2\n",
    "MAX_ORDER = 15\n",
    "times_iisig = np.zeros( (MAX_ORDER) )\n",
    "times_sigker  = np.zeros( (MAX_ORDER) )\n",
    "times_sigpde = np.zeros( (MAX_ORDER) )\n",
    "times_siginfty = np.zeros( (MAX_ORDER) )\n",
    "np.random.seed(99)\n",
    "T1 = 3\n",
    "T2 = 3\n",
    "X = np.random.randn(T1, d) / d\n",
    "Y = np.random.randn(T2, d) / d\n",
    "print(\"X\", X.shape)\n",
    "print(\"Y\", Y.shape)\n",
    "\n",
    "static_kernel = lambda X, Y : linear_kernel_gram(X, Y, custom_factor=1.0)\n",
    "\n",
    "for order in range(1, MAX_ORDER+1):\n",
    "    print(\"\\norder\", order)\n",
    "    t0= time.perf_counter()\n",
    "    dot1=calc_iisig_kernel(X, Y, order)\n",
    "    t1 = time.perf_counter()\n",
    "    dot2=trunc_sig_kernel(X, Y, order, static_kernel_gram=static_kernel, only_last=True)\n",
    "    t2 = time.perf_counter()\n",
    "    #dot3=calc_sigpde_kernel(X, Y)\n",
    "    t3 = time.perf_counter()\n",
    "    dot4=ksig_infty(X, Y, order, static_kernel_gram=static_kernel)\n",
    "    t4 = time.perf_counter()\n",
    "    times_iisig[order-1] = t1-t0\n",
    "    times_sigker[order-1] = t2-t1\n",
    "    times_sigpde[order-1] = t3-t2\n",
    "    times_siginfty[order-1] = t4-t3\n",
    "    print(\"iisig\\t\\t\", dot1)\n",
    "    print(\"trunc\\t\\t\", dot2)\n",
    "    print(\"ksig_infty\\t\", dot4)\n",
    "    #print(\"dot3\", dot3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\ncomparison\", times_iisig[1:]/times_sigker[1:])\n",
    "print(\"\\niisig\", times_iisig[1:])\n",
    "print(\"\\nsigker\", times_sigker[1:])\n",
    "print(\"\\npde\", times_sigpde[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o1 1.0773783600000002\n",
      "o2 13.271283681174836\n"
     ]
    }
   ],
   "source": [
    "d = np.array([[ 0.48835662, -0.56098211],\n",
    "              [ 1.21184376, -1.06183991]])\n",
    "\n",
    "o1 = bessel_2sqrt(d.sum(), level=1)\n",
    "print(\"o1\", o1)\n",
    "cumsum = np.cumsum(d, axis=0)\n",
    "cumsum = np.cumsum(cumsum, axis=1)\n",
    "cumsum = np.cumsum(cumsum, axis=0)\n",
    "cumsum = np.cumsum(cumsum, axis=1)\n",
    "o2 = bessel_2sqrt(cumsum.sum(), level=2) \n",
    "print(\"o2\", o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m00 1.5513156265384986\n",
      "m10 3.574933058791967\n",
      "m01 0.928682533042025\n",
      "test 4.625996003011747\n"
     ]
    }
   ],
   "source": [
    "m00 = bessel_2sqrt(d[0,0], level=10)\n",
    "m10 = bessel_2sqrt(d[0,0]+d[1,0], level=10)\n",
    "m01 = bessel_2sqrt(d[0,0]+d[0,1], level=10)\n",
    "print(\"m00\", m00)\n",
    "print(\"m10\", m10)\n",
    "print(\"m01\", m01)\n",
    "\n",
    "test = m10 + m01 -m00 + bessel_2sqrt(d, level=10)\n",
    "print(\"test\", test)\n",
    "\n",
    "target = 1.1527223047952517\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2523508795013205"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bessel_2sqrt(2, level=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=9\n",
    "factor = d**(1/2) * 45**(1/8)\n",
    "X, Y = np.random.randn(2, 45, d) / factor\n",
    "median = np.median(X, axis=0)\n",
    "print(\"median\", median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDEA: truncated sig --- calculate total variation and base scale on that.   TODO TODO TODO TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test variability of sig between datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$  \\|x\\|_{TV} = \\sum_{i=1}^L \\|x_{i}- x_{i-1}\\|_{R^d} $\n",
    "\n",
    "$ \\|y\\|_{R^d} = \\sqrt{\\sum_{k=1}^d y_k^2} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.experiment_code import normalize_streams, calc_grams\n",
    "\n",
    "\n",
    "\n",
    "# def do_trunc_sig_gram(train, test, factor:float = 1.0):\n",
    "#     ORDER = 10\n",
    "#     ker = lambda X, Y: linear_kernel_gram(X, Y, param_dict[\"sigma\"], custom_factor=factor) #TODO assumes fixed length\n",
    "#     return case_truncated_sig(train, test, ORDER, \n",
    "#                                 linear_kernel_gram, sig_kernel_only_last, \n",
    "#                                 n_jobs, verbose)\n",
    "\n",
    "\n",
    "\n",
    "def total_variation(X:np.ndarray, \n",
    "                    channelwise:bool = False,\n",
    "                    mean:bool = True,\n",
    "                    ):\n",
    "    \"\"\"Calculates the total variation of time series.\n",
    "    X has shape (..., T, d)\"\"\"\n",
    "    #Total Variation\n",
    "    diffs = np.diff(X, axis=-2)\n",
    "    if channelwise:\n",
    "        TV = np.abs(diffs).sum(axis=-2) #shape (..., d)\n",
    "    else:\n",
    "        TV = np.linalg.norm(diffs, axis=-1).sum(axis=-1) #shape (...,)\n",
    "    \n",
    "    # Average\n",
    "    if mean:\n",
    "        ndim = TV.ndim - int(channelwise)\n",
    "        if ndim > 0:\n",
    "            TV = np.mean(TV, axis=tuple(range(ndim)))\n",
    "\n",
    "    return TV\n",
    "\n",
    "\n",
    "def mean_distance_between_times(X:np.ndarray, \n",
    "                                n_samples_N:int = 100,\n",
    "                                n_samples_T:int = 100):\n",
    "    \"\"\" X shape (N, T, d)\"\"\"\n",
    "\n",
    "    #Sample at timesteps and instances\n",
    "    N, T, d = X.shape\n",
    "    n_samples_N = min(n_samples_N, N)\n",
    "    n_samples_T = min(n_samples_T, T)\n",
    "    choice_N = np.random.choice(N, size=n_samples_N, replace=False)\n",
    "    choice_T = np.random.choice(T, size=n_samples_T, replace=False)\n",
    "    X = X[choice_N][:, choice_T] #shape (n_samples_N, n_samples_T, d)\n",
    "\n",
    "    # #out: (N, T, T))\n",
    "    # new = X.transpose(1, 0, 2)\n",
    "    # xx = linear_kernel_gram(new, new, diag=True, divide_by_dims=False)\n",
    "    # xy = linear_kernel_gram(new, new, diag=False, divide_by_dims=False)\n",
    "    # norms_squared = -2*xy + xx[:, np.newaxis] + xx[np.newaxis, :]\n",
    "    # return np.mean(np.sqrt(norms_squared))\n",
    "\n",
    "    #out: (N, T, T)) TAKE MAXIMUM ALONG T's\n",
    "    new = X.transpose(1, 0, 2)\n",
    "    xx = linear_kernel_gram(new, new, diag=True, divide_by_dims=False)\n",
    "    xy = linear_kernel_gram(new, new, diag=False, divide_by_dims=False)\n",
    "    norms_squared = -2*xy + xx[:, np.newaxis] + xx[np.newaxis, :]\n",
    "    max_distances = np.max(np.sqrt(norms_squared), axis=(-1,-2))\n",
    "    return np.mean(max_distances)\n",
    "\n",
    "\n",
    "\n",
    "def test_variability(dataset_name:str):\n",
    "    X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(dataset_name)\n",
    "    print(dataset_name)\n",
    "    unique_labels = np.unique(y_train)\n",
    "    num_classes = len(unique_labels)\n",
    "    N_train, T, d = X_train.shape\n",
    "\n",
    "    corpus, test = normalize_streams(X_train, X_test)\n",
    "    print(\"corpus\", corpus.shape)\n",
    "    s = tslearn.metrics.sigma_gak(dataset=corpus,\n",
    "          n_samples=100,\n",
    "          random_state=0)\n",
    "    \n",
    "    ### TOTAL VARIATION TESTS\n",
    "    # TV = total_variation(X_train, channelwise=False, mean=True)\n",
    "    # print(TV)\n",
    "    # ### calculate the kernel\n",
    "    # choice = np.random.choice(N_train, size=20)\n",
    "    # choice_test = np.random.choice(len(X_test), size=2)\n",
    "    # TRAIN = np.array([corpus[i] for i in choice])\n",
    "    # TEST = np.array([test[i] for i in choice_test])\n",
    "    # TV_TRAIN = total_variation(TRAIN)\n",
    "    # print(\"TV_TRAIN\", TV_TRAIN)\n",
    "    # TRAIN = TRAIN / TV_TRAIN * 30\n",
    "    # TEST = TEST / TV_TRAIN * 30\n",
    "    # print(\"new tv train\", total_variation(TRAIN))\n",
    "    # # param_dict = {\"kernel_name\": \"gak\",\n",
    "    # #                 \"gak_factor\" : 1}\n",
    "    # # param_dict = {\"kernel_name\": \"truncated sig\",\n",
    "    # #                 \"order\" : 8}\n",
    "    # param_dict = {\"kernel_name\": \"signature pde\",\n",
    "    #                 \"dyadic_order\" : 3}\n",
    "    # vv, uv = calc_grams(TRAIN, TEST, param_dict, fixed_length=True, sig_kernel_only_last=False, n_jobs=4, verbose=False)\n",
    "    # print(uv.shape)\n",
    "    # abs = np.mean(np.abs(uv), axis=(-1,-2))\n",
    "    # print(\"abs\", abs)\n",
    "    # print(\"\\n\")\n",
    "    # pass\n",
    "\n",
    "\n",
    "    # ## MEAN DISTANCE TEST\n",
    "    # dist = mean_distance_between_times(X_train)\n",
    "    # print(\"dist\", dist)\n",
    "    # ### calculate the kernel\n",
    "    # choice = np.random.choice(N_train, size=20)\n",
    "    # choice_test = np.random.choice(len(X_test), size=2)\n",
    "    # TRAIN = np.array([corpus[i] for i in choice])\n",
    "    # TEST = np.array([test[i] for i in choice_test])\n",
    "    # TRAIN = TRAIN / dist \n",
    "    # TEST = TEST / dist\n",
    "    # print(\"new dist train\", mean_distance_between_times(TRAIN))\n",
    "    # # param_dict = {\"kernel_name\": \"gak\",\n",
    "    # #                 \"gak_factor\" : 1}\n",
    "    # # param_dict = {\"kernel_name\": \"truncated sig\",\n",
    "    # #                 \"order\" : 8}\n",
    "    # param_dict = {\"kernel_name\": \"signature pde\",\n",
    "    #                 \"dyadic_order\" : 3}\n",
    "    # vv, uv = calc_grams(TRAIN, TEST, param_dict, fixed_length=True, sig_kernel_only_last=False, n_jobs=4, verbose=False)\n",
    "    # print(uv.shape)\n",
    "    # abs = np.mean(np.abs(uv), axis=(-1,-2))\n",
    "    # print(\"abs\", abs)\n",
    "    # print(\"\\n\")\n",
    "    # pass\n",
    "\n",
    "\n",
    "    ### calculate the kernel\n",
    "    choice = np.random.choice(N_train, size=20)\n",
    "    choice_test = np.random.choice(len(X_test), size=8)\n",
    "    TRAIN = np.array([corpus[i] for i in choice])\n",
    "    TEST = np.array([test[i] for i in choice_test])\n",
    "    # param_dict = {\"kernel_name\": \"gak\",\n",
    "    #                 \"gak_factor\" : 1}\n",
    "    # param_dict = {\"kernel_name\": \"truncated sig\",\n",
    "    #                 \"order\" : 8}\n",
    "    param_dict = {\"kernel_name\": \"signature pde\",\n",
    "                    \"dyadic_order\" : 3}\n",
    "    vv, uv = calc_grams(TRAIN, TEST, param_dict, fixed_length=True, sig_kernel_only_last=False, n_jobs=4, verbose=False)\n",
    "    print(uv.shape)\n",
    "    abs = np.mean(np.abs(uv), axis=(-1,-2))\n",
    "    print(\"abs\", abs)\n",
    "    print(\"\\n\")\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "for dataset_name in [\n",
    "        'ArticularyWordRecognition', \n",
    "        'BasicMotions',                #skip for now, instabilities for sig linear\n",
    "        'Libras',\n",
    "        'NATOPS',\n",
    "        'RacketSports',\n",
    "        'FingerMovements',\n",
    "        'Heartbeat',                   #skip for now, instabilities for sig linear\n",
    "        'SelfRegulationSCP1',  \n",
    "        'UWaveGestureLibrary',\n",
    "        'PenDigits',\n",
    "        'LSST',\n",
    "        'EthanolConcentration',\n",
    "        ]:\n",
    "    test_variability(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArticularyWordRecognition T=144, d=9\n",
    "# (10, 8, 9)\n",
    "# abs [1.29565776 2.27435506 2.87972308 4.07389224 5.01688708 6.38028238\n",
    "#  7.11759463 7.86446547 8.08651308 8.29304982]\n",
    "\n",
    "\n",
    "# BasicMotions T=100, d=6\n",
    "# (10, 8, 9)\n",
    "# abs [1.04759194e+00 7.15178976e+01 1.40339471e+02 4.10876657e+03\n",
    "#  1.92255294e+04 2.50874495e+05 1.49520768e+06 1.27200498e+07\n",
    "#  7.06710438e+07 4.39333097e+08]\n",
    "\n",
    "\n",
    "# Libras T=45, d=2\n",
    "# (10, 8, 9)\n",
    "# abs [1.89531427 3.83885875 4.15721433 6.99827019 7.40133744 8.93425362\n",
    "#  9.22978483 9.44218473 9.4780136  9.49202141]\n",
    "\n",
    "\n",
    "# NATOPS T=51, d=24\n",
    "# (10, 8, 9)\n",
    "# abs [ 1.01604486  1.53247836  2.82986402  4.49605307  7.90352287 12.42609689\n",
    "#  18.56948677 24.6321559  29.69169966 33.1874835 ]\n",
    "\n",
    "\n",
    "# RacketSports T=30, d=6\n",
    "# (10, 8, 9)\n",
    "# abs [ 1.16522057  4.40396722  9.04935699 15.67076359 30.32986175 39.15169919\n",
    "#  61.60201888 72.30843763 90.79824697 99.62780377]\n",
    "\n",
    "\n",
    "# FingerMovements T=50, d=28\n",
    "# (10, 8, 9)\n",
    "# abs [0.97984797 1.04719032 1.04531916 1.04813437 1.04803513 1.04810413\n",
    "#  1.04810097 1.048102   1.04810194 1.04810195]\n",
    "\n",
    "\n",
    "# Heartbeat T=405, d=61\n",
    "# (10, 8, 9)\n",
    "# abs [1.08550586e+00 7.23266419e+02 9.05013282e+04 5.82884262e+06\n",
    "#  8.83717077e+08 6.35578512e+10 2.92053048e+12 8.94131107e+13\n",
    "#  4.99193194e+15 3.01476687e+17]\n",
    "\n",
    "\n",
    "# UWaveGestureLibrary T=315, d=3\n",
    "# (10, 8, 9)\n",
    "# abs [  1.20473682   9.60296452  14.84277035  39.26442477  67.65798534\n",
    "#  121.57540175 170.10270738 231.90516802 276.56580554 318.60532653]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$          <x, x>  + <y, y> - <x, y>  - <y, x>  =  <x-y, x> + <x-y, y> = <x-y, x-y>      $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.experiment_code import normalize_streams\n",
    "import plotly.express as px\n",
    "\n",
    "def plot_dataset(dataset_name:str):\n",
    "    X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(dataset_name)\n",
    "    print(dataset_name)\n",
    "    unique_labels = np.unique(y_train)\n",
    "    num_classes = len(unique_labels)\n",
    "    N_train, T, d = X_train.shape\n",
    "\n",
    "    corpus, test = normalize_streams(X_train, X_test)\n",
    "\n",
    "    choice = np.random.choice(N_train, size=9)\n",
    "    TRAIN = np.array([corpus[i] for i in choice])\n",
    "    fig = px.line(TRAIN[0])\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\n",
    "for dataset_name in [\n",
    "        'ArticularyWordRecognition', \n",
    "        'BasicMotions', \n",
    "         ###'Cricket',             # fuck cricket, too big and n_samples=10...\n",
    "         ##########'ERing', #cant find dataset\n",
    "        'Libras', \n",
    "        'NATOPS', \n",
    "        'RacketSports',     \n",
    "        'FingerMovements',      # estimates a bit low, 10e-3\n",
    "        'Heartbeat',\n",
    "        'SelfRegulationSCP1',   # CAN RESAMPLE 2x or even 3x, 4x\n",
    "        'UWaveGestureLibrary',\n",
    "        \"PenDigits\",\n",
    "        \"\"\n",
    "        ]:\n",
    "    plot_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.experiment_code import normalize_streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"UWaveGestureLibrary\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 5\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"SelfRegulationSCP1\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 2\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"Heartbeat\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 2\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"BasicMotions\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 8\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"Libras\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 2\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"EthanolConcentration\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 200\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"HandMovementDirection\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 20\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"LSST\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 28\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"PenDigits\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 7\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(\"MotorImagery\")\n",
    "import plotly.express as px\n",
    "print(X_train.shape)\n",
    "idx = 7\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()\n",
    "X_train, X_test = normalize_streams(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "fig = px.line(X_train[idx])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.experiment_code import normalize_streams\n",
    "import plotly.express as px\n",
    "from tslearn.datasets import UCR_UEA_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epilepsy 34\n",
    "# EthanolConcentration 65\n",
    "# FaceDetection 2945\n",
    "# FingerMovements 158\n",
    "# HandMovementDirection 40\n",
    "# Heartbeat 102\n",
    "# LSST 176\n",
    "# MotorImagery 139\n",
    "# NATOPS 30\n",
    "# PenDigits 749\n",
    "# PEMS-SF 38\n",
    "# PhonemeSpectra 85\n",
    "# RacketSports 38\n",
    "# SelfRegulationSCP1 134\n",
    "\n",
    "for dataset_name in [\n",
    "    \"Epilepsy\",\n",
    "    \"EthanolConcentration\",\n",
    "    \"FaceDetection\",\n",
    "    \"FingerMovements\",\n",
    "    \"HandMovementDirection\",\n",
    "    \"Heartbeat\",\n",
    "    \"LSST\",\n",
    "    \"MotorImagery\",   #NO --- 3000 length too big, too oscillatory\n",
    "    \"NATOPS\",\n",
    "    \"PenDigits\",\n",
    "    \"PEMS-SF\",\n",
    "    \"PhonemeSpectra\",\n",
    "    \"RacketSports\",\n",
    "    \"SelfRegulationSCP1\",\n",
    "]:\n",
    "    X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(dataset_name)\n",
    "    print(dataset_name)\n",
    "    print(X_train.shape)\n",
    "    idx=0\n",
    "    px.line(X_train[idx]).show()\n",
    "    X_train, X_test = normalize_streams(X_train, X_test)\n",
    "    print(X_train.shape)\n",
    "    px.line(X_train[idx]).show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
